{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RDK Documentation?","text":"Entertainment <p>Build Apps, manage media and UI layers in a video platform</p> Explore Features <p>Explore the various features and standards that are supported in RDK</p> Core Components <p>Access detailed documentation on various Core RDK components</p> Architecture <p>Dive deep into the RDK7 Architecture and how different layers interface each other</p> Latest Releases <p>Details on the latest release for video platforms - RDK7</p> Connectivity <p>Framework that enables high-speed internet delivery for service providers. </p> Explore Features <p>Explore the various features and standards that are supported in RDK</p> Core Components <p>Access detailed documentation on various Core RDK components</p> Architecture <p>Dive deep into the RDK middleware architecture and how different layers interface each other</p> Latest Releases <p>Details on the latest release for broadband platforms - 2025 Q2</p> Developer Resources Entertainment Connectivity Getting Started <p>Start exploring RDK software, build RDK in your own setup, and try out RDK in a reference platform.</p> Explore Develop an App <p>Explore Firebolt\u2122, the RDK app framework, and Lightning\u2122 the app development SDK.</p> Explore Port RDK <p>Explore how the port RDK and get it up and running in your platform.</p> Explore Test RDK Device <p>Explore how the open source tools from RDK can be used to test your RDK devices.</p> Explore Getting Started <p>Start exploring RDK software, and try out RDK in a reference platform</p> Explore Features <p>Explore the various features and standards that are supported in RDK</p> Explore Core Components <p>Refer the detailed documentation on Core RDK Components</p> Explore Test RDK Device <p>Explore how the open source tools from RDK can be used to test your RDK devices</p> Explore"},{"location":"connectivity/docs/","title":"Place Holder markdown for Connectivity  Overview page","text":""},{"location":"connectivity/docs/architecture/","title":"Place Holder markdown for Connectivity Architecture","text":""},{"location":"connectivity/docs/features/","title":"Place Holder markdown for Connectivity features","text":""},{"location":"connectivity/docs/rdkb_components/","title":"Place Holder markdown for Connectivity  core component landing page","text":""},{"location":"connectivity/docs/tryout_rdkb/","title":"Place Holder markdown for Connectivity  Getting Started page","text":""},{"location":"device-management/docs/","title":"Device Management","text":"<p>Device management encompasses the centralized control, monitoring, configuration, and maintenance of connected devices, enabling efficient bulk operations, dynamic feature management, and firmware updates to ensure optimal performance, security, and scalability across diverse deployments. The significance lies in its ability to horizontally scale across these profiles, allowing for the efficient sharing of the same code. This streamlined approach facilitates controlled bulk operations and data retrievals, essential for managing diverse devices at scale. The functionality extends to enabling or disabling features dynamically and facilitating firmware (code) downloads. Moreover, Device Management plays a crucial role in retrieving field matrices, ensuring a comprehensive and organized approach to overseeing and controlling devices within the specified frameworks.</p>"},{"location":"device-management/docs/#device-management-capabilities","title":"Device Management capabilities","text":"<p>Different device management capabilities are shared across the different profiles. The key device management capabilities are:</p>"},{"location":"device-management/docs/#xconf","title":"XConf","text":"<p>XConf\u00a0is a pivotal device management service that enables streamlined code download in set-top-boxes (STBs), providing essential information on firmware version, download source, and download protocol. It overcomes limitations of traditional code downloads by employing the eSTB interface for code download.</p>"},{"location":"device-management/docs/#webpa","title":"WebPA","text":"<p>WebPA (Web Protocol Adapter) serves as a secure web protocol messaging system for bi-directional communication between cloud servers and RDK devices. It offers read/write access to device management parameters, prioritizing security and performance, and replaces traditional methods like TR-69 or SNMP.</p>"},{"location":"device-management/docs/LogUpload/","title":"Placeholder for Log Upload documentation","text":""},{"location":"device-management/docs/TR369/","title":"Placeholder for TR369 documentation","text":""},{"location":"device-management/docs/Telemetry/","title":"Placeholder for Telemetry documentation","text":""},{"location":"device-management/docs/Webpa/","title":"Placeholder for webpa documentation","text":""},{"location":"device-management/docs/XConf/","title":"Placeholder for XConf documentation","text":""},{"location":"devices/docs/overview/","title":"Place Holder markdown for Devices page","text":""},{"location":"entertainment/docs/","title":"Overview","text":"Getting Started with RDK for Entertainment Architecture <p>         The latest release of RDK6 comes with major changes in its architecture, including Firebolt - RDK's resident app platform - and the vendor porting kit - among other major changes. To know more details of the RDK Architecture, follow the below link          Click Here </p> Features <p>         A deciding factor of any software stack is the number of user centric features that are supported by that software.  To know what are the features supported by the RDK software stack for various target profiles, follow the below link          Click Here </p> Device Profiles <p>         From the fundamental RDK IP STB to the more sophisticated RDK TV, RDK offers a variety of device profiles: IP STB, Hybrid STB, and RDK TV. To know the details of core components available across profiles, as well as on the differentiating components, please follow below link          Click Here </p> Try Out RDK <p>         The best way to experience RDK is to try out RDK youself in a platform. Get yourself started in exploring RDK, by generating an RDK build of your own, and then getting it up on the popular generic reference platform Raspberry Pi 4          Click Here </p> Vendor Porting Guide <p>          If you are trying to bring up/ port RDK to your SOC platform, you can refer to the Hardware Porting Kit to understand the various HAL APIs that need to be implemented in order to complete the RDK Porting          Click Here </p> RDK Components <p>         To understand the architecture of each RDK component, how the component interfaces with other components as well as other layers of RDK, please follow the below link          Click Here </p>"},{"location":"entertainment/docs/architecture/","title":"Architecture","text":"<p>RDK Video (RDK-V ) Architecture is designed to enable service providers and device manufacturers to develop and deploy innovative video applications, services, and user experiences. It consists of several key components that work together seamlessly to provide a robust video platform.</p> <p>By leveraging the pluggable architecture of RDK-V, a variety of target device profiles can be supported, ranging from a basic IP streaming video platform to a full-fledged TV.</p> <ul> <li>IP provides a common method to manage video playback functions. The IP client device serves as an interface and receives video content from an in-home gateway device or from an external media server.</li> <li>Hybrid is an IP video platform device with capabilities such as tuning and conditional access for its video delivery to manage hybrid video functions.</li> <li>TV is an open-source smart TV profile that allows manufacturers and operations to build RDK-based TV and video solutions.</li> <li>RDK Hybrid TV is a combination of TV plus Hybrid capabilities such as tuning, conditional access, etc.</li> </ul>"},{"location":"entertainment/docs/architecture/#evolution-of-rdk","title":"Evolution of RDK","text":"<p>From RDK6, RDK-V shifted from quarterly to annual release cycles. This annual RDK release aims to synchronize RDK-V with standard industry release practices while comprehensively addressing shared challenges within the community. This approach facilitates the smoother and more consistent adoption of newly contributed features, utilizing the latest releases from technology partners. By aligning with SoC partners, the release enables better resource planning to support core RDK-V platforms. Furthermore, the RDK-V release aligns with SoC, OEM, and app releases, fostering a more cohesive and efficient ecosystem. The first annual release is RDK6, and its release notes can be accessed from RDK6 Release Notes.</p> <p></p>"},{"location":"entertainment/docs/architecture/#architecture-details","title":"Architecture Details","text":"<p>Below is an illustrative representation of the RDK-V software stack, depicting the various components and their interactions.</p> <p></p> <p>At its core, RDK-V consists of five main stack levels, each serving a specific purpose in the overall architecture. These levels are as follows:</p>"},{"location":"entertainment/docs/architecture/#applications","title":"Applications","text":"<p>The application layer primarily focuses on the end-user experience. This layer contains applications that provide various services, content, and features to the users. While the RDK-V ecosystem is continuously evolving, supported applications typically include popular OTT services like Netflix, Amazon Prime Video, and YouTube, alongside native broadcaster applications and other services.</p>"},{"location":"entertainment/docs/architecture/#application-platform","title":"Application Platform","text":"<p>The Application Platform Layer in the RDK-V ecosystem offers essential tools for developers to create applications. It includes components like a UI framework , HTML5 rendering engine, and a JavaScript runtime . This layer acts as a communication channel, serving as a middleware between applications and core RDK-V services. In the RDK-V framework, Firebolt\u00ae handles UI rendering and user input, enabling extensive customization. Lightning\u2122, an open-source JavaScript platform, manages the application lifecycle and integrates components using WebGL for rendering. Together, Firebolt\u00ae and Lightning\u2122 form a robust foundation for seamless and efficient application development in the RDK-V ecosystem.</p> <p>Firebolt\u00ae 1.0 (Ripple) - Firebol\u00ae 1.0 (Ripple) streamlines RDK-V app integration with standardized rules. Ripple, its open-source Rust-based Application gateway, facilitates dynamic extensions and serves as a Firebolt\u00ae gateway. RDK 6 is Firebolt\u00ae 1.0-certified, with a comprehensive test suite for compliance.</p> <p>Security - The Application Platform Layer ensures robust security with Dobby-managed containerization, leveraging Linux kernel features for process isolation. Downloadable Application Containers (DAC) enable the secure running of binary applications on\u00a0video platforms without modification, ensuring compatibility across RDK 6 devices. Access control is enforced through AppArmor, a proactive Linux security system. RDKM's open-sourced AppArmor profile generator tool for RDK 6 provides fine-grained control over process resources, contributing to a secure environment.</p>"},{"location":"entertainment/docs/architecture/#rdk-middleware","title":"RDK Middleware","text":"<p>Serving as a vital bridge between the Application Platform Layer and the hardware (HAL), the RDK Middleware Layer incorporates essential components that are pivotal for the seamless operation of the RDK-V platform. Core to this layer are RDK services, providing JSON-RPC services for interactive applications. In the realm of security, iCrypto handles critical cryptographic operations, ensuring secure communication and data protection. Rialto offers a secure solution for AV pipelines in containerized applications, and the Window Manager orchestrates GUI layout. Device management enables streamlined operations in RDK deployments, including bulk operations and firmware downloads. XCONF integration revolutionizes code downloads for a smoother deployment experience. Log uploads aid in comprehensive debugging, offering insights into system performance. RDK Feature Control (RFC) enables dynamic feature management for enhanced flexibility. Telemetry systematically collects essential data insights, while WebPA ensures secure communication between cloud servers and RDK devices. The Media Player, crucial for local rendering devices, manages various pipeline functions, supporting IP and QAM playback. The Open Content Decryption Module(OCDM) enforces Digital Rights Management (DRM) policies. Together with other RDK-V elements, these components ensure the efficient and secure functioning of the RDK-V platform.</p>"},{"location":"entertainment/docs/architecture/#rdk-hal-hardware-abstraction-layer","title":"RDK HAL (Hardware Abstraction Layer)","text":"<p>In the RDK-V stack, the HAL layer plays a vital role in facilitating communication between the video application software and hardware components like the GPU, video encoding/decoding hardware, and audio devices. It provides a standardized framework for functions, data structures, and protocols, enabling efficient hardware resource utilization. The HAL layer manages hardware initialization, input/output operations, and hardware-specific events, shielding software developers from hardware complexities and allowing them to prioritize user experience and functionality.</p> <p>RDK-V provides a set of HAL APIs that abstract the platform from RDK. Vendors need to implement the HAL APIs to meet the HAL specifications. With the help of the HAL API specification for different RDK-V components, vendors can successfully port RDK-V to their platform. Depending on the device profile (IP, TV, Hybrid, etc.), vendors may choose the relevant components and perform the port by implementing the HAL layer. For more details on the vendor porting process, refer to the Vendor Porting Guide.</p>"},{"location":"entertainment/docs/architecture/#soc","title":"SOC","text":"<p>The System on Chip (SOC) layer forms the foundational interface between hardware components, ensuring system security and reliability. It incorporates various crucial elements, such as DRM Libraries, which manage digital rights and secure content delivery to prevent unauthorized access and distribution. Trusted Applications (Apps TA) guarantee the secure execution of sensitive operations and protect critical data from unauthorized access. The Secure Store oversees the storage of DRM keys and apps triplets, maintaining the confidentiality and integrity of vital data. Additionally, MFR Libraries manage hardware functionality, providing access to specific hardware features and capabilities, thereby contributing to the overall security and functionality of the system.</p>"},{"location":"entertainment/docs/architecture/#application-scenario","title":"Application Scenario","text":"<p>Consider the use case of a user accessing a streaming application like Youtube on an RDK Video-supported device. The user interacts with the application through the Application Layer, selecting content and initiating playback. The Application Platform Layer, utilizing the Firebolt\u00ae and Lightning\u2122 frameworks, manages the user interface and application lifecycle. The RDK-V Layer ensures seamless communication between the application and the hardware, managing services, cryptographic operations, inter-component communication, window management, and content decryption through OpenCDM. The RDK HAL Layer then utilizes the Gstreamer media pipeline to decode and render the video content, ensuring a smooth and high-quality viewing experience. Finally, the SOC Layer provides a secure environment for the entire system, safeguarding the hardware, managing DRM policies, and securing sensitive data, ensuring a secure and reliable video streaming experience for the user.</p>"},{"location":"entertainment/docs/architecture/#useful-links","title":"Useful Links","text":"<p>RDK-V:</p> <p>You can find an overview of the RDK-V platform, detailing its key features and functionalities at RDK Video Documentation.</p> <p>Applications:</p> <p>To get the information about various applications supported by the RDK-V, aiding in understanding the diverse application landscape refer RDK Video Accelerator - Applications.</p> <p>Application Development:</p> <p>Developers interested in RDK-V application development using Firebolt \u00ae can refer Firebolt\u00ae Overview,</p> <p>Developers interested in RDK-V application development using Lightning\u2122 the inhouse JavaScript framework - can refer Lightning\u2122 Framework.</p> <p>Security:</p> <p>Understanding the concept of containerization in RDK-V is crucial for ensuring secure and efficient application deployment, and the 'Containerization in RDK' document provides in-depth insights into this aspect.</p> <p>To learn about the implementation and benefits of Downloadable Application Containers (DAC) within the RDK-V ecosystem, the 'DAC Documentation' offers comprehensive guidance for developers.</p> <p>For insight into the Access Control Mechanism in RDK-V using AppArmor, developers can refer to the 'AppArmor Documentation' to understand how to enforce security policies and restrict application access within the RDK-V environment.</p>"},{"location":"entertainment/docs/features/","title":"Placeholder page for Entertainment features","text":""},{"location":"entertainment/docs/hpk/","title":"Placeholder page for RDK Vendor Porting Guide","text":""},{"location":"entertainment/docs/rdkv_components/","title":"Place Holder markdown for Entertainment  core component landing page","text":""},{"location":"entertainment/docs/tryout_rdkv/","title":"Placeholder page for Getting started in RDK","text":""},{"location":"entertainment/docs/video_profiles/","title":"Placeholder page for RDK Device Profiles","text":""},{"location":"preview-rdk/docs/preview-rdk-broadband/","title":"Preview RDK Broadband","text":"<p>RDK</p> <p>RDK is a fully modular, portable, and customizable open source software solution that standardizes core functions used in video, broadband, and IoT devices. Deployed on over a hundred million devices around the globe, RDK enables operators to manage devices and easily customize their UIs and apps, providing analytics to improve the customer experience. RDK is platform and operator agnostic, so it can easily be ported &amp; adopted by multiple SoC/OEM/Operators, significantly reducing the time to market . With over 600 companies, RDK has an active open source community that regularly contributes cutting edge technologies to the stack.</p> <p>RDK Broadband (RDK-B) software is capable of powering next-gen gateways across DOCSIS, PON, DSL, 5G, and Ethernet, enabling OEMs to standardize elements of their modems, gateways, and converged devices. It provides common functionalities such as routing, Wi-Fi, DNS, diagnostics, remote management, and IoT interfaces, such as Bluetooth, Thread, and Zigbee.</p>"},{"location":"preview-rdk/docs/preview-rdk-broadband/#rdk-architecture","title":"RDK Architecture","text":"<p>RDK middleware is powered by generic open source software along with RDK specific open source components. The RDK Broadband middleware stack architecture is pictured below:</p> <p></p>"},{"location":"preview-rdk/docs/preview-rdk-broadband/#implementing-rdk","title":"Implementing RDK","text":"<p>Getting started with RDK is easy. A simple image depicting adoption of RDK is below:</p> <p></p>"},{"location":"preview-rdk/docs/preview-rdk-broadband/#broadband-user-interface","title":"Broadband User Interface","text":"<p>WebUI is a graphical user interface that is available on connected devices. It acts as an application running on the RDK-B stack and performs the functions of a device management interface similar to TR69 &amp; SNMP. Users can monitor and modify RDK-B feature settings/rules using WebUI. It is a client\u2013server application: the client runs in a web browser (as part of devices connected over LAN) and Lighttpd on the RDK-B stack acts as server.</p> <p>WebUi can be accessed by both the LAN clients and from the WAN Side.</p> <p>WebUI From WAN Side:</p> <p>Give 'http://&lt;WAN IP Address of RaspberryPi&gt;:8080' in browser.</p> <ul> <li>Example:\u00a0     http://192.168.1.35:8080</li> </ul> <p>If you use erouter0 IP, then it opens admin page</p> <p>Login Credentials:</p> <p>Username: admin Password: password</p> <p>Once the login is successful, the user can verify and control various aspects of the Network Connection (like the SSID of the network, password of the network etc.).</p> <p></p> <p>WebUI For LAN Clients :</p> <p>In browser on the LAN client/machine give the url http://10.0.0.1 to launch the captive portal page.</p> <p></p>"},{"location":"preview-rdk/docs/preview-rdk-broadband/#try-out-rdk","title":"Try Out RDK","text":""},{"location":"preview-rdk/docs/preview-rdk-broadband/#further-reading","title":"Further Reading","text":"<ul> <li>RDK-B Raspberry Pi</li> <li>RDK-B R-Pi Build guide</li> <li>RDK Documentation</li> <li>RDK Broadband Documentation rdk+faq</li> </ul> <pre><code>.oc-documentation-card-s&amp;#123;\nposition: relative;\nflex-direction: column!important;\ndisplay: flex!important;\nmargin-block-end:1rem!important; display: flex;\nalign-items: center;\nborder: 0.1px solid \\#d7d7d7;\nbox-shadow: 4px 2px 2px 0 rgba(128, 128, 128, 30);\nmargin-bottom: 0.5rem;\nbox-shadow: 2px 2px 6px 0 rgba(0, 0, 0, 0.1);\n&amp;#125;\n.oc-documentation-card-s:hover&amp;#123;border: 3px solid \\#d7d7d7;&amp;#125;\n.support&amp;#123;\nposition: relative;\nflex-direction: column!important;\ndisplay: flex!important;\nmargin-block-end:1rem!important; display: flex;\nborder: 0.1px solid \\#d7d7d7;\nbox-shadow: 4px 2px 2px 0 rgba(128, 128, 128, 30);\nborder-radius:30;\nmargin-bottom: 0.5rem;\nalign-items: center;\nbox-shadow: 2px 2px 6px 0 rgba(0, 0, 0, 0.1);\n&amp;#125;\n</code></pre>"},{"location":"preview-rdk/docs/preview-rdk-video/","title":"Entertainment","text":"<p>RDK is a fully modular, portable, and customizable open-source software solution that standardizes core functions used in video, broadband, and IoT devices. Deployed on over a hundred million devices around the globe, RDK enables operators to manage devices and easily customize their UIs and apps, providing analytics to improve the customer experience. RDK is platform and operator agnostic, so it can easily be ported &amp; adopted by multiple SoC/OEM/Operators, significantly reducing the time to market. With over 600 companies, RDK has an active open-source community that regularly contributes cutting edge technologies to the stack.</p> <p></p> <p>RDK for Entertainment RDK middleware enables operators to add video streaming capabilities to their IP or hybrid devices. The latest version of the RDK Video software stack is designed to simplify app development and integration on any set-top device, while allowing companies to maintain complete control of their apps, device data, and customer experience. This is achieved through Firebolt\u2122, the RDK application platform, which ensures compatibility with the latest app releases, eliminating the need for future updates. The seamless integration of global streaming apps provides operators with an easy path to offer subscribers today's most popular content.  </p> <p>Video User Interface Preview</p> <p>The front end of any video device is the user interface that consumers will see. RDK comes with an open-source UI written in Lightning\u2122  , or you can create your own. To experience the RDK UI, watch the Video:  </p> <p>Try Out RDK</p> <p>If you want to play around RDK, a port of RDK is available on the popular open source platform Raspberry Pi. A guide on how to bring up RDK for Entertainment in Raspberry Pi is available here</p>"},{"location":"source/docs/build-system/","title":"Build System","text":""},{"location":"source/docs/build-system/#yocto-build-system-overview","title":"Yocto Build System Overview","text":"<p>The Yocto Project is an open source collaboration project that provides templates, tools and methods to help create custom Linux-based systems for embedded products. It is an open source project initiated by the Linux Foundation in 2010. The Yocto Project uses the OpenEmbedded build system to construct complete Linux images.</p> <p>The core components of the Yocto Project are:</p> <ul> <li>BitBake     , the build engine is a task scheduler, like make. It interprets configuration files and recipes (also called metadata) to perform a set of tasks, to download, configure and build specified packages and filesystem images.</li> <li>OpenEmbedded-Core     , a set of base layers. It is a set of recipes, layers and classes which are shared between all OpenEmbedded based systems. Recipes have a specific syntax and describe how to fetch, configure, compile and package applications and images. Layers are sets of recipes, matching a common purpose. Multiple layers are used within a same distribution, depending on the requirements.</li> </ul>"},{"location":"source/docs/build-system/#yocto-architecture","title":"Yocto Architecture","text":""},{"location":"source/docs/build-system/#bitbake","title":"BitBake","text":"<p>BitBake is the task executor and scheduler used by the OpenEmbedded build system to build images. BitBake is a generic task execution engine that allows shell and Python tasks to be run efficiently and in parallel while working within complex inter-task dependency constraints. BitBake stores the output of each task in a directory, the shared state cache. Its location is controlled by the SSTATE_DIR variable. This cache is use to speed up compilation.</p> <p>Usage: <pre><code>bitbake [options] [recipename/target ...]\u00a0\n</code></pre> Bitbake executes all the layers starting with a prefix \u2018meta\u2019.</p> <p>The build/ directory</p> <ul> <li>conf/     \u00a0: Configuration files - image specific and layer configuration.</li> <li>downloads/     \u00a0: This folder stores the downloaded upstream tarballs of the packages used in the builds, facilitating fast rebuilds. If the content of this folder is deleted, the builds will go and refetch the source tars again.</li> <li>sstate-cache/     \u00a0: Shared state cache, it is the local prebuilt store used by all builds. It will be populated when you do the builds. It is important to keep this directory safe for sstate reuse.</li> <li>tmp/     \u00a0: Holds all the build.</li> <li>tmp/buildstats/     \u00a0: Build statistics for all packages built (CPU usage, elapsed time, host, timestamps).</li> <li>tmp/deploy/     \u00a0: Final output of the build.</li> <li>tmp/deploy/images/     \u00a0: Contains the complete images built by the OpenEmbedded build system. These images are used to flash the target.</li> <li>tmp/work/     \u00a0: Set of specific work directories, split by architecture. They are used to unpack, configure and build the packages. Contains the patched sources, generated objects and logs.</li> <li>tmp/sysroots/     \u00a0: Shared libraries and headers used to compile packages for the target but also for the host.</li> </ul> <p>Note: \u00a0build-(e.g. build-oem-platform) - This is the object/build directory, all objects and intermediate files for all components are stored in this folder. if you want to do a clean build you can delete this folder, then run ./meta-cmf/setup-environment and rebuild. The build will be very fast since it will reuse the sstate (prebuilts) during this build, assuming the sstate-cache directory was populated with previous builds already."},{"location":"source/docs/build-system/#meta-layers","title":"Meta-layers","text":"<p>Meta-layer contains configuration, recipes, classes, patches.</p> <ul> <li>Configuration (*.conf) files: global definition of variables</li> <li>Classes (*.bbclass): encapsulation and inheritance of build logic, packaging etc.</li> <li>Recipes (*.bb, *.bbappend): logical units of software/Images to build\u00a0</li> </ul> <p>Bitbake parses the build classes, config files, and recipes. For every task, a shell script on-the-fly is created and executed.</p>"},{"location":"source/docs/build-system/#recipe","title":"Recipe","text":"<p>Recipes are essentially a set of instructions for building packages. A recipe describes where you get source code and which patches to apply. Recipes describe dependencies for libraries or for other recipes, and they also contain configuration and compilation options. Recipes contain the logical unit of execution, the software to build, the images to build, and use the .bb file extension.</p> <p>The recipes are parsed by the BitBake build engine. The format of a recipe file name is  _.bb <p>A recipe contains configuration variables: name, license, dependencies, path to retrieve the source code etc. It also contains functions that can be run (fetch, configure, compile. . .), called tasks.</p> <p>Recipe provides:</p> <ul> <li>Descriptive information about the package.</li> <li>Existing dependencies (both build and runtime dependencies)</li> <li>DEPENDS &amp; RDEPENDS variables holds the build &amp; runtime dependencies e.g.</li> <li>Where the source code resides and how to fetch it: SRC_URI variable holds the URL path to fetch</li> <li>The version of the recipe</li> <li>Whether the source code requires any patches, where to find them, and how to apply them</li> <li>How to configure and compile the source code</li> <li>Where on the target machine to install the package or packages created</li> </ul>"},{"location":"source/docs/build-system/#append-files","title":"Append Files","text":"<p>Files that append build information to a recipe file. Append files are known as BitBake append files and .bbappend files. The OpenEmbedded build system expects every append file to have a corresponding recipe (.bb) file. Furthermore, the append file and corresponding recipe file must use the same root filename. The filenames can differ only in the file type suffix used (e.g. formfactor_0.0.bb and formfactor_0.0.bbappend).</p> <p>Information in append files overrides the information in the similarly-named recipe file.</p>"},{"location":"source/docs/build-system/#patches","title":"Patches","text":"<p>Patches can be applied to recipe files. Patch files should be having extension *.patch. Place the patch file in subdirectory of recipe named (component) folder.\u00a0 The subdirectory should be preferably named as that of component or as \u2018files\u2019. Add the below line to the recipe file</p> <p>SRC_URI += file://filename.patch/ \u00a0</p>"},{"location":"source/docs/build-system/#external-src","title":"External SRC","text":"<p>By default, the OpenEmbedded build system uses the Build Directory when building source code. The build process involves fetching the source files, unpacking them, and then patching them if necessary before the build takes place.\u00a0</p> <p>Yocto place individual components at discrete locations for the build purpose. For example; consider emulator build</p> <p>../../&lt; Project Folder &gt;/build-qemux86mc/tmp/work/i586-rdk-linux/iarmbus</p> <p>../../&lt; Project Folder &gt;/build-qemux86mc/tmp/work/qemux86mc-rdk-linux/devicesettings</p> <p>It will be difficult for a developer to do a code walk through since the entire source code is spread across multiple directories. You might want to\u00a0build software from source files that are external to and thus outside of the OpenEmbedded build system.For example</p> <p>../../&lt; Project Folder&gt;/generic</p> <p>You want the recipe's SRC_URI variable to point to the external directory and use it as is, not copy it.\u00a0Yocto provides a solution to this by its external SRC support. By this all the components will be pulled to a single place.\u00a0Say, you are component owner and only focused to modify source code of that component and build it alone.\u00a0Modify the files under\u00a0../../&lt; Project Folder &gt;/generic/iarmbus\u00a0(as an example; you can modify any component like this)</p> <p>bitbake iarmbus (as an example; you can build any component like this)</p> <p>To build from software that comes from an external source, all you need to do is inherit the externalsrc class and then set the EXTERNALSRC variable to point to your external source code.</p> <p>The statements to put in your local.conf file are illustrated below:</p> <pre><code>INHERIT += \"externalsrc\"\nEXTERNALSRC_pn-myrecipe = \"path-to-your-source-tree\"\n</code></pre> <p>By default, externalsrc.bbclass builds the source code in a directory separate from the external source directory as specified by EXTERNALSRC. If you need to have the source built in the same directory in which it resides, or some other nominated directory, you can set EXTERNALSRC_BUILD to point to that directory: <pre><code>EXTERNALSRC_BUILD_pn-myrecipe = \"path-to-your-source-tree\"\n</code></pre> To know the components building from external SRC, see the content of the file\u00a0../../&lt;  Project Folder &gt;/build-qemux86mc/conf/auto.conf (In case of emulator)</p>"},{"location":"source/docs/build-system/#yocto-build-types","title":"Yocto Build Types","text":""},{"location":"source/docs/build-system/#references","title":"References","text":"<ul> <li>The Yocto Project</li> <li>Yocto Developer Manual</li> <li>SystemD</li> </ul>"},{"location":"source/docs/creating-yocto-sdk/","title":"Creating Yocto SDK","text":""},{"location":"source/docs/creating-yocto-sdk/#introduction","title":"Introduction","text":"<p>Welcome to the Yocto Software Development Kit (SDK) Guide. SDK allows developers in quick development and testing during development stage. It eliminates the need of downloading &amp; setting-up of full repository environments.</p> <p>Setting a full RDK stack is also quite time consuming and requires a high end machine having good disk space and CPU power for the build process. In the other hand SDK supports following features to overcome above challenges.</p> <ul> <li>A minimal collection of tool chain, development binaries, supporting headers &amp; libraries are shipped in the form of a self extracting script.</li> <li>Allows to build any component using generic auto tool or similar build approach.</li> <li>Supports packaging so as to install the modified software in target in a easy manner while taking care of the dependencies.</li> </ul> <p>This page provides information that explains how to use both the Yocto SDK to develop images and components using the Yocto Project.\u00a0A SDK consists of the following:</p> <ul> <li>Cross-Development Toolchain     : This toolchain contains a compiler, debugger, and various miscellaneous tools.</li> <li>Libraries, Headers, and Symbols     : The libraries, headers, and symbols are specific to the image (i.e. they match the image).</li> <li>Environment Setup Script     : This *.sh file, once run, sets up the cross-development environment by defining variables and preparing for SDK use.</li> </ul> <p>We can use the standard SDK to independently develop and test code that is destined to run on some target machine.</p> <p>SDKs are completely self-contained. The binaries are linked against their own copy of libc, which results in no dependencies on the target system. To achieve this, the pointer to the dynamic loader is configured at install time since that path cannot be dynamically altered. This is the reason for a wrapper around the populate_sdk and populate_sdk_ext archives.</p> <p>Another feature for the SDKs is that only one set of cross-compiler toolchain binaries are produced per architecture. This feature takes advantage of the fact that the target hardware can be passed to gcc as a set of compiler options. Those options are set up by the environment script and contained in variables such as CC and LD. This reduces the space needed for the tools. Understand, however, that a sysroot is still needed for every target since those binaries are target-specific.</p> <p>The SDK development environment consists of the following:</p> <ul> <li> <p>The self-contained SDK, which is an architecture-specific cross-toolchain and matching sysroots (target and native) all built by the OpenEmbedded build system (e.g. the SDK). The toolchain and sysroots are based on a Metadata configuration and extensions, which allows you to cross-develop on the host machine for the target hardware. </p> </li> <li> <p>Various user-space tools that greatly enhance your application development experience. These tools are also separate from the actual SDK but can be independently obtained and used in the development process.</p> </li> </ul>"},{"location":"source/docs/creating-yocto-sdk/#the-cross-development-toolchain","title":"The Cross-Development Toolchain","text":"<p>The\u00a0Cross-Development Toolchain\u00a0consists of a cross-compiler, cross-linker, and cross-debugger that are used to develop user-space applications for targeted hardware. This toolchain is created by running a toolchain installer script or through a\u00a0Build Directory\u00a0that is based on your Metadata configuration or extension for your targeted device. The cross-toolchain works with a matching target sysroot.</p>"},{"location":"source/docs/creating-yocto-sdk/#sysroots","title":"Sysroots","text":"<p>The native and target sysroots contain needed headers and libraries for generating binaries that run on the target architecture. The target sysroot is based on the target root filesystem image that is built by the OpenEmbedded build system and uses the same Metadata configuration used to build the cross-toolchain.</p>"},{"location":"source/docs/creating-yocto-sdk/#user-space-tools","title":"User-Space Tools","text":"<p>User-space tools, which are available as part of the SDK development environment, can be helpful. The tools include LatencyTOP, PowerTOP, Perf, SystemTap, and Lttng-ust. These tools are common development tools for the Linux platform.</p> <ul> <li> <p>LatencyTOP:     \u00a0LatencyTOP focuses on latency that causes skips in audio, stutters in your desktop experience, or situations that overload your server even when you have plenty of CPU power left.</p> </li> <li> <p>PowerTOP:     \u00a0Helps you determine what software is using the most power.\u00a0</p> </li> <li> <p>Perf:     \u00a0Performance counters for Linux used to keep track of certain types of hardware and software events.\u00a0</p> </li> <li> <p>SystemTap:     \u00a0A free software infrastructure that simplifies information gathering about a running Linux system. This information helps you diagnose performance or functional problems. l.</p> </li> <li> <p>Lttng-ust:     \u00a0A User-space Tracer designed to provide detailed information on user-space activity.\u00a0</p> </li> </ul>"},{"location":"source/docs/creating-yocto-sdk/#sdk-development-model","title":"SDK Development Model","text":"<p>Fundamentally, the SDK fits into the development process as follows:</p> <p></p> <p>The SDK is installed on any machine and can be used to develop applications, images, and kernels. An SDK can even be used by a QA Engineer or Release Engineer. The fundamental concept is that the machine that has the SDK installed does not have to be associated with the machine that has the Yocto Project installed. A developer can independently compile and test an object on their machine and then, when the object is ready for integration into an image, they can simply make it available to the machine that has the Yocto Project. Once the object is available, the image can be rebuilt using the Yocto Project to produce the modified image.</p> <p>You just need to follow these general steps:</p> <ol> <li> <p>Install the SDK for your target hardware: For information on how to install the SDK, see the \"Installing the SDK\" section.</p> </li> <li> <p>Download the Target Image: The Yocto Project supports several target architectures and has many pre-built kernel images and root filesystem images. If you are going to develop your application on hardware, go to the machines\u00a0download area and choose a target machine area from which to download the kernel image and root filesystem. This download area could have several files in it that support development using actual hardware. For example, the area might contain <code>.hddimg</code> files that combine the kernel image with the filesystem, boot loaders, and so forth. Be sure to get the files you need for your particular development process.</p> </li> <li> <p>Develop and Test your Application: At this point, you have the tools to develop your application. If you need to separately install and use the emulator, you can go to Emulator to download and learn about the emulator.\u00a0</p> </li> </ol>"},{"location":"source/docs/creating-yocto-sdk/#using-the-sdk","title":"Using the SDK","text":""},{"location":"source/docs/creating-yocto-sdk/#generating-sdk","title":"Generating SDK","text":"<p>To generate SDK use the following command: <pre><code>$ bitbake  &lt;image&gt;  -c populate_sdk\n#e.g: $ bitbake\u00a0rdk-generic-broadband-image -c populate_sdk\n</code></pre> The command results in a toolchain installer that contains the sysroot that matches your target root filesystem. Another powerful feature is that the toolchain is completely self-contained. The binaries are linked against their own copy of libc, which results in no dependencies on the target system. To achieve this, the pointer to the dynamic loader is configured at install time since that path cannot be dynamically altered. This is the reason for a wrapper around the populate_sdk archive.</p> <p>Remember, before using BitBake command, you must source the build environment setup script and you must make sure yourconf/local.conf variables are correct. In particular, you need to be sure the MACHINE variable matches the architecture for which you are building and that the SDKMACHINE variable is correctly set if you are building a toolchain designed to run on an architecture that differs from your current development host machine (i.e. the build machine).</p> <p>When the bitbake command completes, the SDK will be populated in tmp/deploy/sdk location.</p>"},{"location":"source/docs/creating-yocto-sdk/#installing-sdk","title":"Installing SDK","text":"<p>The first thing you need to do is install the SDK on your host development machine by running the\u00a0 <code>*.sh</code> \u00a0installation script.</p> <p>The toolchains the Yocto Project provides are based off the\u00a0 <code>core-image-sato</code> \u00a0image and contain libraries appropriate for developing against that image. Each type of development system supports five or more target architectures.</p> <p>The names of the tarball installer scripts are such that a string representing the host system appears first in the filename and then is immediately followed by a string representing the target architecture.</p> <p><pre><code>rdk-glibc-host_system-image_type-arch-toolchain-release_version.sh\n</code></pre> Where:  - <code>host_system</code> is a string representing your development system: For e.g. <code>i686</code> or <code>x86_64</code>  - <code>image_type</code> is the image for which the SDK was built.  - <code>arch</code> is a string representing the tuned target architecture: For e.g., <code>i586</code>, <code>x86_64</code>, <code>powerpc</code>, <code>mips</code>, <code>armv7a</code> or <code>armv5te</code>  - <code>release_version</code>  is a string representing the release number of the Yocto Project: For e.g., <code>2.0</code> </p> <p>For example, the following toolchain installer is for a 64-bit development host system and a i586-tuned target architecture based off the SDK for <code>core-image-sato</code> and using the  2.1 snapshot: <pre><code>rdk-glibc-x86_64-arm-toolchain-2.0.sh\n</code></pre></p> <p>The SDK and toolchains are self-contained and by default are installed into <code>/opt/poky</code> . . However, when you run the SDK installer, you can choose an installation directory.</p> <p>Note</p> <p>You must change the permissions on the toolchain installer script so that it is executable: <pre><code>$ chmod +x rdk-glibc-x86_64-arm-toolchain-2.0.sh\n</code></pre> The following command shows how to run the installer given a toolchain tarball for a 64-bit x86 development host system and a 32-bit x86 target architecture. The example assumes the toolchain installer is located in <code>~/Downloads/</code></p> <p>RW Permissions</p> <p>If you do not have write permissions for the directory into which you are installing the SDK, the installer notifies you and exits. Be sure you have write permissions in the directory and run the installer again.</p> <pre><code>$ ./rdk-glibc-x86_64-arm-toolchain-2.0.sh \n\nRDK (A Yocto Project based Distro) SDK installer version 2.0 \n============================================================  \nEnter target directory for SDK (default: /opt/rdk/2.0): \nYou are about to install the SDK to \"/opt/rdk/2.0\". Proceed[Y/n]? Y \nExtracting SDK............................................................................done \nSetting it up...done \nSDK has been successfully set up and is ready to be used\nEach time you wish to use the SDK in a new shell session, you need to source the environment setup script e.g. \n$ . /opt/rdk/2.0/environment-setup-cortexa7t2hf-neon-vfpv4-rdk-linux-gnueabi\n</code></pre>"},{"location":"source/docs/creating-yocto-sdk/#running-the-sdk-environment-setup-script","title":"Running the SDK Environment Setup Script","text":"<p>Once you have the SDK installed, you must run the SDK environment setup script before you can actually use it. This setup script resides in the directory you chose when you installed the SDK.\u00a0</p> <p>Before running the script, be sure it is the one that matches the architecture for which you are developing. Environment setup scripts begin with the string \" <code>environment-setup</code> \" and include as part of their name the tuned target architecture. For example, the command to source a setup script for an IA-based target machine using i586 tuning and located in the default SDK installation directory is as follows:</p> <pre><code>$ source /mnt/sdk/environment-setup-cortexa7hf-neon-vfpv4-rdk-linux-gnueabi\n</code></pre> <p>When you run the setup script, many environment variables are defined:</p> <pre><code>SDKTARGETSYSROOT - The path to the sysroot used for cross-compilation\nPKG_CONFIG_PATH - The path to the target pkg-config files\nCONFIG_SITE - A GNU autoconf site file preconfigured for the target\nCC - The minimal command and arguments to run the C compiler \nCXX - The minimal command and arguments to run the C++ compiler\nCPP - The minimal command and arguments to run the C preprocessor\nAS - The minimal command and arguments to run the assembler\nLD - The minimal command and arguments to run the linker\nGDB - The minimal command and arguments to run the GNU Debugger\nSTRIP - The minimal command and arguments to run 'strip', which strips symbols \nRANLIB - The minimal command and arguments to run 'ranlib'\nOBJCOPY - The minimal command and arguments to run 'objcopy' \nOBJDUMP - The minimal command and arguments to run 'objdump'\nAR - The minimal command and arguments to run 'ar' \nNM - The minimal command and arguments to run 'nm' \nTARGET_PREFIX - The toolchain binary prefix for the target tools \nCROSS_COMPILE - The toolchain binary prefix for the target tools\nCONFIGURE_FLAGS - The minimal arguments for GNU configure\nCFLAGS - Suggested C flags\nCXXFLAGS - Suggested C++ flags\nLDFLAGS - Suggested linker flags when you use CC to link \nCPPFLAGS - Suggested preprocessor flags\n</code></pre>"},{"location":"source/docs/creating-yocto-sdk/#autotools-based-projects","title":"Autotools-Based Projects","text":"<p>Once you have a suitable cross-toolchain installed, it is very easy to develop a project outside of the OpenEmbedded build system. This section presents a simple \"Helloworld\" example that shows how to set up, compile, and run the project.</p>"},{"location":"source/docs/creating-yocto-sdk/#creating-and-running-a-project-based-on-gnu-autotools","title":"Creating and Running a Project Based on GNU Autotools","text":"<p>Create a Project Directory</p> <p>Create and enter a clean project directory</p> <pre><code>mkdir -p $HOME/helloworld\ncd $HOME/helloworld\n</code></pre> <p>Populate the Project Files</p> <p>Create the following three files in your project directory:</p> <p>hello.c</p> <pre><code>#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"Hello World!\\n\");\n    return 0;\n}\n</code></pre> <p>Makefile.am</p> <pre><code>bin_PROGRAMS = hello\nhello_SOURCES = hello.c\n</code></pre> <p>configure.in</p> <pre><code>AC_INIT(hello.c)\nAM_INIT_AUTOMAKE(hello, 0.1)\nAC_PROG_CC\nAC_PROG_INSTALL\nAC_OUTPUT(Makefile)\n</code></pre> <p>Source the Cross-Toolchain Environment</p> <p>Before building, source the environment setup script provided by your cross-toolchain SDK. This script is typically named <code>environment-setup-*</code>.</p> <p>Example:</p> <pre><code>source /opt/rdk/2.0/environment-setup-cortexa7t2hf-neon-vfpv4-rdk-linux-gnueabi\n</code></pre> <p>Create GNU Standard Files</p> <p>Create placeholder files required by GNU coding standards:</p> <pre><code>touch NEWS README AUTHORS ChangeLog\n</code></pre> <p>Generate the <code>configure</code> Script</p> <p>Run Autotools to generate the <code>configure</code> script:</p> <pre><code>autoreconf -i\n</code></pre> <p>Configure the Build (Cross-Compile)</p> <p>Use the cross-compiler to configure the build:</p> <pre><code>./configure ${CONFIGURE_FLAGS}\n</code></pre> <p>Replace <code>${CONFIGURE_FLAGS}</code> with any required options specific to your target platform.</p> <p>Build and Install the Project</p> <p>Compile and install the project locally:</p> <pre><code>make\nmake install DESTDIR=./tmp\n</code></pre> <p>The binary will be installed to <code>./tmp/usr/local/bin/hello</code>.</p> <p>Verify the Installation</p> <p>Check the binary to ensure it's built for the correct architecture:</p> <pre><code>file ./tmp/usr/local/bin/hello\n</code></pre> <p>Run the Project</p> <p>Run the binary (either locally or on the target device):</p> <pre><code>./hello\n</code></pre> <p>Expected output:</p> <pre><code>Hello World!\n</code></pre>"},{"location":"source/docs/creating-yocto-sdk/#passing-host-options","title":"Passing Host Options","text":"<p>For an Autotools-based project, you can use the cross-toolchain by just passing the appropriate host option to\u00a0<code>configure.sh</code> . The host option you use is derived from the name of the environment setup script found in the directory in which you installed the cross-toolchain. For example, the host option for an ARM-based target that uses the GNU EABI is  <code>armv5te-poky-linux-gnueabi</code> . You will notice that the name of the script is <code>environment-setup-armv5te-poky-linux-gnueabi</code> . Thus, the following command works to update your project and rebuild it using the appropriate cross-toolchain tools:</p> <pre><code>$ ./configure --host=arm-rdk-linux-gnueabi --prefix=/usr --with-libtool-sysroot=sysroot_dir\n</code></pre> <p>Note</p> <p>If the\u00a0<code>configure</code> \u00a0script results in problems recognizing the <code>--with-libtool-sysroot=</code><code>sysroot-dir</code> \u00a0option, regenerate the script to enable the support by doing the following and then run the script again</p> <pre><code>$ libtoolize --automake\n$ aclocal -I ${OECORE_NATIVE_SYSROOT};/usr/share/aclocal   [-I dir_containing_your_project-specific_m4_macros]\n$ autoconf\n$ autoheader\n$ automake -a\n</code></pre>"},{"location":"source/docs/creating-yocto-sdk/#makefile-based-projects","title":"Makefile-Based Projects","text":"<p>For Makefile-based projects, the cross-toolchain environment variables established by running the cross-toolchain environment setup script are subject to general\u00a0<code>make</code> \u00a0rules.</p> <p>To illustrate this, consider the following four cross-toolchain environment variables: <pre><code>CC=i586-poky-linux-gcc -m32 -march=i586 --sysroot=/opt/poky/2.1/sysroots/i586-poky-linux\nLD=i586-poky-linux-ld --sysroot=/opt/poky/2.1/sysroots/i586-poky-linux\nCFLAGS=-O2 -pipe -g -feliminate-unused-debug-types\nCXXFLAGS=-O2 -pipe -g -feliminate-unused-debug-types\n</code></pre> Now, consider the following three cases:</p> <ul> <li> <p>Case 1 - No Variables Set in the <code>Makefile</code>:     Because these variables are not specifically set in the <code>Makefile</code> , the variables retain their values based on the environment.</p> </li> <li> <p>Case 2 - Variables Set in the\u00a0<code>Makefile</code> :      Specifically setting variables in the <code>Makefile</code> during the build results in the environment settings of the variables being overwritten.</p> </li> <li> <p>Case 3 - Variables Set when the\u00a0<code>Makefile</code> is Executed from the Command Line:     \u00a0Executing the\u00a0<code>Makefile</code> from the command line results in the variables being overwritten with command-line content regardless of what is being set in the <code>Makefile</code> . In this case,  environment variables are not considered unless you use the \"-e\" flag during the build: <pre><code>$ make -e file\n</code></pre> If you use this flag, then the environment values of the variables override any variables specifically set in the <code>Makefile</code></p> </li> </ul>"},{"location":"source/docs/how-to-contribute/","title":"How to Contribute","text":""},{"location":"source/docs/how-to-contribute/#before-you-contribute","title":"Before You Contribute","text":"<p>In order to contribute code, first-time users are requested to agree to the license at\u00a0RDK Central Wiki. As an unaffiliated individual, you must sign the  CLA . You can complete that process online.</p>"},{"location":"source/docs/how-to-contribute/#what-is-a-cla","title":"What is a CLA?","text":"<p>The Contributor License Agreement is necessary mainly because you own the copyright to your changes, even after your contribution becomes part of our codebase, so we need your permission to use and distribute your code. We also need to be sure of various other things \u2014 for instance that you\u2018ll tell us if you know that your code infringes on other people\u2019s patents.</p> <p>You don\u2018t have to sign the CLA until after you\u2019ve submitted your code for review and a member has approved it, but you must do it before we can put your code into our codebase. Before you start working on a larger contribution, get in touch with us to discuss your idea so that we can help out and possibly guide you. Early coordination makes it much easier to avoid frustration later on.</p>"},{"location":"source/docs/how-to-contribute/#code-reviews","title":"Code Reviews","text":"<p>All submissions, including submissions by project members, require review. We use both Gerrit ( Gerrit Code Review ) and Github ( Github Code Review ) depending on where the repo is hosted. Currently, team-member submissions are reviewed privately, and external submissions go through public reviews.</p>"},{"location":"source/docs/how-to-contribute/#code-submission-process","title":"Code Submission Process","text":"<p>The following steps explain the submission process:</p> <ul> <li>Ensure you or your company have signed the appropriate CLA as discussed in the     \u00a0     Before You Contribute     \u00a0     section above.</li> <li>Rebase your changes down into a single git commit.</li> <li>Run     \u00a0     <code>git push command</code>     \u00a0     to upload the review to     \u00a0     code.rdkcentral     .</li> <li>Someone from the maintainers team reviews the code, adding comments on any things that need to change before the code can be submitted.</li> <li>If you need to make changes, make them locally, test them, then     \u00a0     <code>git commit \u00a0 -- amend</code>     \u00a0     to add them to the     \u00a0     existing     \u00a0     commit. Then return to step 2.</li> <li>If you do not need to make any more changes, a maintainer integrates the change into our private repository, and it is pushed out to the public repository after some time.</li> </ul>"},{"location":"source/docs/how-to-contribute/#contributor-license-agreement-cla-rdk-central-github","title":"Contributor License Agreement (CLA) - RDK Central Github","text":"<p>The RDK CLA facilitates the acceptance and sharing of RDK contributions within the community.</p> <p>When you contribute to an RDK open source project on GitHub via a new pull request, a bot will evaluate whether you have signed the CLA. The bot will comment on the pull request, including a link to accept the agreement.</p> <p>CLA assistant enables contributors to sign CLAs from within a pull request. The CLA is stored as a GitHub Gist file and linked with the repository/organization in CLA assistant.</p>"},{"location":"source/docs/how-to-contribute/#cla-assistant","title":"CLA assistant","text":"<ul> <li>Comments on each opened pull request to ask the contributor to sign the CLA.</li> <li>Allows contributors to sign a CLA from within a pull request.</li> <li>Authenticates the signee with his or her GitHub account.</li> <li>Updates the status of a pull request when the contributor agrees to the CLA.</li> <li>Automatically asks users to re-sign the CLA for each new pull request in the event the associated Gist &amp; CLA has changed.</li> <li>Repository owners can review a list of users who signed the CLA for each version of it.</li> </ul> <p>Note - CLA assistant is provided by SAP as a free hosted offering under:\u00a0 cla-assistant.io </p>"},{"location":"source/docs/how-to-contribute/#code-contribution-process","title":"Code Contribution Process","text":""},{"location":"source/docs/how-to-contribute/#code-contribution-workflow","title":"Code Contribution Workflow","text":"<p>The Code Contribution Workflow is designed to facilitate community involvement in the development of RDK components. The structured process ensures that contributions are reviewed, validated and integrated effectively, maintaining high standards of quality throughout.</p>"},{"location":"source/docs/how-to-contribute/#branch-overview","title":"Branch Overview","text":"<ol> <li> <p>Product Branch</p> <ul> <li>The Product Branch is a deployment-ready branch where the community submits changes for review. This branch serves as the main integration point for code that meets rigorous testing qualifications.</li> <li>For more information on the components hosted in the product branch, refer to the CMF Gerrit and the RDK Central GitHub repository.</li> </ul> </li> <li> <p>Monthly Sprint Branch (rdk-dev-yymm)</p> <ul> <li>Created monthly as a new CMF integration branch, this branch is based on the product branch.</li> <li>It is hosted per repository and aims to incorporate community changes as early as possible.</li> <li>Once community changes are approved, they will be cherry-picked to the monthly sprint branch, making them available before the final down-streaming to the regression branch.</li> </ul> </li> <li> <p>Regression Branch</p> <ul> <li>This branch is used for validating contributions.</li> <li>Approved changes are down-streamed here for pre-deployment validation through the established testing process.</li> <li>Defects and features will be planned in monthly sprints, with timelines published to contributors.</li> <li>Contributions pending validation will be available in monthly development iteration branches.</li> </ul> </li> </ol>"},{"location":"source/docs/how-to-contribute/#contribution-process","title":"Contribution Process","text":"<ul> <li>Users will make code contributions to the rdk-next branch. This process includes:<ul> <li>Code reviews</li> <li>Build verification</li> <li>License compliance scans</li> <li>Test validation</li> </ul> </li> <li>Once the changes are successfully validated, changes are cherry-picked to the monthly sprint branch (rdk-dev-yymm).</li> <li>These changes are then down-streamed to the regression branch for further pre-deployment testing.</li> <li>After successful validation, the changes are cherry-picked to the product branch, completing the integration into the main deployment-ready branch.</li> </ul> <p>Component owners/reviewers/approvers, defined as specific groups in Gerrit, will be added to the review by default. You may request additional feedback by specifically adding reviewers via the Gerrit web GUI.\u00a0</p>"},{"location":"source/docs/how-to-contribute/#development-workflow","title":"Development Workflow","text":"<p>This section describes the general RDK development work-flow and related topics. The general pattern for successfully accepting a change is as follows:</p> <ul> <li>Discuss on mailing list to get general consensus about approach.</li> <li>Pull latest code.</li> <li>Build on your supported platform.</li> <li>Develop features or fix bugs following     \u00a0     RDK Coding standards     .</li> <li>Submit to Gerrit for review.</li> <li>Review and respond to reviewer comments.</li> <li>Change accepted and merged.</li> </ul> <p>For a detailed step by step description, please refer:\u00a0Gerrit Development Workflow .</p>"},{"location":"source/docs/how-to-contribute/#code-management-facility-cmf","title":"Code Management Facility (CMF)","text":"<p>On a periodic basis, RDK code is tested and released to the community as \u00a0 CMF releases . This will be generic RDK code without dependency to any platform. CMF code can be built for \u00a0 raspberry-pi \u00a0 or can be ported to a specific platform ( RDK Porting ). And once the component owner approves this change, it will be available to the community in RDK central.</p>"},{"location":"source/docs/how-to-contribute/#cmf-contributions","title":"CMF Contributions","text":"<p>While working with CMF stack, one might find ways to enhance RDK code by adding new features or bug fixes as RDK contribution. The general CMF contribution workflow is as follows:</p> <p></p> <p>Detailed information on contributing code changes to RDK can be found here:\u00a0 Code Management Documentation</p>"},{"location":"source/docs/how-to-contribute/#getting-support","title":"Getting Support","text":"<p>Support tickets can be raised to get request support from RDK Community Support team. This can be for the bugs you face, doubts you have or any code contributions which you think might enhance RDK. RDK Support ticket can be raised here: support@rdkcentral .</p>"},{"location":"source/docs/how-to-contribute/#jira-guidelines","title":"JIRA Guidelines","text":""},{"location":"source/docs/how-to-contribute/#where-to-create-a-jira-ticket","title":"Where to Create a JIRA ticket","text":"<ul> <li>Log in to JIRA\u00a0     jira.rdkcentral     \u00a0using rdkcentral credentials</li> <li>Create a JIRA ticket under     RDKDEV     (for Video) or     RDKBDEV     (for Broadband).</li> <li>Click on the Create button</li> </ul> <p>A Snap shot for how to create a JIRA.</p> <p></p>"},{"location":"source/docs/how-to-contribute/#jira-guideline-for-patches-contributions","title":"JIRA Guideline for Patches Contributions","text":"<p>Issue type corresponds to the type of contributions we are making. The following issue types can be possible for patches contribution \u221a Incident - Build failure incident issues with the code verification steps such as Black duck scan, Jenkins verification etc. \u221a Bug - Bugs in existing component code. To report a bug, users must create a ticket with type Bug and provide as much information as possible, including:</p> <ul> <li>A clear and concise description of the bug</li> <li>Steps to reproduce the bug</li> <li>The expected behavior</li> <li>The actual behavior</li> <li>Any relevant screenshots, logs or videos</li> </ul> <p>\u221a Task - An individual task which may be part of enhancement of existing feature, etc. \u221a\u00a0Improvement - Improvements such as code refactoring or enhancements in current code.</p> <p>Summary and Descriptions are mandatory fields need to be filled.</p> <p>Click on Create button to Create a new JIRA. Sample example is provided below.</p> <p></p> <p>Note: To know more about how to refresh the patches click\u00a0here .</p>"},{"location":"source/docs/how-to-contribute/#jira-guideline-for-new-feature-contribution","title":"JIRA Guideline for New Feature Contribution","text":"<p>A feature contribution should follow after creating an appropriate JIRA project. This will present a clear picture about the architecture, testing details and other information which will be helpful during the acceptance process of the contribution.</p>"},{"location":"source/docs/how-to-contribute/#mandatory-information","title":"Mandatory information","text":""},{"location":"source/docs/how-to-contribute/#project","title":"Project","text":"<pre><code>For Video &amp; build system (Yocto) related contributions, the ticket should be created under RDKDEV. For broadband, the ticket should be created under RDKBDEV project.\n</code></pre>"},{"location":"source/docs/how-to-contribute/#issue-type","title":"Issue Type","text":"<pre><code>\u221a\u00a0New feature - New feature contributions.\n</code></pre>"},{"location":"source/docs/how-to-contribute/#ticket-status","title":"Ticket Status","text":"<pre><code>Status should be initially Open, and transitioned to the appropriate value while the contribution is being worked on.\n</code></pre>"},{"location":"source/docs/how-to-contribute/#summary","title":"Summary","text":"<p>A brief summary about what we are trying to contribute\u00a0</p>"},{"location":"source/docs/how-to-contribute/#description","title":"Description","text":"<p>A descriptive information about the contribution should be present so that component developers &amp; architecture team can do assessment of the feature. Below details are desirable if the contribution is a new feature or having an significant impact on the current architecture.</p> <p><pre><code>Brief introduction on what the current system lacks &amp; what needs to be done:\n1. Individual task/highlighted point \\#1 brief description.\n2. Individual task/highlighted point \\#2 brief description.\n</code></pre> <pre><code>The following items should be considered/addressed in the documentation for any RDK design initiative\nJIRA Update Checklist\n-----------------------\nThe following JIRA fields MUST be filled in to be considered \"Definition Complete\":\n\\* RDK SoC, RDK OEM - populate these fields for any user story where we have dependency on OEM and/or SoC to perform work in the completion of this user story. Select all that apply, or \u201cNone\u201d if there is no dependency.\n\\* OEM/SoC Impact Details - description of impact (or \"see Solution Overview\" if included in the architecture specification)\n\\* Platforms - ensure correct list of devices\n\\* Validation - type of testing\n\\* Regression - is regression required?\n\\* Dependency - Internal/External\n\\* Description - Solution Overview and Architecture Checklist\nTesting impact/Guidance\n------------------------\n\\* Impacted modules\n\\* Test process\nAutomated Testing\n------------------\n\\* Automation test procedure.\nDiagnostics, Telemetry and Logging\n-----------------------------------\n\\* N/A\nOutbound Network Connections\n------------------------------\n\\* Does this component make outbound connection requests?\n\\* If yes, do the connection requests retry in the case of failure?\n\\*\\* Do the repeated requests use an exponential back-off?\n\\*\\* If a maximum back-off has been defined, is it greater than 10 minutes?\nSecurity\n----------\n\\* For Security Review - Do feature elements:\n\\*\\* make any changes to network port assignments?\n\\*\\* change iptables rules?\n\\*\\* require credentials, passwords, secret data?\n\\*\\* make any changes to our network connections?\n\\*\\* connect to new services or servers?\n\\*\\* use data input from users or external tools?\n\\*\\* use any cryptographic functions?\n\\*\\* create or disclose proprietary or sensitive Co. or device data?\n\\*\\* properly log operational and configuration changes?\n\\*\\* If possible describe what could happen if feature elements are:\n\\*\\*\\* spoofed?\n\\*\\*\\* tampered with?\n\\*\\*\\* used by an unauthorized actor?\n\\*\\* Advanced questions (optional)\n\\*\\*\\* what happens if a record of actions taken is destroyed?\n\\*\\*\\* what happens if an attacker attempts to DOS with the feature?\nSI Concerns\n-------------\n\\* Yes/No/Any\nPerformance expectations\n-------------------------\n\\* Yes/No/Any\nTiming consideration\n----------------------\n\\* If Any.\n</code></pre></p>"},{"location":"source/docs/how-to-contribute/#supplementary-information","title":"Supplementary Information","text":"<ol> <li>Impacted component(s) - Fill in list of impacted RDK components</li> <li>RDK SI Impact - System Integration impacts</li> <li>CPE SW Components - Component names.</li> <li>Test Notes - Describe what tests are performed to validate this contribution and the procedure.</li> <li>Unit Test Result - Description.</li> </ol>"},{"location":"source/docs/how-to-contribute/#code-submission-process-rdk-central-gerrit","title":"Code Submission Process - RDK Central Gerrit","text":"<p>In order to contribute code, first-time users are requested to agree to the license at wiki.rdkcentral .</p> <p>RDK components are hosted at\u00a0 code.rdkcentral . You can submit your code changes for review via that site using the workflow outlined below.</p>"},{"location":"source/docs/how-to-contribute/#create-a-jira-ticket","title":"Create a JIRA ticket","text":"<ul> <li>Refer to\u00a0 JIRA Guidelines for creating a JIRA before pushing your code changes in rdkcentral.</li> </ul>"},{"location":"source/docs/how-to-contribute/#clone-the-repository","title":"Clone the Repository","text":"<p>Clone the component repository from the Gerrit server code.rdkcentral\u00a0into a local workspace</p> <p>Clone with commit-msg hook \u00a0(to add Change-ID footer to commit messages)</p> <pre><code>git clone\u00a0https://code.rdkcentral.com/r/&amp;lt;component-name&amp;gt;\u00a0&amp;lt;component-name&amp;gt; -b &amp;lt;branch-name&amp;gt;\ncd &amp;lt;component-name&amp;gt;\ngitdir=$(git rev-parse --git-dir); curl -o $&amp;#123;gitdir&amp;#125;/hooks/commit-msg https://code.rdkcentral.com/r/tools/hooks/commit-msg ; chmod +x $&amp;#123;gitdir&amp;#125;/hooks/commit-msg\n</code></pre> <p>Click here to find the details about  &amp;  for code submission. <p>**Note:\u00a0** The commit-msg hook is installed in the local Git repository and is a prerequisite for Gerrit to accept commits. The inclusion of the unique Change-ID in the commit message allows Gerrit to automatically associate a new version of a change back to its original review.</p> <p>Note: \u00a0You may need to configure your Git identity on the cloned repository. The email address that your local Git uses should match the email address listed in Gerrit.</p> <p>Example commands to run are as follows:</p> <pre><code>$ git config user.name \"John Doe\"\n$ git config user.email \"john.doe@example.org\"\n</code></pre>"},{"location":"source/docs/how-to-contribute/#work-on-the-change-commit-to-local-clone","title":"Work on the change, commit to local clone","text":"<p>Each commit constitutes a change in Gerrit and must be approved separately. It is recommended to squash several commits into one that represents a change to the project.</p> <p>If necessary, it is possible to squash a series of commits into a single commit before publishing them, using interactive rebase:</p> <pre><code>$ git rebase --interactive\n</code></pre> <p>It is important to preserve the\u00a0 Change-Id \u00a0line when editing and there should only be one \"pick\" entry at the end of this process. The end result is to submit one change to Gerrit.</p>"},{"location":"source/docs/how-to-contribute/#push-the-new-changes-for-gerrit-for-review","title":"Push the new changes for Gerrit for review","text":"<p>Commits will be BLOCKED if the format of the commit message does not comply with the standard. You will see a warning as to why the commit was blocked.</p> <p>Mandatory Information in Commit Message</p> <ol> <li>Associated JIRA ticket (Following the Guideline to create a JIRA)</li> <li>Reason for change information</li> <li>Test procedure by which change can be verified</li> <li>Possible risks of failure</li> </ol> <pre><code>$ git commit --amend\n</code></pre> <p> <pre><code>&amp;lt;JIRA TICKET \\#1&amp;gt;, &amp;lt;JIRA TICKET \\#2&amp;gt;, &amp;lt;JIRA TICKET \\#n&amp;gt; : &amp;lt;one line summary of change&amp;gt;\n&amp;lt;empty line&amp;gt;\nReason\u00a0for\u00a0change: &amp;lt;explanation of change&amp;gt;\nTest Procedure: &amp;lt; test procedure&amp;gt;\nRisks: &amp;lt;side effects and other considerations&amp;gt; [Note: state None\u00a0if\u00a0there are no other considerations]\n&amp;lt;empty line&amp;gt;\nSigned-off-by: Your Name &amp;lt;your_name@email.com&amp;gt;\n</code></pre> <p>Submit your code changes for review</p> <pre><code>$ git push origin HEAD:refs/for/&amp;lt;branch&amp;gt;\n</code></pre> <p>When interfacing with Gerrit you push to a virtual branch /refs/for/&lt;branch&gt;, representing \"code review before submission to branch\". Gerrit will subsequently assign a unique URL for the change, to facilitate access and review via the web UI.</p> <p>Notes: </p> <ul> <li>HEAD \u00a0is a Git symbolic reference to the most recent commit on the current branch. When you change branches,\u00a0 HEAD \u00a0is updated to refer to the new branch's latest commit.</li> <li>The\u00a0 refspec \u00a0in the git push operation takes the form\u00a0 source:destination \u00a0( source \u00a0is the local ref being pushed,\u00a0 destination is the remote ref being updated).</li> </ul>"},{"location":"source/docs/how-to-contribute/#review-notifications-and-addition-of-new-reviewers","title":"Review notifications and addition of new reviewers","text":"<p>Component owners/reviewers/approvers, defined as specific groups in Gerrit, will be added to the review by default. You may request additional feedback by specifically adding reviewers via the Gerrit web GUI.\u00a0</p>"},{"location":"source/docs/how-to-contribute/#scan-and-build-on-code-submission","title":"Scan and build on code submission","text":"<p>BlackDuck, copyright scanning and build jobs will be triggered automatically from CMF Jenkins. The output of these jobs is integrated into the Gerrit voting process via custom labels and will reflect any 'red flag' in a file that has new code changes, whether introduced in the new change/patch-set or not. Scans will post any findings as comments in the Gerrit review. Build jobs also do that, but in addition will upload the build log to the corresponding JIRA ticket (if there is one) as an attachment.</p>"},{"location":"source/docs/how-to-contribute/#code-review-and-scoring-process","title":"Code review and scoring process","text":"<p>Reviewers can comment on and score a given change. The default set of rules for enabling a code change for submission requires:</p> <ul> <li>a Code Review score of +2; this can only be provided by the component owner or an admin;</li> <li>+1 score on any mandatory Gerrit labels configured for the project.</li> </ul> <p>The result of the scoring process and validation rules is to enable the\u00a0 Submit \u00a0action on the Gerrit Web UI and subsequent merge capability to the target branch.</p> <p>Label: Code Review (Highlighted in yellow color) \u00a0For a change to be mergeable, the latest patch set must have a '+2' value approval in this category or label, and no '-2 Do not submit'. Thus -2 on any patch set can block a submit, while +2 on the latest patch set enables it for merging.</p> <p>Labels: Blackduck/Copyright/Component-Build (Highlighted in yellow color) \u00a0For a change to be mergeable, the change must have a '+1' score on these labels, and no '-1 Fails'. Thus, '-1 Fails' can block a submit, while '+1' enables a submit.</p> <p></p>"},{"location":"source/docs/how-to-contribute/#submit-code-change","title":"Submit code change","text":"<p>Only authorized users, i.e. component owners, component approvers or admins, can submit the change allowing Gerrit to merge it to the target branch as soon as possible. A change can be submitted, having satisfied the approval conditions described earlier, by clicking the 'Submit Patch Set n' button within the Gerrit UI.\u00a0When a change has been Submitted, it is automatically merged to the target branch by Gerrit.</p>"},{"location":"source/docs/how-to-contribute/#abandon-change","title":"Abandon change","text":"<p>Depending on the review outcome, it might be decided to abandon the change. The component owner or an authorised user may abandon the change by clicking the \"Abandon Change\" button. The abandoned changes are not removed from the Gerrit database and can be restored at a later stage.</p>"},{"location":"source/docs/how-to-contribute/#submitted-merge-pending","title":"Submitted, Merge Pending","text":"<p>If a change depends on another change that is still in review, it will enter this state. It will be merged automatically by Gerrit once all its dependencies are submitted and merged.</p>"},{"location":"source/docs/how-to-contribute/#change-needs-to-be-reworked","title":"Change needs to be reworked","text":"<p>If you need to rework a change, you need to push another commit with the same\u00a0 Change-ID \u00a0as the original in its commit message. This is the mechanism Gerrit uses to associate or link the two items. The <code>--amend</code> option to the Git commit command prevents a new\u00a0 Change-ID \u00a0being generated by the\u00a0 commit-msg \u00a0hook.</p> <p>The basic steps are outlined below.</p> <p>First, fetch the change. If you still have the checkout that was used to push the original change, you can skip this step.</p> <pre><code>$ git fetch\u00a0https://user@code.rdkcentral.com/r/component1\u00a0refs/changes/02/2/1 &amp;&amp; git checkout FETCH_HEAD\n</code></pre> <p>where the numbering scheme for fetching the changes is as follows:</p> <p>refs/changes/&lt;last two digits of change number&gt; &lt;change number&gt; &lt;patch set number&gt;</p> <p></p> <p>Next, make any necessary source changes, and do:</p> <pre><code>$ git commit --amend\n$ git push origin HEAD:refs/for/&amp;lt;branch&amp;gt;\n</code></pre> <p>A new patch set is now appended to the Gerrit review item, and this will go through the same review process as before.</p>"},{"location":"source/docs/how-to-contribute/#gerrit-merge-failure-as-a-result-of-a-conflict","title":"Gerrit merge failure as a result of a conflict","text":"<p>Essentially this means that the remote branch has evolved since this change was started and now software conflicts with changes in the remote branch. The developer must resolve the merge conflicts in their local clone and then push another patch-set. The process is resumed at step 4, with the important distinction of committing with the --amend option, once the developer pulls the latest changes.\u00a0 Note: \u00a0A summary of the steps involved, assuming the local branch still exists:\u00a0</p> <p>Rebase the local branch to the latest state of origin/&lt;branch&gt;;Resolve all conflicts; Commit with the <code>--amend</code> option; Push changes to Gerrit for review. After this change a new patch set is created for the change.</p> <p>Note: If the local branch no longer exists, the steps are as follows:</p> <pre><code>$ git fetch\u00a0https://user@code.rdkcentral.com/r/rdk_component_1\u00a0refs/changes/58/58/2 &amp;&amp; git checkout FETCH_HEAD\n$ git rebase origin/&amp;lt;branch&amp;gt;\n[Edit the conflicting file, cleaning up the &amp;lt;&amp;lt;&amp;lt;&amp;lt;, ==== &amp;gt;&amp;gt;&amp;gt; markers surrounding the conflicting lines]\n$ git add &amp;lt;file&amp;gt;\n$ git commit --amend\n$ git push origin HEAD:refs/for/&amp;lt;branch&amp;gt;\n</code></pre>"},{"location":"source/docs/how-to-contribute/#rdk-components-product-branch","title":"RDK Components - Product Branch","text":"<p>Following RDK components are hosted at\u00a0 code.rdkcentral . Follow the Instructions to submit your code changes.</p> <p>Example of how to use git clone for meta-rdk-ext component:\u00a0 git clone https://code.rdkcentral.com/r/plugins/gitiles/rdk/components/generic/rdk-oe/meta-rdk-ext \u00a0-b rdk-next</p> <p>List of open-sourced and licensed repositories hosted in RDK central gerrit can be found from Source Code Repositories .</p>"},{"location":"source/docs/how-to-contribute/#code-submission-process-rdk-central-github","title":"Code Submission Process - RDK Central GitHub","text":""},{"location":"source/docs/how-to-contribute/#introduction","title":"Introduction","text":"<p>GitHub is a Git repository hosting service, but it adds many of its own features. While Git is a command line tool, GitHub provides a Web-based graphical interface.</p> <p>GitHub Enterprise is the on-premises version of GitHub and is available on VMware, AWS, and OpenStack KVM, on your own servers or in a private cloud. GitHub Enterprise operates on your infrastructure with your existing information security controls from firewalls and VPNs, to IAM and monitoring systems.</p> <p>CMF GitHub Organizations</p> <p>There is one primary RDKM Code Management organizations, namely RDKcentral. This organization hosts the open-source repositories for projects pertaining to RDK-V, RDK-B and RDK-C profiles.</p> <ul> <li>github/rdkcentral</li> </ul>"},{"location":"source/docs/how-to-contribute/#rdk-central-github-components","title":"RDK Central GitHub Components","text":"<p>Please refer to this link to see all the repositories\u00a0 Source Code Repositories .</p>"},{"location":"source/docs/how-to-contribute/#github-pull-requests","title":"GitHub Pull Requests","text":"<p>Pull requests let you tell others about changes you've pushed to a branch in a repository on GitHub. Once a pull request is opened, you can review the potential changes with collaborators and add follow-up commits before your changes are merged into the base branch. Anyone with read permissions to a repository can create a pull request, but you must have write permissions to create a branch. If you want to create a new branch for your pull request and don't have write permissions to the repository, you can fork the repository first. Pull requests can only be opened between two branches that are different.</p>"},{"location":"source/docs/how-to-contribute/#github-fork","title":"GitHub Fork","text":"<p>A \u2018fork\u2019 is a personal copy of another user's repository that lives on your GitHub account. Forks allow you to freely make changes to a project without affecting the original. A forked project also remains attached to the original, allowing you to submit a pull request to the original's author to update with your changes, ensuring you\u2019re always working off a recent or up-to-date codebase.</p>"},{"location":"source/docs/how-to-contribute/#github-workflow-steps","title":"GitHub Workflow Steps","text":"<ul> <li>Create a Fork by simply clicking on the 'fork' button of the repository page on GitHub.</li> <li>Clone your Fork, the clone command creates a local git repository from your remote fork on GitHub.</li> <li>git clone\u00a0     https://github.com/USERNAME/REPOSITORY.git</li> <li>Modify the Code in your local clone and commit the changes to your local clone using the git commit command.</li> <li>Push your Changes by invoking the git push command, from your workspace, to upload your changes to your remote fork on GitHub.</li> <li>Create a Pull Request by clicking the 'pull request' button on the GitHub page of your remote fork.</li> </ul>"},{"location":"source/docs/how-to-contribute/#configure-your-github-access-token","title":"Configure your Github access token","text":"<p>In the recent past support for direct password authentication was removed from Github. You will need to generate a Github personal token to push your code changes RDK Central Github.</p> <p>To create your personal token, you have to go to github.com -&gt; Settings -&gt; Developer Settings -&gt; Personal Access Token -&gt; Generate New Token.</p> <p>Note - While creating a new token, it will ask for Github configuration options selection \u2013 Select everything.</p> <p>Once the Github token is generated successfull, you will need to add an entry an entry to the ~/.netrc file OR you can directly use this token as your Github password in the command line to push the code changes.</p> <p>Example: how to add Github credential on ~/.netrc file <pre><code>machine\n[github.com](http://github.com)\nlogin your-github-handle-name password ghp_BCy09kNYxg82no6OnliSJQVngGi9K1234567\n</code></pre></p>"},{"location":"source/docs/how-to-contribute/#github-protected-branches","title":"GitHub Protected Branches","text":"<p>Protected branches ensure that collaborators on your repository cannot make irrevocable changes to branches. Enabling protected branches also allows you to enable other optional checks and requirements, like required status checks and required reviews.</p> <p>A custom CMF branch protection scheme is deployed in each repository in order to enforce the desired workflows. This scheme imposes the following rules:</p> <ul> <li>Require pull request reviews before merging</li> <li>Require status checks to pass before merging<ul> <li>blackduck</li> <li>copyright</li> <li>license/cla</li> <li>component-build</li> </ul> </li> </ul> <p>Required status checks ensure that all required CI tests are passing before collaborators can make changes to a protected branch. Status checks are based on external processes, such as continuous integration builds, code compliance scanning, which run for each push you make to a repository. You can see the pending, passing, or failing state of status checks next to individual commits in your pull request.</p>"},{"location":"source/docs/how-to-contribute/#contributor-license-agreement-cla","title":"Contributor License Agreement (CLA)","text":"<p>The RDK CLA facilitates the acceptance and sharing of RDK contributions within the community.</p> <p>When you contribute to an RDK open source project on GitHub via a new pull request, a bot will evaluate whether you have signed the CLA. The bot will comment on the pull request, including a link to accept the agreement.</p> <p>CLA assistant enables contributors to sign CLAs from within a pull request. The CLA is stored as a GitHub Gist file and linked with the repository/organization in CLA assistant.</p> <p>CLA assistant:</p> <ul> <li>Comments on each opened pull request to ask the contributor to sign the CLA</li> <li>Allows contributors to sign a CLA from within a pull request</li> <li>Authenticates the signee with his or her GitHub account</li> <li>Updates the status of a pull request when the contributor agrees to the CLA</li> <li>Automatically asks users to re-sign the CLA for each new pull request in the event the associated Gist &amp; CLA has changed</li> <li>Repository owners can review a list of users who signed the CLA for each version of it.</li> </ul> <p>Note - CLA assistant is provided by SAP as a free hosted offering under:\u00a0 cla-assistant.io</p>"},{"location":"source/docs/how-to-contribute/#compliance-scanning","title":"Compliance Scanning","text":"<p>CMF uses BlackDuck (Protex) to check incoming contributions for license compliance. BlackDuck is normally a very manual tool but a significant level of automation has been developed by the team to reduce manual intervention, but it still requires a human to oversee it.</p> <p>Compliance scanning is looking for several things:</p> <ul> <li>Addition of source code with a conflicting license (e.g. LGPL code in an Apache component).</li> <li>Modification of an opensource component with code of a conflicting license.</li> <li>Incorrect or proprietary copyright attribution.</li> </ul> <p>The key points are as follows:</p> <ul> <li>Scan contribution in GitHub Pull Request.</li> <li>Scan is automatically triggered by a webhook.</li> <li>Results in scan of the contribution only, i.e. only the changes.</li> <li>Required Status Check, associated with the Blackduck scan is updated.</li> <li>Summary of the scan including any code matches are provided via a link to an associated Gist.</li> </ul> <p>OSS Engineer and interested parties are notified of scan failures (violations, pending identifications or reviews etc) via AWS Mailing list and Slack.</p>"},{"location":"source/docs/how-to-contribute/#git-secrets-scanning","title":"git-secrets Scanning","text":"<p>git-secrets is a tool created by AWS Labs that scans commits and commit messages and aims to prevent passwords and other sensitive information being committed to a git repository. The tool can also scan files or folders to look for secrets such as an AWS Access Key ID and AWS Secret Access Keys in a repository. git-secrets scans commits, commit messages, and merge commits to prevent adding secrets into your git repositories. If a commit, commit message, or any commit in merge history matches one of the configured prohibited regular expression patterns, then the commit is rejected.</p>"},{"location":"source/docs/how-to-contribute/#example-of-how-to-push-the-code-changes","title":"Example of how to push the code changes","text":""},{"location":"source/docs/how-to-contribute/#step-1-fork-the-component-from-github","title":"Step 1: Fork the component from GitHub","text":"<p>Sign-in to GitHub with your own credentials.</p> <p>Search for the Component.</p> <p>Fork the component from GitHub. Forking will create a copy (i.e., your own WORKSPACE) of an original component to work.</p> <p></p>"},{"location":"source/docs/how-to-contribute/#step-2-creating-a-new-branch","title":"Step 2: Creating a new Branch","text":"<p>From the file tree view on the left, select the \u00a0 branch dropdown menu, In the \"Find or create a branch...\" text field, type a unique name for your new branch, then click \u00a0 Create branch .</p> <p></p>"},{"location":"source/docs/how-to-contribute/#step-3-clone-the-component-with-new-branch","title":"Step 3: Clone the Component with new branch","text":"<p>Click on the \"Clone or download\" button to get the clone URL from GitHub. Ensure your GitHub username present in the URL to start work with your own workspace.</p> <p></p> <pre><code>abcd123@dvm-yocto4-docker-abcd123:~/builds/meta_wan$ git clone https://github.com/Sukanya673/meta-rdk-wan.git -b new_branch_1\nCloning into 'meta-rdk-wan'...\nremote: Enumerating objects: 276, done.\nremote: Counting objects: 100% (117/117), done.\nremote: Compressing objects: 100% (71/71), done.\nremote: Total 276 (delta 95), refused 47 (delta 41), pack-reused 159 (from 1)\nReceiving objects: 100% (276/276), 59.05 kiB | 2.68 MiB/s, done.\nResolving deltas: 100% (141/141), done.\nabcd123@dvm-yocto4-docker-abcd123:~/builds/meta_wan$\n</code></pre>"},{"location":"source/docs/how-to-contribute/#step-4-work-on-changes-and-gerrit-commands-to-push-the-changes","title":"Step 4: Work on changes and Gerrit commands to push the changes","text":"<p>Make the code changes, and commit the changes</p> <p>cd\u00a0 meta_wan</p> <pre><code>git clone https://github.com/Sukanya673/meta-rdk-wan.git -b new_branch_1</code></pre> <p>Modify your code.</p> <p>$ git status \u00a0 \u00a0Here You will see the files you have locally modified.  $ git add &lt;FILE_NAME&gt; $ git commit -a\u00a0 \u00a0 \u00a0Add the following to your commit message. \u00a0 \u00a0 \u00a0 \u00a0 JIRA-ID Write a small description \u00a0 \u00a0 \u00a0 \u00a0 &lt;One empty line&gt; \u00a0 \u00a0 \u00a0 \u00a0 Reason for change: \u00a0 \u00a0 \u00a0 \u00a0 Test Procedure: \u00a0 \u00a0 \u00a0 \u00a0 Risks:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Signed-off-by:</p> <p>$ git push</p> <p>After submitting your changes, follow the next step to create a PR.</p>"},{"location":"source/docs/how-to-contribute/#step-5-create-pull-request-for-review-the-changes","title":"Step 5: Create pull request for review the changes","text":"<p>Once submitted the changes need to create pull request from GitHub for review. Pull requests \u00a0 let you tell others about changes you've pushed to a branch in a repository on \u00a0 GitHub . Once a \u00a0 pull request \u00a0 is opened, you can discuss and review the potential changes with collaborators and add follow-up commits before your changes are merged into the base branch.</p> <ul> <li>Click on \"Compare &amp; pull request\" button.</li> </ul> <p></p> <ul> <li>Provide the commit request and Click on\u00a0\"Create pull request\" button.</li> </ul> <p></p> <ul> <li>Pull Request page will be created.</li> </ul> <p></p>"},{"location":"source/docs/how-to-contribute/#step-6-working-on-review-comments","title":"Step 6: Working on review comments","text":"<p>Once you've created a pull request, you can push commits from your workspace to add them to your existing pull request. These commits will appear in chronological order within your pull request and the changes will be visible in the \"Files changed\" tab.</p> <p>Other contributors can review your proposed changes, add review comments, contribute to the pull request discussion, and even add commits to the pull request.  </p>"},{"location":"source/docs/how-to-contribute/#documenting-the-code","title":"Documenting the Code","text":""},{"location":"source/docs/how-to-contribute/#why-to-document","title":"Why to Document?","text":"<p>Writing documentation improves the design of your code. Talking through your API and design decisions on paper allows you to think about them in a more formalized way. A nice side effect is that it allows people to contribute code that follows your original intentions as well.</p>"},{"location":"source/docs/how-to-contribute/#how-to-document","title":"How to Document?","text":"<p>RDK component code is documented following the Doxygen standards and guidelines. Doxygen is a popular open-source tool for generating documentation from annotated C/C++ sources. Also, Doxygen supports documenting code written in other programming languages, such as Python, PHP, Java, etc.</p>"},{"location":"source/docs/how-to-contribute/#tools-required-for-doxygen-documentation","title":"Tools Required for Doxygen Documentation","text":"<p>The following tools\u00a0are required to be installed in Linux machine (through apt-get install) to generate documentation with respect to various data flow diagrams.</p> <ol> <li>doxygen : It is a tool for a documentation system for various programming languages such as C++, C, Java and Objective-C.</li> <li>graphviz : Rich set of graph drawing tools. It was required to fulfill the need for centralized documentation presenting all available tools in the graphviz package.</li> <li>dot : Filter for drawing directed graphs. A graph that can be drawn as hierarchy. It reads attributed graph files and writes drawings. By default, the output format dot is the input file with layout coordinates appended.</li> <li>perl : It is a script file used by doxygen, and it should be present in the system.</li> <li>mscgen : Message Sequence Chart Renderer. This will help to make sequence diagram for Doxygen documentation.</li> </ol>"},{"location":"source/docs/how-to-contribute/#steps-to-generate-document-using-doxygen","title":"Steps to Generate Document using Doxygen","text":"<p>The following are the steps to generate documentation using Doxygen tool.</p> <ol> <li>Create a new folder \u201cexample_name\". This is where the final report will reside.</li> <li>Go to directory \u201cexample_name\u201d.</li> <li>Reference doxygen configuration file</li> <li>Doxygen.dox: used for customizing the index page.</li> <li>doxygen.css: style sheet file used for formatting html output.</li> <li>Doxyfile: Configuration file that is needed for generating doxygen output.</li> <li>RDK-Logo.png: RDK Logo.</li> <li>Check out all the RDK component source code (Source code must be Doxygen complaint) for which document needs to be generated, for example:</li> <li>$ git clone https://code.rdkcentral.com/r/rdk/components/generic/wifi \u00a0\u00a0 wifi</li> <li>Edit Doxyfile and set all configurations as required, given below are examples</li> <li>PROJECT_NAME\u00a0 /* Name of the project */</li> <li>INPUT\u00a0\u00a0\u00a0/* Path of source code provided as input for document generation*/</li> <li>OUTPUT_DIRECTORY /* output folder path */</li> <li>Edit doxygen.dox, if the index page needs to be customized, add module names that will be shown in output index page.</li> <li>Edit doxygen.css, for output formats, fonts, etc.</li> <li>Use the following command at the command prompt, to generate html report.</li> <li>$\u00a0 doxygen Doxyfile</li> <li>Doxygen Output HTML report will be available at '/example_name/OUTPUT_DIRECTORY/html' folder, open index.html file to see Doxygen report.</li> </ol>"},{"location":"source/docs/how-to-contribute/#steps-to-add-module-level-information-to-components","title":"Steps to add module level information to components","text":"<p>Refer to below Doxygen Guideline Section for uniform style of adding Doxygen comments for the RDK system.  </p>"},{"location":"source/docs/how-to-contribute/#doxygen-guideline","title":"Doxygen Guideline","text":""},{"location":"source/docs/how-to-contribute/#introduction_1","title":"Introduction","text":"<p>The purpose of this page is to provide a uniform style of Doxygen commenting for the RDK system. It will serve as a reference for current and future developers while documenting the RDK system as it evolves. Ultimately, this will establish a consistent manner of documentation to enhance the simplicity, readability, scalability, writability, reliability, and maintainability of the system.\u00a0</p>"},{"location":"source/docs/how-to-contribute/#documentation-style","title":"Documentation Style","text":"<p>Doxygen documentation can be generated in many formats (HTML, LaTeX, RTF, PDF, DOC). HTML generation has support for more plugins and is easier to refactor as the system changes. Doxygen style should follow a consistent format to aid development across different IDEs, reducing issues when generating documentation.</p> <pre><code>/\\*\\*\n\\* @tagname\n\\*/\n</code></pre> <p>This is an example of a Java doc style Doxygen tag, since it uses the \u201c@\u201d symbol. Tags using the \u201c\\tagname\u201d style are considered Qt style Doxygen tags.There should be a header file containing only Doxygen tags or a separate Doxygen file that acts as a guide for the components, classes, methods, and variables (e.g. DoxygenMainpage.h). This can be done using the\u00a0@mainpage\u00a0tag at the top of the file.</p>"},{"location":"source/docs/how-to-contribute/#system","title":"System","text":"<p>There should be a header file containing only Doxygen tags or a separate Doxygen file that acts as a guide for the components, classes, methods, and variables (e.g., DoxygenMainpage.h). This can be done using the @mainpage\u00a0tag at the top of the file.</p> <pre><code>/\\*\\*\n\\* @mainpage Title of Document\n\\*\n\\*/\n</code></pre>"},{"location":"source/docs/how-to-contribute/#file","title":"File","text":"<p>A file should contain the\u00a0@file\u00a0tag at the top of the file. This supports generation of a file list tab on the main page. It also helps when files contain multiple classes.</p> <pre><code>/\\*\\*\n\\* @file FileName.h\n\\*\n\\* @brief Brief file description.\n\\*\n\\* Verbose file description.\n\\*/\n</code></pre>"},{"location":"source/docs/how-to-contribute/#classes","title":"Classes","text":"<p>Classes can be tagged in a number of different ways, but in general they are tagged using the\u00a0@brief\u00a0and\u00a0@class\u00a0tags before the class declaration. Having the\u00a0@author,\u00a0@date, and\u00a0@version\u00a0supports tractability as the system is versioned throughout the software lifecycle. When updating classes, update comments like this:</p> <pre><code>\\#include &amp;lt;iostream&amp;gt;\nusing namespace std;\n/\\*\\*\n\\* @brief Brief class description\n\\*\n\\* Verbose description of class.\n\\*\n\\* @class Class Name\n\\*/\nclass ClassName &amp;#123;\npublic:\nClassName();\n~ClassName();\nint var1; /\\*\\*&amp;lt; Comment about public member variable\\*/\n/\\*\\*\n\\*@brief Brief method description\n\\*\n\\* Verbose description of method\n\\*\n\\*@param Parameter in the method\u2019s definition\n\\*\n\\*@return Return value of method\n\\*/\nint Function1(int x);\nprotected:\nint var2; /\\*\\*&amp;lt; Comment about protected member variable\\*/\n/\\*\\*\n\\*@brief Brief method description\n\\*\n\\* Verbose description of method\n\\*\n\\*@param Parameter in the method\u2019s definition\n\\*\n\\*@return Return value of method\n\\*/\nint Function2(int x);\nprivate:\nint var3; /\\*\\*&amp;lt; Comment about private member variable\\*/\n/\\*\\*\n\\*@brief Brief method description\n\\*\n\\* Verbose description of method\n\\*\n\\*@param Parameter in the method\u2019s definition\n\\*\n\\*@return Return value of method\n\\*/\nint Function3(int x);\n&amp;#125;;\n</code></pre>"},{"location":"source/docs/how-to-contribute/#structs","title":"Structs","text":"<p>A struct can be tagged in the same way a class, but it is best to use the \u00a0 @struct \u00a0 tag. When updating structs, update comments like this:</p> <pre><code>/\\*\\*\n\\*@brief Brief struct description\n\\*\n\\*@struct Struct Name\n\\*/\n</code></pre>"},{"location":"source/docs/how-to-contribute/#methods","title":"Methods","text":"<p>Methods can be tagged in a number of ways, but in general the \u00a0 @brief ,\u00a0 @details ,\u00a0 @param , and \u00a0 @return \u00a0 tags are used before a method\u2019s declaration or implementation. When updating methods, update comments like this:</p> <pre><code>/\\*\\*\n\\*@brief Brief method description\n\\*\n\\* Verbose description of method\n\\*\n\\*@param Parameter in the method\u2019s definition\n\\*\n\\*@return Return value of method\n\\*@retval Verbose explanation of return values\n\\*/\nint addNumbers(int x)\n&amp;#123;\nint sum = 0;\nsum += x;\u00a0\nreturn sum;\u00a0\n&amp;#125;\n</code></pre>"},{"location":"source/docs/how-to-contribute/#variables","title":"Variables","text":"<p>When updating variables, update comments like this:</p> <pre><code>int number; /\\*\\*&amp;lt; Comment about number\\*/\n</code></pre>"},{"location":"source/docs/how-to-contribute/#enumerated-types","title":"Enumerated Types","text":"<p>Enumerated types are tagged using the\u00a0 @enum . \u00a0When updating enum types, update comments like this:</p> <pre><code>/\\*\\*\n\\*@brief Brief enum description\n\\*\n\\*@enum enum Name\n\\*/\n</code></pre>"},{"location":"source/docs/how-to-contribute/#miscellaneous","title":"Miscellaneous","text":"<p>There are many tags you can use with HTML markup to create unique Doxygen documentation for a given file, class, method, or variable. The following are common tags that should be used when appropriate.</p> <p><pre><code>/\\*\\*\n\\*@note A brief remark about the implementation to help clarify.\n\\*\n\\*@attention An important remark that may cause code to break.\n\\*\n\\*@warning An import remark that may depend on random conditions etc.\n\\*\n\\*@see A reference to a class or a link to documentation (e.g. http://document.1a.com)\n\\*/\n</code></pre> <pre><code>/\\*\\*\n\\*@bug A remark about a known bug in the code.\n\\*\n\\*@todo A remark of what needs to be done to fix issues or remaining work.\n\\*\n\\*/\n</code></pre> <pre><code>/\\*\\*\n\\*@a Formats following word in special font (used for hyperlinks)\n\\*\n\\*@b Formats following word in bold\n\\*\n\\*@em Formats following word in italic\n\\*\n\\*@c Formats following word in monospaced typewriter font\n\\*\n\\*/\n</code></pre> <pre><code>/\\*\\*\n\\* - bulleted list item1\n\\* - sub bulleted item1\n\\*\n\\* - bulleted list item2\n\\*\n\\*/\n</code></pre> <pre><code>/\\*\\*\n\\* -# numbered list item1\n\\* -# numbered list item2\n\\*\n\\*/\n</code></pre> <pre><code>/\\*\\*\n\\*@code\ni++;\n\\*@endcode\n\\*/\n</code></pre></p>"},{"location":"source/docs/how-to-contribute/#setting-up-doxygen-environment-on-linux","title":"Setting up Doxygen Environment on Linux","text":"<p>Tools Required for Doxygen Documentation:</p> <pre><code>Following Tools are need to be installed in Linux machine (through apt-get install) to generate documentation with respect to various data flow diagrams.\n\u00a0 \u00a0 $ sudo apt-get install \"doxy\\*\"\n\u00a0 \u00a0 $ sudo apt-get install graphviz\n\u00a0 \u00a0 $ sudo apt-get install dot\n\u00a0 \u00a0 $ sudo apt-get install mscgen\n\u00a0 \u00a0 $ sudo apt-get install perl\n</code></pre> <p>Check the doxygen version by using command: \u00a0 <code>$ doxygen --version</code> Graphviz:\u00a0 graphviz.org (Click the Download link on the left side of the page)</p>"},{"location":"source/docs/how-to-refresh-the-patches/","title":"How to Refresh the Patches","text":""},{"location":"source/docs/how-to-refresh-the-patches/#overview","title":"Overview","text":"<p>Sometimes while applying patches, it may face offsets mismatch and results in failure. This makes your build verification also to fail. You can get similar error in console logs for patch failures.</p> <p><pre><code>ERROR: Command Error: exit status: 1 Output:  \nApplying patch index.patch  \npatching file source/Styles/xb3/code/index.php  \nHunk \\#1 succeeded at 22 (offset 21 lines).  \nHunk \\#2 succeeded at 32 (offset 21 lines).  \nHunk \\#3 succeeded at 73 (offset 21 lines).  \nHunk \\#4 succeeded at 183 (offset 27 lines).  \nHunk \\#5 succeeded at 195 (offset 27 lines).  \nHunk \\#6 succeeded at 245 (offset 37 lines).  \nHunk \\#7 succeeded at 307 (offset 37 lines).  \nHunk \\#8 succeeded at 460 (offset 52 lines).  \nHunk \\#9 succeeded at 469 (offset 52 lines).  \nHunk \\#10 FAILED at 431.  \nHunk \\#11 FAILED at 445.  \nHunk \\#12 FAILED at 455.  \n3 out of 12 hunks FAILED -- rejects in file source/Styles/xb3/code/index.php  \nPatch index.patch does not apply (enforce with -f)\n</code></pre> From the logs, you can find out that patch is not applied to the source file properly. In such scenarios you will have to update or refersh the patch.</p>"},{"location":"source/docs/how-to-refresh-the-patches/#step-1-get-the-patch-file","title":"Step 1 : Get the patch file","text":"<p>1.Find the repo for the patch file.(For ex : here the patch file is index.patch.)</p> <p>2.Clone the repo. For ex: <pre><code>$ mkdir patch\n$ cd patch/\n$ git clone ssh://rkumar840@gerrit.teamccp.com:29418/rdk/yocto_oe/layers/meta-rdk-oem-pace-broadcom\n</code></pre> 3.Checkout the branch for which you want to create the patch.</p> <p><pre><code>$ git checkout 1905_sprint\n$ git branch\n</code></pre> 4.Find the location of the patch file in the repo.</p> <pre><code>$ find . -iname index.patch\n./meta-pacexf3/recipes-ccsp/ccsp/ccsp-webui/index.patch\n</code></pre>"},{"location":"source/docs/how-to-refresh-the-patches/#step-2-identify-the-component-repo","title":"Step 2 : Identify the component repo","text":"<ol> <li> <p>Next find the repo for the actual source file to which the patch file was getting patched. ( For ex: here the source file is index.php)</p> </li> <li> <p>clone the repo Example: <pre><code>$ mkdir source\n$ cd source/\n$ git clone ssh://rkumar840@gerrit.teamccp.com:29418/rdk/rdkb/components/opensource/ccsp/webui/generic\n</code></pre> 3.checkout the required branch</p> </li> </ol> <p><pre><code>$ git checkout 1905_sprint\n$ git branch\n</code></pre> 4.Cherry-pick the required changes also <pre><code>$ git fetch\u00a0ssh://rkumar840@gerrit.teamccp.com:29418/rdk/rdkb/components/opensource/ccsp/webui/generic\n</code></pre> 5.After cherry-picking you can verify the changes in the source file.</p>"},{"location":"source/docs/how-to-refresh-the-patches/#step-3-apply-the-patches","title":"Step 3 : Apply the patches","text":"<p>1. create another directory, and clone the source code repo (as in step 2). For ex :</p> <ul> <li>$ mkdir dummy</li> <li>$ cd dummy/</li> <li>$ git\u00a0\u00a0clone\u00a0     ssh://rkumar840@gerrit.teamccp.com:29418/rdk/rdkb/components/opensource/ccsp/webui/generi     c</li> </ul> <p>2.checkout the required branch</p> <ul> <li>$ git checkout 1905_sprint</li> <li>$ git branch</li> </ul> <p>3.Copy the patch file from the patch repo (step 1) to the current directory.</p> <ul> <li>$ cp ../patch/meta-pacexf3/recipes-ccsp/ccsp/ccsp-webui/index.patch .</li> <li>$ ls</li> </ul> <p>cmpnt_build_custom_pre_arm.mk CONTRIBUTING.md \u00a0 \u00a0 \u00a0 \u00a0debug_scripts\u00a0 \u00a0 \u00a0 LICENSE\u00a0 \u00a0 \u00a0 \u00a0 \u00a0NOTICE\u00a0 \u00a0 \u00a0 \u00a0 \u00a0scripts \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0cmpnt_build_custom_pre_pc.mk \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0COPYING\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 index.patch\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Makefile.orig\u00a0 \u00a0 \u00a0README\u00a0 \u00a0 \u00a0 \u00a0source</p> <p>4.Apply the patch to the source file/files.</p> <ul> <li>$ patch -p1 &lt; index.patchpatching file source/Styles/xb3/code/index.php     Hunk #1 succeeded at 22 (offset 21 lines).     Hunk #2 succeeded at 32 (offset 21 lines).     Hunk #3 succeeded at 73 (offset 21 lines).     Hunk #4 succeeded at 183 (offset 27 lines).     Hunk #5 succeeded at 195 (offset 27 lines).     Hunk #6 succeeded at 245 (offset 37 lines).     Hunk #7 succeeded at 307 (offset 37 lines).     Hunk #8 succeeded at 445 (offset 37 lines).     Hunk #9 succeeded at 454 (offset 37 lines).     Hunk #10 succeeded at 468 (offset 37 lines).     Hunk #11 succeeded at 482 (offset 37 lines).     Hunk #12 succeeded at 492 (offset 37 lines).</li> </ul> <p>5.It should be applied successfully. In case of observing any failure when apply the patch to the source file/files then skip this step. If no failures observed then take a backup for the file/files got patched. For ex :\u00a0</p> <ul> <li>$ cp source/Styles/xb3/code/index.php source/Styles/xb3/code/index_bk.php</li> </ul> <p>6.In case of observing any failure when apply the patch to the source file/files, then this may\u00a0expects some other patch to be applied first. In such case,</p> <ul> <li>Find the repo init command from the full console log. Search for \"Repo Init\".\u00a0</li> </ul> <p>Example: Repo Init for - Project: &lt; clone_url&gt; Branch: 2003_sprint Manifest: ciscoxb3-3939B</p> <ul> <li>Create another directory</li> </ul> <p>$ mkdir cisco_intel_repo</p> <p>$ cd cisco_intel_repo</p> <ul> <li>Append .xml with manifest filename in repo init command and Clone the repo</li> </ul> <p>$ repo init -u &lt; clone_url&gt; -m ciscoxb3-3939B.xml -b 2003_sprint</p> <p>$\u00a0repo sync -j4 --no-clone-bundle</p> <ul> <li>grep with file name( in which patch applied failure observed) in meta-* layers, So that will find the other patch file which creates this file.</li> </ul> <p>$\u00a0grep -irn \"Filename\" meta-* \u00a0 \u00a0 \u00a0 \u00a0 \u00a0</p> <ul> <li>Analyse and apply the patch file first, and then on top of that apply the second patch file,\u00a0If no failures observed then take a backup for the file/files got patched. For ex :\u00a0</li> </ul> <p>$ cp source/Styles/xb3/code/index.php source/Styles/xb3/code/index_bk.php \u00a0 \u00a0 \u00a0</p>"},{"location":"source/docs/how-to-refresh-the-patches/#step-4-compare-the-files-and-generate-patch","title":"Step 4 : Compare the files and generate patch","text":"<p>1.Now you can use \"Meld tool\" to compare between files to refresh the patch. Here you can compare between the source file generated in step 2 (which will have the required changes) and the source file generated in step-3 (which will have the patch appied on to it).</p> <p>2.During comparing between source files make sure that you take only the required changes (changes available in actual source file step-2) to the patched file generated in step-3.</p> <p>3.Once all changes are taken , you can verify the patch by checking the option file/format as patch in the tool. Save the updated file and copy it to your repo (repo generated in step-2)</p> <p>4.Now in your repo , you will have 2 source file (for ex: one will be\u00a0index.php --original file with the required changes and\u00a0index_bk.php --updated file with patch applied and also your changes).</p> <p>5.In terminal , you can use command \"diff -ruN\u00a0 file1 file2 &gt; new_patch_file.patch\" to generate a\u00a0 new patch.</p> <p>6.For ex : diff -ruN index.php index_bk.php &gt; new_index.patch</p> <p>7.In case patch file has more than one file, then append the difference using diff -ruN next_file nextfile_bk.php &gt;&gt; new_index.patch</p>"},{"location":"source/docs/how-to-refresh-the-patches/#step-5-update-the-patch-file","title":"Step 5 : Update the patch file","text":"<p>1. Open the newly created patch file, update the file location correctly and save it. For ex :</p> <p>git/source/Styles/xb3/code/index.php 2019-05-20 05:56:54.047078876 +0000 +++ git.1/source/Styles/xb3/code/index.php 2019-05-20 06:26:56.000000000 +0000</p>"},{"location":"source/docs/how-to-refresh-the-patches/#step-6-validate-the-patch-file","title":"Step 6 : Validate the patch file","text":"<p>1.In order to verify the newly created patch, you can create a temporary folder, clone the repo, checkout the required branch. Now copy the latest patch (new_index.patch) here.\u00a0</p> <p>2.In the terminal, give the command\u00a0 patch -p1 &lt;\u00a0 new_index.patch , will apply the patch to the source file. It should not fail.</p>"},{"location":"source/docs/how-to-refresh-the-patches/#step-7-push-the-changes","title":"step 7 : Push the changes","text":"<p>1.Now for pushing the latest patch, clone the repo for patch (step-1)</p> <ul> <li>$ mkdir push</li> <li>$ cd push/</li> <li>$ git clone\u00a0     ssh://rkumar840@gerrit.teamccp.com:29418/rdk/yocto_oe/layers/meta-rdk-oem-pace-broadcom     \u00a0.</li> </ul> <p>2.checkout the required branch.</p> <ul> <li>$ git checkout 1905_sprint</li> </ul> <p>3.copy the latest patch(new_index.patch in this case) to the actual patch file available in the repo.</p> <ul> <li>$ cp ../src/new_index.patch\u00a0meta-pacexf3/recipes-ccsp/ccsp/ccsp-webui/index.patch</li> <li>$ git status</li> </ul> <p>4.It will show the file as modified. Perform git add.</p> <ul> <li>$ git add\u00a0meta-pacexf3/recipes-ccsp/ccsp/ccsp-webui/index.patch</li> <li>$ git commit</li> </ul> <p>5.Update if any commit message has to be added and try to push the changes.</p> <ul> <li>$ git push origin HEAD:refs/for/1905_sprint</li> </ul> <p>6.It fails for commit message upload. For ex : you may get error like this :</p> <ul> <li>remote: ERROR: [6b429fb] missing Change-Id in commit message footer</li> <li>remote:</li> <li>remote: Hint: To automatically insert Change-Id, install the hook:</li> <li>remote:     gitdir=$(git rev-parse --git-dir); scp -p -P 29418     rkumar840     @gerrit.teamccp.com     :hooks/commit-msg ${gitdir}/hooks/</li> <li>remote: And then amend the commit:</li> <li>remote: git commit --amend</li> </ul> <p>7.Run the command mention in logs.</p> <ul> <li>$ gitdir=$(git rev-parse --git-dir); scp -p -P 29418\u00a0     rkumar840     @gerrit.teamccp.com     :hooks/commit-msg ${gitdir}/hooks/</li> <li>$ git commit --amend (No change-id is assigned to the change.)</li> <li>$ git commit --amend\u00a0 (change-id has assigned now.)</li> <li>$ git push origin HEAD:refs/for/1905_sprint</li> </ul> <p>8.This will push the changes successfully to the branch. You can open the gerrit link and verify.</p> <p>9.Put the same topic name for the patch and the source file , trigger the verification.</p>"},{"location":"support/docs/overview/","title":"Place Holder markdown for Support page","text":""},{"location":"tools/docs/Automatics/","title":"Automatics","text":"<p>Automatics is the fully \u00a0integrated test automation system to support functional &amp; non-functional testing. Automatics is now available to the RDK community. Any community member can use this system to validate their RDK builds or their infrastructure.</p> <p>Automatics supports:</p> <ul> <li>Integration with CI flow to validate new changes checked in by user</li> <li>Configure test script details and test strategies</li> <li>Manual trigger of automated tests against RDK builds</li> <li>Walk through on test execution results</li> <li>End to End system is designed to support fast-paced DevOps model</li> <li>Support to execute test scripts based on Java, Python and PyTest.</li> </ul> <p>Major features of Automatics framework to work with external tools to enhance the Automatics capabilities:</p> <ul> <li>The framework supports integration with modern software tools -     Jira, ALM, Jenkins, Git, Grafana, Candela, CDRouter etc</li> <li>Dynamic device allocation and device health check is supported</li> <li>Automated defect creation and tagging can be done using the     framework</li> </ul> <p></p>"},{"location":"tools/docs/Automatics/#automatics-overview","title":"Automatics Overview","text":"<ul> <li> <ul> <li> <p> Automatics Architecture </p> </li> <li> <p></p> <p> Automatics in CI/CD </p> </li> <li> <p></p> <p> Automatics Repository Details </p> </li> <li> <p></p> <p> Automatics Tools Releases </p> </li> </ul> </li> </ul>"},{"location":"tools/docs/Automatics/#automatics-recent-updates","title":"Automatics Recent Updates","text":"<p> Automatics Framework and Tools - Release V15.0\u00a0is available</p> <p> Automatics Framework and Tools - Release V10.0\u00a0is available</p> <p> Automatics RDK-B Test script Release V10.0 is available</p>"},{"location":"tools/docs/Automatics/#automatics-useful-links","title":"Automatics Useful Links","text":"<ul> <li>Automatics Overview Webinar</li> <li>Automatics RDK-B Test Coverage Overview Webinar</li> <li>Automatics Demo Webinar</li> <li>Code Contribution Process</li> <li>Scriptless Automation Webinar</li> </ul>"},{"location":"tools/docs/Automatics/#automatics-framework","title":"Automatics Framework","text":"<ul> <li> <ul> <li> <p> Automatics Automated Build &amp; Deployment </p> </li> <li> <p></p> <p> Automatics Device Manager </p> </li> <li> <p></p> <p> Automatics Framework Repository Details </p> </li> <li> <p></p> <p> Automatics Generic Core Test Execution </p> </li> <li> <p></p> <p> Automatics Getting Started </p> </li> <li> <p></p> <p> Automatics Properties </p> </li> <li> <p></p> <p> Automatics Provider Details </p> </li> <li> <p></p> <p> Automatics Providers List </p> </li> <li> <p></p> <p> Automatics System Setup </p> </li> <li> <p></p> <p> Automatics Technology Stack - Upgrade </p> </li> <li> <p></p> <p> Automatics Tool Setup </p> </li> <li> <p></p> <p> Jenkins Setup and Deployment Guide </p> </li> </ul> </li> </ul>"},{"location":"tools/docs/Automatics/#automatics-core","title":"Automatics Core","text":"<ul> <li> <ul> <li> <p> Automatics API Specification </p> </li> <li> <p></p> <p> Automatics Core Overview </p> </li> </ul> </li> </ul>"},{"location":"tools/docs/Automatics/#automatics-rdk-b-tests","title":"Automatics RDK-B Tests","text":"<ul> <li> <ul> <li> <p> Automatics RDK-B Test case Provider Mapping </p> </li> <li> <p></p> <p> Automatics RDK-B Test Plan </p> </li> <li> <p></p> <p> Automatics RDK-B Test Property configuration </p> </li> <li> <p></p> <p> Automatics RDK-B Test Refactoring Releases &amp; Roadmap </p> </li> <li> <p></p> <p> Automatics RDKB Test Repository Details </p> </li> <li> <p></p> <p> Automatics RDK-B Test script Releases </p> </li> <li> <p></p> <p> Automatics RDK-B Test Scripts </p> </li> <li> <p></p> <p> Automatics RDK-B Tests Test Category </p> </li> <li> <p></p> <p> Automatics TCs shared by L&amp;T for open sourcing </p> </li> <li> <p></p> <p> Device Configuration in Automatics </p> </li> <li> <p></p> <p> RDKB Automatics Test - Connected Client Environment Setup </p> </li> <li> <p></p> <p> RDK-B Automatics Test Setup </p> </li> <li> <p></p> <p> RDKB - Test Reports 2023Q4 Kirkstone build </p> </li> <li> <p></p> <p> RDKB - Test Reports 2024Q2 Kirkstone build </p> </li> <li> <p></p> <p> RDKB - Test Reports 2024Q3 Kirkstone build </p> </li> <li> <p></p> <p> RDKB - Test Reports 2024Q4 Kirkstone build </p> </li> <li> <p></p> <p> RDKB Tests on Raspberry Pi device </p> </li> <li> <p></p> <p> RDKB Tests on Raspberry Pi device - Execution Status </p> </li> </ul> </li> </ul>"},{"location":"tools/docs/Automatics/#automatics-working-group","title":"Automatics Working Group","text":"<ul> <li> <ul> <li> <p> Automatics-3.0 </p> </li> <li> <p></p> <p> Automatics Candela Integration </p> </li> <li> <p></p> <p> Automatics Roadmap and Backlogs </p> </li> <li> <p></p> <p> TR181 Validation Support </p> </li> </ul> </li> </ul>"},{"location":"tools/docs/Automatics/#automatics-community-collaboration","title":"Automatics Community Collaboration","text":"<ul> <li> <ul> <li> <p> Automatics Community Contributions </p> </li> </ul> </li> </ul>"},{"location":"tools/docs/TDK/","title":"Test Development Kit (TDK) Home","text":"<p>Welcome to the TDK space!</p> <p>The RDK Test Development Kit (TDK) is a generic test kit for automated testing of generic RDK components and end-to-end scenarios facilitated by a web based user interface for configuration, test creation, execution and result aggregation. The web based UI is complemented by command line interfaces to power test automation from third party test and continuous integration tools. The TDK facilitates the testing of RDK devices in standalone environments. This page provides information regarding the TDK roadmap, usage tutorials, development processes and FAQs to facilitate the RDK community to start using the tool and provide feedback and requirements for the improvement of the tool to suite the generic community needs.</p>"},{"location":"tools/docs/TDK/#tdk-release-notes-roadmap-updates","title":"TDK Release Notes &amp; Roadmap Updates","text":"<ul> <li>TDK Releases</li> </ul>"},{"location":"tools/docs/TDK/#tdk-documentation","title":"TDK-Documentation","text":"<ul> <li> <p>TDK-V Documentation</p> </li> <li> <p>TDK-B Documentation</p> </li> <li> <p>TDK-C Documentation</p> </li> <li> <p>RDK Certification\u00a0</p> </li> </ul>"},{"location":"tools/docs/TDK/#tutorials-documents","title":"Tutorials &amp; Documents","text":"<ul> <li> <p>TDK-V Test Case Documents</p> </li> <li> <p>TDK-B Test Case Documents</p> </li> <li> <p>Docker Setup for TDK Test Manager</p> </li> <li> <p>TDK-B E2E Setup Document</p> </li> <li> <p>TDK Bug Resolution     Workflow</p> </li> <li> <p>FAQ</p> </li> <li> <p>TDK Test Manager Java8 Migration</p> </li> <li> <p>TDK - RDK Service Validation Framework</p> </li> </ul>"}]}