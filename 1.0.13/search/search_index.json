{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RDK Documentation?","text":"Entertainment <p>Build Apps, manage media and UI layers in a video platform</p> Explore Features <p>Explore the various features and standards that are supported in RDK</p> Core Components <p>Access detailed documentation on various Core RDK components</p> Architecture <p>Dive deep into the RDK7 Architecture and how different layers interface each other</p> Latest Releases <p>Details on the latest release for video platforms - RDK7</p> Connectivity <p>Framework that enables high-speed internet delivery for service providers. </p> Explore Features <p>Explore the various features and standards that are supported in RDK</p> Core Components <p>Access detailed documentation on various Core RDK components</p> Architecture <p>Dive deep into the RDK middleware architecture and how different layers interface each other</p> Latest Releases <p>Details on the latest release for broadband platforms - 2025 Q2</p> Developer Resources Entertainment Connectivity Getting Started <p>Start exploring RDK software, build RDK in your own setup, and try out RDK in a reference platform.</p> Explore Develop an App <p>Explore Firebolt\u2122, the RDK app framework, and Lightning\u2122 the app development SDK.</p> Explore Port RDK <p>Explore how the port RDK and get it up and running in your platform.</p> Explore Test RDK Device <p>Explore how the open source tools from RDK can be used to test your RDK devices.</p> Explore Getting Started <p>Start exploring RDK software, and try out RDK in a reference platform</p> Explore Features <p>Explore the various features and standards that are supported in RDK</p> Explore Core Components <p>Refer the detailed documentation on Core RDK Components</p> Explore Test RDK Device <p>Explore how the open source tools from RDK can be used to test your RDK devices</p> Explore"},{"location":"connectivity/docs/","title":"Place Holder markdown for Connectivity  Overview page","text":""},{"location":"connectivity/docs/architecture/","title":"Place Holder markdown for Connectivity Architecture","text":""},{"location":"connectivity/docs/features/","title":"Place Holder markdown for Connectivity features","text":""},{"location":"connectivity/docs/rdkb_components/","title":"Place Holder markdown for Connectivity  core component landing page","text":""},{"location":"connectivity/docs/tryout_rdkb/","title":"Place Holder markdown for Connectivity  Getting Started page","text":""},{"location":"device-management/docs/","title":"Device Management","text":"<p>Device management encompasses the centralized control, monitoring, configuration, and maintenance of connected devices, enabling efficient bulk operations, dynamic feature management, and firmware updates to ensure optimal performance, security, and scalability across diverse deployments. The significance lies in its ability to horizontally scale across these profiles, allowing for the efficient sharing of the same code. This streamlined approach facilitates controlled bulk operations and data retrievals, essential for managing diverse devices at scale. The functionality extends to enabling or disabling features dynamically and facilitating firmware (code) downloads. Moreover, Device Management plays a crucial role in retrieving field matrices, ensuring a comprehensive and organized approach to overseeing and controlling devices within the specified frameworks.</p>"},{"location":"device-management/docs/#device-management-capabilities","title":"Device Management capabilities","text":"<p>Different device management capabilities are shared across the different profiles. The key device management capabilities are:</p>"},{"location":"device-management/docs/#xconf","title":"XConf","text":"<p>XConf\u00a0is a pivotal device management service that enables streamlined code download in set-top-boxes (STBs), providing essential information on firmware version, download source, and download protocol. It overcomes limitations of traditional code downloads by employing the eSTB interface for code download.</p>"},{"location":"device-management/docs/#webpa","title":"WebPA","text":"<p>WebPA (Web Protocol Adapter) serves as a secure web protocol messaging system for bi-directional communication between cloud servers and RDK devices. It offers read/write access to device management parameters, prioritizing security and performance, and replaces traditional methods like TR-69 or SNMP.</p>"},{"location":"device-management/docs/LogUpload/","title":"Placeholder for Log Upload documentation","text":""},{"location":"device-management/docs/TR369/","title":"Placeholder for TR369 documentation","text":""},{"location":"device-management/docs/Telemetry/","title":"Placeholder for Telemetry documentation","text":""},{"location":"device-management/docs/Webpa/","title":"Placeholder for webpa documentation","text":""},{"location":"device-management/docs/XConf/","title":"XConf","text":"<p>Note</p> <p>Details of XConf API are available at  XConf APIs &amp; User Interface Documentation on XConf deployment is available at XConf Security &amp; Deployment</p>"},{"location":"device-management/docs/XConf/#overview","title":"Overview","text":"<p>XConf is a comprehensive configuration management system designed for RDK (Reference Design Kit) devices, primarily set-top boxes (STBs). It serves as the central authority for managing firmware versions, device settings, feature controls, and telemetry configurations across large device populations.</p> <p>The system handles the complex requirements of managing thousands to millions of deployed devices across diverse network environments. XConf provides operators with centralized control over firmware deployments, device behaviors, feature toggles, and telemetry data collection through a sophisticated rule-based platform.</p> <p>XConf operates on rule-based decision making principles. When devices request configurations, firmware updates, or feature settings, XConf evaluates configurable rules against device attributes (MAC address, model, environment, firmware version, location) to determine appropriate responses. This provides fine-grained control over device populations while maintaining flexibility for diverse deployment scenarios.</p>"},{"location":"device-management/docs/XConf/#key-features","title":"Key Features","text":"<ul> <li>Centralized Configuration Management: Single point of control for all device configurations</li> <li>Rule-Based Decision Engine: Sophisticated conditional logic for device targeting</li> <li>High-Volume Device Support: Designed to handle millions of concurrent device requests</li> <li>Multi-Application Support: Supports STB, xHome, and rdkCloud device types</li> <li>Real-time Feature Control: Dynamic feature enabling/disabling without firmware updates</li> <li>Comprehensive Telemetry: Both legacy and modern telemetry data collection systems</li> </ul>"},{"location":"device-management/docs/XConf/#use-cases","title":"Use Cases","text":"<ul> <li>Firmware Rollouts: Controlled deployment of firmware updates with percentage-based rollouts</li> <li>Feature Management: Remote enabling/disabling of device features for A/B testing</li> <li>Device Configuration: Centralized management of device operational parameters</li> <li>Telemetry Collection: Comprehensive data gathering for analytics and troubleshooting</li> <li>Emergency Response: Rapid configuration changes for security or operational issues</li> </ul>"},{"location":"device-management/docs/XConf/#architecture","title":"Architecture","text":"<p>XConf follows a distributed microservices architecture designed to handle high-volume device requests while maintaining administrative flexibility. The system separates device-facing operations from administrative functions, ensuring that high-frequency device requests don't interfere with configuration management operations.</p>"},{"location":"device-management/docs/XConf/#high-level-architecture","title":"High-level Architecture","text":"<p>The following diagram illustrates the core components and their interactions. Device requests flow through the DataService, which evaluates rules stored in Cassandra to determine appropriate configurations. Administrative operations are handled through a separate service layer for operational stability and security isolation.</p> <pre><code>graph TD\n    A[STB Devices] --&gt;|Requests| B[XConf DataService]\n    B --&gt;|Queries| C[Cassandra Database]\n    B --&gt;|Admin API| D[XConf Admin Service]\n    D --&gt;|UI Access| E[XConf UI]\n    F[3rd-party Tools] --&gt;|Monitoring| B</code></pre>"},{"location":"device-management/docs/XConf/#components","title":"Components","text":"<p>XConf DataService (<code>xconfwebconfig</code>): The core backend service processes all device-initiated requests. Built in Go using <code>gorilla/mux</code> router, it handles firmware updates, DCM settings, and RFC requests through a sophisticated rule evaluation engine. Operating on port <code>9000</code>, it's designed for high throughput with comprehensive caching mechanisms and supports time-based deployments, percentage rollouts, and geographic targeting.</p> <p>The DataService implements efficient request processing with optimized database queries and response caching. It evaluates complex rule sets against device attributes to determine appropriate configurations, ensuring consistent and reliable responses even under high load conditions.</p> <p>XConf Admin Service (<code>xconfadmin</code>): Provides comprehensive management capabilities through RESTful APIs for all XConf configurations. Operating on port <code>9001</code>, it handles CRUD operations, validation, testing, and export/import functionality. The service implements role-based access control and supports multiple application types (STB, xHome, rdkCloud) with proper isolation.</p> <p>The Admin Service includes sophisticated validation logic to ensure configuration consistency and provides testing endpoints for verifying rule behavior before deployment. It supports bulk operations for efficient management of large configuration sets.</p> <p>XConf UI (<code>xconfui</code>): A web-based management console built with AngularJS and Go backend. It offers intuitive forms, visual rule builders, and comprehensive testing capabilities. The interface provides progressive disclosure, presenting simple interfaces for common operations while offering advanced features when needed.</p> <p>The UI includes extensive validation, real-time feedback, and preview capabilities to help administrators understand configuration impacts before deployment. It supports import/export operations and bulk configuration management.</p> <p>Cassandra Database: The distributed NoSQL storage layer using the <code>ApplicationsDiscoveryDataService</code> keyspace. It stores all configuration data with a schema optimized for read-heavy workloads and efficient rule evaluation queries. The database design uses wide-row patterns for consistent performance and supports configurable consistency levels.</p> <p>Cassandra's distributed architecture provides high availability and horizontal scalability essential for supporting large device populations across multiple geographic regions.</p> <p>Authentication Provider: Integrates with external authentication systems, primarily OAuth2 providers, for secure access control. The system validates tokens for all administrative operations and supports configurable authentication endpoints, enabling integration with existing organizational identity management systems.</p>"},{"location":"device-management/docs/XConf/#core-capabilities","title":"Core Capabilities","text":""},{"location":"device-management/docs/XConf/#firmware-management","title":"Firmware Management","text":"<p>XConf's firmware management provides comprehensive control over firmware deployments across device populations. The system handles complex distribution requirements including staged rollouts, compatibility verification, and rollback capabilities through a sophisticated rule-based engine.</p> <p>When devices request firmware updates, XConf evaluates device characteristics (firmware version, model, MAC address, environment) against configured deployment rules to determine appropriate responses.</p>"},{"location":"device-management/docs/XConf/#firmware-configuration-management","title":"Firmware Configuration Management","text":"<p>Firmware Configs define available firmware packages with comprehensive metadata including version identifiers, filenames, download locations, supported models, and deployment parameters. The system supports IPv4/IPv6 locations, multiple protocols (HTTP, HTTPS, TFTP), and configurable upgrade delays.</p>"},{"location":"device-management/docs/XConf/#rule-based-distribution","title":"Rule-Based Distribution","text":"<p>Firmware Rules determine which devices receive specific firmware versions based on device attributes and environmental factors. Rules support complex conditional logic with AND/OR operators, negation, and priority-based evaluation for sophisticated targeting scenarios.</p>"},{"location":"device-management/docs/XConf/#deployment-control-mechanisms","title":"Deployment Control Mechanisms","text":"<p>The system provides multiple deployment control mechanisms: percentage filters for gradual rollouts, time filters for maintenance window restrictions, and location filters for geographic targeting. These controls minimize risk and ensure smooth deployments.</p>"},{"location":"device-management/docs/XConf/#version-management","title":"Version Management","text":"<p>Comprehensive version tracking includes Activation Version rules for minimum firmware requirements and Intermediate Version configurations for staged upgrade paths, ensuring compatibility and reducing upgrade failures.</p>"},{"location":"device-management/docs/XConf/#device-configuration-manager-dcm","title":"Device Configuration Manager (DCM)","text":"<p>DCM provides comprehensive management of device operational parameters, logging configurations, and behavioral settings. It offers centralized control over device field operations, data collection, and reporting through a rule-based system that evaluates device attributes to determine appropriate configuration profiles.</p>"},{"location":"device-management/docs/XConf/#device-settings-management","title":"Device Settings Management","text":"<p>Device Settings control fundamental operational parameters including configuration check schedules, reboot policies, service endpoint URLs, and activation flags. The system supports both immediate and scheduled configuration changes for coordinated updates across device populations.</p>"},{"location":"device-management/docs/XConf/#logging-and-upload-control","title":"Logging and Upload Control","text":"<p>Log Upload Settings manage device logging behavior, controlling log file collection, retention periods, upload schedules, and automatic upload triggers. The system supports sophisticated rules for targeting specific log files and scheduling uploads based on device state or time triggers.</p>"},{"location":"device-management/docs/XConf/#repository-management","title":"Repository Management","text":"<p>Upload Repositories define destinations for device logs and data, including destination URLs, upload protocols, authentication parameters, and handling requirements. The system supports multiple repository types with routing based on content type or device characteristics.</p>"},{"location":"device-management/docs/XConf/#vod-and-specialized-settings","title":"VOD and Specialized Settings","text":"<p>VOD Settings provide specialized configurations for Video-on-Demand services, including server locations, network parameters, and session management settings to ensure efficient content delivery network access.</p>"},{"location":"device-management/docs/XConf/#rdk-feature-control-rfc","title":"RDK Feature Control (RFC)","text":"<p>RFC enables remote feature control without firmware updates, allowing operators to quickly enable/disable features and respond to changing requirements. The system uses sophisticated feature definitions and rule evaluation to determine appropriate feature configurations for different device populations.</p>"},{"location":"device-management/docs/XConf/#feature-definition-and-management","title":"Feature Definition and Management","text":"<p>Features are defined with comprehensive metadata including identifiers, names, configuration parameters, and behavioral specifications. Features can take effect immediately or require device restarts, with support for complex multi-parameter configurations.</p>"},{"location":"device-management/docs/XConf/#rule-based-feature-activation","title":"Rule-Based Feature Activation","text":"<p>Feature Rules determine which devices receive specific features based on device attributes (model, firmware version, location, environment). The system supports priority-based evaluation and feature-specific configuration parameters for different device populations.</p>"},{"location":"device-management/docs/XConf/#whitelisting-and-access-control","title":"Whitelisting and Access Control","text":"<p>Namespaced Lists allow features to be restricted to specific device populations through MAC address, device model, or other identifiers. This enables controlled rollouts, beta testing, and targeted deployments.</p>"},{"location":"device-management/docs/XConf/#dynamic-configuration","title":"Dynamic Configuration","text":"<p>Features marked as \"effective immediate\" can be enabled/disabled in real-time without device restarts, allowing rapid response to operational requirements or emergency situations.</p>"},{"location":"device-management/docs/XConf/#telemetry-system","title":"Telemetry System","text":"<p>XConf provides comprehensive data collection and reporting through both legacy Telemetry 1.0 and modern Telemetry 2.0 architectures. The system enables collection of operational data, performance metrics, and diagnostic information from field devices.</p>"},{"location":"device-management/docs/XConf/#telemetry-10-legacy","title":"Telemetry 1.0 (Legacy)","text":"<p>Uses profile-based data collection with Telemetry Profiles specifying collection frequency, data types, and destinations. Profiles contain Telemetry Elements defining specific collection points including log patterns, system metrics, and custom data sources.</p>"},{"location":"device-management/docs/XConf/#telemetry-20-modern","title":"Telemetry 2.0 (Modern)","text":"<p>Provides flexible, component-driven data collection through JSON-based configurations supporting complex scenarios, modular architectures, and advanced processing. Supports dynamic profile assignment and real-time profile switching based on device characteristics.</p>"},{"location":"device-management/docs/XConf/#rule-based-activation","title":"Rule-Based Activation","text":"<p>Both systems support rule-based activation for applying different telemetry configurations to device populations. Telemetry Rules evaluate device attributes to determine active profiles, enabling targeted data collection for specific populations, regions, or scenarios.</p>"},{"location":"device-management/docs/XConf/#data-collection-and-reporting","title":"Data Collection and Reporting","text":"<p>Supports various collection methods including log monitoring, system metrics, and custom sources. Data can be sent to multiple destinations with different formats and protocols, with scheduling capabilities for optimized network usage.</p>"},{"location":"device-management/docs/XConf/#data-model","title":"Data Model","text":"<p>XConf's data model uses Cassandra's distributed NoSQL architecture to support high-volume, read-heavy workloads typical of device configuration systems. The design emphasizes efficient rule evaluation, fast device lookups, and scalable storage.</p> <p>The system uses a single Cassandra keyspace <code>ApplicationsDiscoveryDataService</code> containing all XConf data. The table structure is optimized for XConf's query patterns with careful partition key design and clustering strategies.</p>"},{"location":"device-management/docs/XConf/#cassandra-keyspaces-tables","title":"Cassandra Keyspaces &amp; Tables","text":"<p>Keyspace: <code>ApplicationsDiscoveryDataService</code></p> <p>Contains all operational data organized into functional area tables designed with Cassandra best practices for even data distribution and efficient queries.</p> <p>Core Tables:</p> <ul> <li><code>FirmwareConfig</code>: Firmware package definitions with metadata and deployment parameters  </li> <li><code>FirmwareRule4</code>: Firmware deployment rules with conditions and priorities  </li> <li><code>DcmRule</code>: Device Configuration Manager rules for operational settings  </li> <li><code>DeviceSettings2</code>: Device operational parameters and schedules  </li> <li><code>FeatureControlRule2</code>: RDK Feature Control rules for feature activation  </li> <li><code>XconfFeature</code>: Feature definitions with parameters and specifications  </li> <li><code>TelemetryTwoProfiles</code>: Modern telemetry profile definitions  </li> <li><code>TelemetryTwoRules</code>: Rules for telemetry profile activation  </li> <li><code>Environment</code>: Environment definitions and parameters  </li> <li><code>Model</code>: Device model registry with capabilities  </li> <li><code>GenericNamespacedList</code>: Reusable lists for whitelists and device groups  </li> </ul>"},{"location":"device-management/docs/XConf/#sample-table-firmwareconfig","title":"Sample Table: <code>FirmwareConfig</code>","text":"<p>The <code>FirmwareConfig</code> table uses Cassandra's wide-row model for efficient firmware configuration storage and retrieval.</p> Column Type Description key text Composite key containing firmware config ID column1 text Grouped sub-key for data organization value blob Serialized configuration data in JSON format <p>Note</p> <p>The compound primary key structure enables efficient queries while the serialized value column contains complete firmware configuration objects, minimizing database queries required for rule evaluation.</p>"},{"location":"device-management/docs/xconf-apis-ui/","title":"XConf APIs &amp; User Interface","text":""},{"location":"device-management/docs/xconf-apis-ui/#api-endpoints","title":"API Endpoints","text":"<p>XConf provides comprehensive API coverage for device operations and administrative management. The design follows RESTful principles while accommodating high-volume device requests and complex administrative operations.</p>"},{"location":"device-management/docs/xconf-apis-ui/#device-facing-endpoints-dataservice","title":"Device-facing Endpoints (DataService)","text":""},{"location":"device-management/docs/xconf-apis-ui/#firmware-update-api","title":"Firmware Update API","text":"Field Details Endpoint <code>/xconf/swu/{applicationType}</code> Purpose Handles firmware update requests by evaluating firmware rules against device attributes. Returns firmware download information or no-update indication. Query Parameters <ul><li><code>eStbMac</code>: Device MAC address (primary identifier)</li><li><code>ipAddress</code>: Device IP address for geographic routing</li><li><code>env</code>: Environment (PROD, QA, DEV)</li><li><code>model</code>: Device model identifier</li><li><code>firmwareVersion</code>: Current firmware version</li><li><code>partnerId</code>: Partner/operator identifier</li><li><code>accountId</code>: Customer account identifier</li><li><code>capabilities</code>: Device capability flags</li><li><code>timeZone</code>: Device timezone</li><li><code>time</code>: Current device time</li></ul> Response Example (click to expand) <pre><code>{\n  \"firmwareDownloadProtocol\": \"http\",\n  \"firmwareFilename\": \"RDKV_2022Q1_sprint.bin\",\n  \"firmwareLocation\": \"http://firmware-server.com/files/\",\n  \"firmwareVersion\": \"RDKV_2022Q1_sprint_20220214040201sdy_VBN\",\n  \"rebootImmediately\": false,\n  \"upgradeDelay\": 3600\n}\n</code></pre>"},{"location":"device-management/docs/xconf-apis-ui/#dcm-settings-api","title":"DCM Settings API","text":"Field Details Endpoint <code>/loguploader/getSettings/{applicationType}</code> Purpose Provides device configuration and logging settings based on DCM rules. Returns comprehensive configuration data including cron schedules, upload destinations, and operational parameters formatted for device consumption. Query Parameters <ul><li><code>estbMacAddress</code>: Device MAC address</li><li><code>ipAddress</code>: Device IP address</li><li><code>env</code>: Environment identifier</li><li><code>model</code>: Device model</li><li><code>firmwareVersion</code>: Current firmware</li><li><code>partnerId</code>: Partner identifier</li><li><code>accountId</code>: Account identifier</li><li><code>version</code>: API version</li></ul> Response Example (click to expand) <pre><code>{\n  \"urn:settings:GroupName\": \"ProductionGroup\",\n  \"urn:settings:CheckOnReboot\": true,\n  \"urn:settings:CheckSchedule:cron\": \"0 2 * * *\",\n  \"urn:settings:LogUploadSettings:NumberOfDays\": 7,\n  \"urn:settings:LogUploadSettings:UploadRepository:URL\": \"https://logs.example.com/upload\",\n  \"urn:settings:LogUploadSettings:UploadOnReboot\": true\n}\n</code></pre>"},{"location":"device-management/docs/xconf-apis-ui/#feature-control-api","title":"Feature Control API","text":"Field Details Endpoint <code>/featureControl/getSettings/{applicationType}</code> Purpose Delivers feature control settings based on RFC rules. Evaluates feature rules against device attributes to determine enabled features, configuration parameters, and whitelist restrictions. Query Parameters <ul><li><code>estbMacAddress</code>: Device MAC address</li><li><code>ipAddress</code>: Device IP address</li><li><code>env</code>: Environment</li><li><code>model</code>: Device model</li><li><code>firmwareVersion</code>: Current firmware</li><li><code>partnerId</code>: Partner identifier</li><li><code>accountId</code>: Account identifier</li></ul> Response Example (click to expand) <pre><code>{\n  \"featureControl\": {\n    \"features\": [\n      {\n        \"name\": \"FEATURE_BLUETOOTH\",\n        \"featureName\": \"bluetooth_support\",\n        \"effectiveImmediate\": true,\n        \"enable\": true,\n        \"configData\": {\n          \"maxConnections\": \"4\",\n          \"timeout\": \"30\"\n        }\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"device-management/docs/xconf-apis-ui/#admin-endpoints-admin-service","title":"Admin Endpoints (Admin Service)","text":"<p>The administrative APIs provide comprehensive management capabilities with proper authentication, authorization, and validation for secure configuration management. These endpoints support the full lifecycle of configuration management operations.</p>"},{"location":"device-management/docs/xconf-apis-ui/#management-apis","title":"Management APIs","text":"<p>Base Endpoint: <code>/xconfAdminService/*</code></p> <p>The Admin Service provides full CRUD operations for all configuration types including firmware configs/rules, DCM settings, RFC features, and telemetry profiles. All endpoints include validation logic, testing capabilities, and bulk operations for efficient administration.</p> <p>Firmware Management APIs:</p> <ul> <li><code>GET/POST/PUT/DELETE /firmwareconfig</code> \u2014 Firmware configuration management  </li> <li><code>GET/POST/PUT/DELETE /firmwarerule</code> \u2014 Firmware rule management  </li> <li><code>POST /firmwarerule/testpage</code> \u2014 Rule testing and validation  </li> </ul> <p>DCM Management APIs:</p> <ul> <li><code>GET/POST/PUT/DELETE /dcm/deviceSettings</code> \u2014 Device settings management  </li> <li><code>GET/POST/PUT/DELETE /dcm/uploadRepository</code> \u2014 Upload repository management  </li> <li><code>POST /dcm/formula/testpage</code> \u2014 DCM rule testing  </li> </ul> <p>RFC Management APIs:</p> <ul> <li><code>GET/POST/PUT/DELETE /rfc/feature</code> \u2014 Feature definition management  </li> <li><code>GET/POST/PUT/DELETE /rfc/featurerule</code> \u2014 Feature rule management  </li> <li><code>POST /rfc/featurerule/testpage</code> \u2014 Feature rule testing  </li> </ul> <p>Telemetry Management APIs:</p> <ul> <li><code>GET/POST/PUT/DELETE /telemetry/profile</code> \u2014 Telemetry profile management  </li> <li><code>GET/POST/PUT/DELETE /telemetry/rule</code> \u2014 Telemetry rule management  </li> </ul> <p>Common Features:</p> <ul> <li>Authentication token validation for all operations  </li> <li>Role-based access control with application type isolation  </li> <li>Comprehensive input validation and sanitization  </li> <li>Bulk operations for efficient large-scale management  </li> <li>Export/import capabilities for configuration migration  </li> <li>Testing endpoints for rule validation before deployment</li> </ul>"},{"location":"device-management/docs/xconf-apis-ui/#user-interface-xconf-ui","title":"User Interface (XConf UI)","text":"<p>The XConf UI provides a comprehensive web-based management console built with AngularJS and modern web technologies. It offers intuitive forms, visual rule builders, and testing capabilities designed for operators with varying technical expertise.</p> <p>The interface uses progressive disclosure principles, presenting simple interfaces for common operations while providing access to advanced features when needed. It includes extensive validation, real-time feedback, and preview capabilities.</p>"},{"location":"device-management/docs/xconf-apis-ui/#main-modules","title":"Main Modules","text":""},{"location":"device-management/docs/xconf-apis-ui/#firmware-management","title":"Firmware Management","text":"<p>Purpose: Comprehensive tools for managing firmware deployments across device populations.</p> <p>Key Features:</p> <ul> <li>Visual rule builders with drag-and-drop interfaces</li> <li>Form-based condition editors for complex rule creation</li> <li>Firmware configuration management with metadata editing</li> <li>Testing capabilities for simulating device requests</li> <li>Bulk operations for managing large rule sets</li> <li>Export/import capabilities for configuration migration</li> <li>Real-time validation and preview of rule behavior</li> </ul> <p>Workflows:</p> <ul> <li>Create firmware configurations with version and compatibility information</li> <li>Define deployment rules with conditional logic and targeting</li> <li>Test rules against simulated device requests</li> <li>Deploy configurations with percentage-based rollouts</li> <li>Monitor deployment status and device responses</li> </ul>"},{"location":"device-management/docs/xconf-apis-ui/#dcm-management","title":"DCM Management","text":"<p>Purpose: Intuitive tools for device operational settings, logging configurations, and upload repositories.</p> <p>Key Features:</p> <ul> <li>Schedule builders for creating cron expressions visually</li> <li>Repository configuration wizards for upload destinations</li> <li>Device settings management with operational parameters</li> <li>Log upload configuration with file selection and retention</li> <li>Validation tools for configuration consistency</li> <li>Real-time preview showing how configurations appear to devices</li> </ul> <p>Workflows:</p> <ul> <li>Configure device operational schedules and policies</li> <li>Set up log collection and upload repositories</li> <li>Define VOD settings for video services</li> <li>Test DCM configurations against device profiles</li> <li>Monitor device compliance with configuration settings</li> </ul>"},{"location":"device-management/docs/xconf-apis-ui/#rfc-management","title":"RFC Management","text":"<p>Purpose: Comprehensive tools for feature definitions, rules, and whitelist configurations.</p> <p>Key Features:</p> <ul> <li>Visual feature builders for complex feature definitions</li> <li>Rule editors with support for complex conditional logic</li> <li>Whitelist management tools for device targeting</li> <li>Feature testing capabilities for simulating requests</li> <li>Bulk feature operations for large-scale management</li> <li>Priority management for feature rule conflicts</li> </ul> <p>Workflows:</p> <ul> <li>Define features with configuration parameters</li> <li>Create feature rules with device targeting logic</li> <li>Manage whitelists for controlled feature rollouts</li> <li>Test feature activation against device scenarios</li> <li>Monitor feature deployment and device adoption</li> </ul>"},{"location":"device-management/docs/xconf-apis-ui/#namespaced-list-editor","title":"Namespaced List Editor","text":"<p>Purpose: Specialized tools for creating and managing reusable lists referenced across multiple configurations.</p> <p>Key Features:</p> <ul> <li>Support for various list types (MAC addresses, IP addresses, generic values)</li> <li>Import/export capabilities for bulk list management</li> <li>Validation tools ensuring list consistency and format compliance</li> <li>Cross-reference tracking showing where lists are used</li> <li>Bulk editing operations for large lists</li> </ul> <p>Workflows:</p> <ul> <li>Create and maintain device whitelists</li> <li>Import device lists from external sources</li> <li>Validate list formats and content</li> <li>Track list usage across configurations</li> <li>Update lists with bulk operations</li> </ul>"},{"location":"device-management/docs/xconf-apis-ui/#monitoring-and-diagnostics","title":"Monitoring and Diagnostics","text":"<p>Purpose: Real-time visibility into system health, performance metrics, and operational status.</p> <p>Key Features:</p> <ul> <li>System health dashboards with key performance indicators</li> <li>Error tracking and diagnostic tools for troubleshooting</li> <li>Comprehensive logging with searchable audit trails</li> <li>Performance metrics monitoring for system optimization</li> <li>Alerting capabilities for critical events and thresholds</li> <li>Configuration change tracking and approval workflows</li> </ul> <p>Workflows:</p> <ul> <li>Monitor system performance and health metrics</li> <li>Track configuration changes and their impacts</li> <li>Investigate issues using diagnostic tools</li> <li>Set up alerts for critical system events</li> <li>Generate reports for compliance and analysis</li> </ul>"},{"location":"device-management/docs/xconf-apis-ui/#main-modules_1","title":"Main Modules","text":"Module Purpose Key Features Workflows Firmware Management Comprehensive tools for managing firmware deployments across device populations. <ul><li>Visual rule builders with drag-and-drop interfaces</li><li>Form-based condition editors</li><li>Metadata editing for firmware configurations</li><li>Simulated device request testing</li><li>Bulk rule operations</li><li>Export/import support</li><li>Real-time rule validation</li></ul> <ul><li>Create firmware configurations with version info</li><li>Define deployment rules with logic</li><li>Test rules on simulated devices</li><li>Deploy with % rollouts</li><li>Monitor deployments</li></ul> DCM Management Intuitive tools for device operational settings, logging configurations, and upload repositories. <ul><li>Cron schedule builders</li><li>Repository configuration wizards</li><li>Device settings editors</li><li>Log upload config</li><li>Validation tools</li><li>Real-time previews</li></ul> <ul><li>Configure operational policies</li><li>Set up logs &amp; repositories</li><li>Define VOD settings</li><li>Test DCM profiles</li><li>Monitor device compliance</li></ul> RFC Management Comprehensive tools for feature definitions, rules, and whitelist configurations. <ul><li>Visual feature builders</li><li>Conditional rule editors</li><li>Whitelist tools</li><li>Feature simulation testing</li><li>Bulk operations</li><li>Priority management</li></ul> <ul><li>Define features configs</li><li>Create targeting rules</li><li>Manage whitelists</li><li>Simulate feature activation</li><li>Track feature rollout</li></ul> Namespaced List Editor Specialized tools for creating and managing reusable lists used across configurations. <ul><li>Supports MAC/IP/generic types</li><li>Import/export capabilities</li><li>List validation</li><li>Cross-reference tracking</li><li>Bulk editing</li></ul> <ul><li>Create and manage whitelists</li><li>Import external lists</li><li>Validate content</li><li>Track usage across configs</li><li>Update lists in bulk</li></ul> Monitoring &amp; Diagnostics Real-time visibility into system health, performance metrics, and operational status. <ul><li>Dashboards &amp; KPIs</li><li>Error tracking &amp; diagnostics</li><li>Audit logs</li><li>Performance metrics</li><li>Alerting tools</li><li>Change tracking workflows</li></ul> <ul><li>Monitor system health</li><li>Track config changes</li><li>Investigate diagnostics</li><li>Set alerts for events</li><li>Generate reports</li></ul>"},{"location":"device-management/docs/xconf-apis-ui/#integration-use-cases-and-examples","title":"Integration Use Cases and Examples","text":"<p>XConf's comprehensive API architecture enables extensive integration with external systems, third-party tools, and enterprise infrastructure. Below are the primary integration use cases and real-world implementation examples.</p>"},{"location":"device-management/docs/xconf-apis-ui/#integration-use-cases","title":"Integration Use Cases","text":"<p>1. Device Management and Orchestration - Automated firmware deployment through CI/CD pipelines - Device configuration management via external orchestration tools - Real-time feature control and A/B testing platforms - Device health monitoring and diagnostic data collection</p> <p>2. Enterprise Monitoring and Observability - System performance monitoring with metrics collection - Log aggregation and analytics for operational intelligence - Real-time alerting and incident management - Business intelligence and firmware penetration analytics</p> <p>3. External Service Integration - Authentication and authorization with enterprise identity providers - Integration with device management platforms and account services - Third-party tagging and metadata enrichment services - Service mesh and microservices communication</p> <p>4. Infrastructure and Operations - Load balancing and high availability configurations - Backup and disaster recovery automation - Configuration change notifications and approval workflows - Compliance reporting and audit trail management</p> <p>5. Development and Deployment Workflows - Automated testing and validation of configuration changes - Staged deployment and rollback mechanisms - Environment promotion and configuration migration - Quality assurance and testing automation</p>"},{"location":"device-management/docs/xconf-apis-ui/#device-integration","title":"Device Integration","text":"<p>XConf is designed to integrate seamlessly with RDK devices through standardized API calls. Devices typically implement periodic configuration checks and event-driven updates.</p> <p>STB Firmware Update Client Example: <pre><code>#!/bin/bash\n# STB firmware update script\n\nXCONF_URL=\"http://xconf-server:9000\"\nMAC_ADDRESS=$(cat /sys/class/net/eth0/address)\nMODEL=$(cat /proc/device-tree/model)\nCURRENT_FW=$(cat /version.txt)\n\n# Request firmware update\nRESPONSE=$(curl -s \"${XCONF_URL}/xconf/swu/stb\" \\\n  -G \\\n  --data-urlencode \"eStbMac=${MAC_ADDRESS}\" \\\n  --data-urlencode \"model=${MODEL}\" \\\n  --data-urlencode \"firmwareVersion=${CURRENT_FW}\" \\\n  --data-urlencode \"env=PROD\")\n\n# Parse response and download if update available\nif echo \"$RESPONSE\" | grep -q \"firmwareLocation\"; then\n    DOWNLOAD_URL=$(echo \"$RESPONSE\" | jq -r '.firmwareLocation + .firmwareFilename')\n    wget \"$DOWNLOAD_URL\" -O /tmp/firmware.bin\n    # Install firmware and reboot\n    install_firmware /tmp/firmware.bin\nfi\n</code></pre></p> <p>Feature Control Integration: <pre><code>// JavaScript client for feature control\nclass XConfFeatureClient {\n    constructor(baseUrl, deviceInfo) {\n        this.baseUrl = baseUrl;\n        this.deviceInfo = deviceInfo;\n    }\n\n    async getFeatures() {\n        const params = new URLSearchParams(this.deviceInfo);\n        const response = await fetch(\n            `${this.baseUrl}/featureControl/getSettings/stb?${params}`\n        );\n        const data = await response.json();\n        return data.featureControl.features;\n    }\n\n    async isFeatureEnabled(featureName) {\n        const features = await this.getFeatures();\n        const feature = features.find(f =&gt; f.featureName === featureName);\n        return feature &amp;&amp; feature.enable;\n    }\n}\n\n// Usage example\nconst client = new XConfFeatureClient('http://xconf-server:9000', {\n    estbMacAddress: 'AA:BB:CC:DD:EE:FF',\n    model: 'STB_MODEL_X1',\n    env: 'PROD'\n});\n\nif (await client.isFeatureEnabled('bluetooth_support')) {\n    enableBluetooth();\n}\n</code></pre></p>"},{"location":"device-management/docs/xconf-apis-ui/#third-party-integration-examples","title":"Third-party Integration Examples","text":"<p>XConf provides extensive integration capabilities with external systems through its APIs, metrics endpoints, and external service connectors. Below are the comprehensive third-party integration examples organized by use case:</p>"},{"location":"device-management/docs/xconf-apis-ui/#use-case-1-enterprise-monitoring-and-observability","title":"Use Case 1: Enterprise Monitoring and Observability","text":"<p>Real-world Scenario: Monitor XConf system performance, track firmware deployment success rates, and alert on system issues.</p> <p>Prometheus Metrics Integration: XConf exposes comprehensive Prometheus metrics through dedicated <code>/metrics</code> endpoints on both DataService and Admin Service:</p> <pre><code># prometheus.yml configuration\nscrape_configs:\n  - job_name: 'xconf-dataservice'\n    static_configs:\n      - targets: ['localhost:9000']\n    metrics_path: '/metrics'\n    scrape_interval: 30s\n    metrics_path: '/metrics'\n\n  - job_name: 'xconf-admin'\n    static_configs:\n      - targets: ['localhost:9001']\n    metrics_path: '/metrics'\n    scrape_interval: 30s\n\n# Custom metric collection for XConf-specific metrics\n  - job_name: 'xconf-firmware-penetration'\n    static_configs:\n      - targets: ['localhost:9000']\n    metrics_path: '/metrics'\n    scrape_interval: 60s\n    metric_relabel_configs:\n      - source_labels: [__name__]\n        regex: 'xconf_firmware_penetration_counts'\n        target_label: __name__\n        replacement: 'firmware_deployment_stats'\n</code></pre> <p>Available XConf Metrics: - <code>api_requests_total</code> - Total API requests with labels for app, status code, method, path - <code>api_request_duration_seconds</code> - Request latency histograms - <code>external_api_count</code> - External service call counts (SAT, Device Service, Account Service) - <code>external_api_request_duration_seconds</code> - External API call latencies - <code>xconf_firmware_penetration_counts</code> - Firmware deployment statistics by partner/model/version - <code>in_flight_requests</code> - Current concurrent requests - <code>request_size_bytes</code> / <code>response_size_bytes</code> - Request/response size histograms - <code>log_counter</code> - Log event counters by type</p> <p>Grafana Dashboard Integration: <pre><code>{\n  \"dashboard\": {\n    \"title\": \"XConf System Monitoring\",\n    \"panels\": [\n      {\n        \"title\": \"Firmware Update Requests\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(api_requests_total{path=\\\"/xconf/swu/{applicationType}\\\"}[5m])\",\n            \"legendFormat\": \"{{method}} {{code}}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Firmware Penetration by Model\",\n        \"type\": \"piechart\",\n        \"targets\": [\n          {\n            \"expr\": \"xconf_firmware_penetration_counts\",\n            \"legendFormat\": \"{{model}} - {{fw_version}}\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre></p>"},{"location":"device-management/docs/xconf-apis-ui/#use-case-2-external-service-integration","title":"Use Case 2: External Service Integration","text":"<p>Real-world Scenario: Integrate XConf with enterprise services for authentication, device management, and account information.</p> <p>SAT (Service Access Token) Integration: XConf integrates with SAT service for secure token management:</p> <pre><code>// SAT Service Configuration\nsat {\n    SAT_REFRESH_FREQUENCY_IN_HOUR = 6\n    SAT_REFRESH_BUFFER_IN_MINS = 15\n    host = \"https://sat-service.example.com\"\n    SatOn = true\n}\n</code></pre> <p>Device Service Integration: For device metadata and account information:</p> <pre><code>// Device Service Connector Configuration\nxconfwebconfig {\n    device_service {\n        host = \"https://device-service.example.com\"\n        timeout = \"30s\"\n        retry_attempts = 3\n    }\n}\n</code></pre> <p>Account Service Integration: For customer account and timezone information:</p> <pre><code>// Account Service Configuration\nxconfwebconfig {\n    account_service {\n        host = \"https://account-service.example.com\"\n        timeout = \"30s\"\n    }\n}\n</code></pre> <p>Tagging Service Integration: For dynamic device tagging and context enrichment:</p> <pre><code>// Tagging Service Configuration\nxconfwebconfig {\n    tagging_service {\n        host = \"https://tagging-service.example.com\"\n        enable_tagging_service = true\n        enable_tagging_service_rfc = true\n    }\n}\n</code></pre>"},{"location":"device-management/docs/xconf-apis-ui/#use-case-3-devops-and-cicd-integration","title":"Use Case 3: DevOps and CI/CD Integration","text":"<p>Real-world Scenario: Automate firmware deployments and configuration management through CI/CD pipelines.</p> <p>Jenkins Pipeline Integration: <pre><code>pipeline {\n    agent any\n    stages {\n        stage('Deploy Firmware Config') {\n            steps {\n                script {\n                    // Create firmware configuration\n                    def firmwareConfig = [\n                        firmwareVersion: \"${BUILD_NUMBER}\",\n                        firmwareFilename: \"firmware-${BUILD_NUMBER}.bin\",\n                        firmwareLocation: \"https://cdn.example.com/firmware/\",\n                        supportedModelIds: [\"MODEL_X1\", \"MODEL_X2\"]\n                    ]\n\n                    // Deploy to XConf Admin API\n                    httpRequest(\n                        httpMode: 'POST',\n                        url: 'http://xconf-admin:9001/xconfAdminService/firmwareconfig',\n                        contentType: 'APPLICATION_JSON',\n                        requestBody: groovy.json.JsonBuilder(firmwareConfig).toString(),\n                        authentication: 'xconf-api-token'\n                    )\n                }\n            }\n        }\n\n        stage('Create Deployment Rule') {\n            steps {\n                script {\n                    // Create percentage-based rollout rule\n                    def deploymentRule = [\n                        name: \"Firmware ${BUILD_NUMBER} Rollout\",\n                        condition: [\n                            freeArg: [type: \"STRING\", name: \"env\"],\n                            operation: \"IS\",\n                            fixedArg: [bean: [value: [\"java.lang.String\": \"QA\"]]]\n                        ],\n                        percentage: 10, // Start with 10% rollout\n                        firmwareConfig: firmwareConfig.id\n                    ]\n\n                    httpRequest(\n                        httpMode: 'POST',\n                        url: 'http://xconf-admin:9001/xconfAdminService/firmwarerule',\n                        contentType: 'APPLICATION_JSON',\n                        requestBody: groovy.json.JsonBuilder(deploymentRule).toString()\n                    )\n                }\n            }\n        }\n    }\n}\n</code></pre></p>"},{"location":"device-management/docs/xconf-apis-ui/#use-case-4-high-availability-and-load-balancing","title":"Use Case 4: High Availability and Load Balancing","text":"<p>Real-world Scenario: Deploy XConf in high-availability configuration with load balancing and health monitoring.</p> <p>HAProxy Configuration: <pre><code># HAProxy configuration for XConf services\nglobal\n    daemon\n\ndefaults\n    mode http\n    timeout connect 5000ms\n    timeout client 50000ms\n    timeout server 50000ms\n\n# XConf DataService Backend\nbackend xconf-dataservice\n    balance roundrobin\n    option httpchk GET /healthz\n    server xconf-ds1 10.0.1.10:9000 check\n    server xconf-ds2 10.0.1.11:9000 check\n    server xconf-ds3 10.0.1.12:9000 check\n\n# XConf Admin Backend\nbackend xconf-admin\n    balance roundrobin\n    option httpchk GET /healthz\n    server xconf-admin1 10.0.1.20:9001 check\n    server xconf-admin2 10.0.1.21:9001 check\n\n# Frontend configuration\nfrontend xconf-frontend\n    bind *:80\n    bind *:443 ssl crt /etc/ssl/certs/xconf.pem\n\n    # Route device requests to DataService\n    acl is_device_request path_beg /xconf/swu /loguploader /featureControl\n    use_backend xconf-dataservice if is_device_request\n\n    # Route admin requests to Admin Service\n    acl is_admin_request path_beg /xconfAdminService\n    use_backend xconf-admin if is_admin_request\n</code></pre></p> <p>NGINX Configuration: <pre><code>upstream xconf_dataservice {\n    server 10.0.1.10:9000 max_fails=3 fail_timeout=30s;\n    server 10.0.1.11:9000 max_fails=3 fail_timeout=30s;\n    server 10.0.1.12:9000 max_fails=3 fail_timeout=30s;\n}\n\nupstream xconf_admin {\n    server 10.0.1.20:9001 max_fails=3 fail_timeout=30s;\n    server 10.0.1.21:9001 max_fails=3 fail_timeout=30s;\n}\n\nserver {\n    listen 80;\n    server_name xconf.example.com;\n\n    # Health check endpoint\n    location /health {\n        access_log off;\n        return 200 \"healthy\\n\";\n        add_header Content-Type text/plain;\n    }\n\n    # Device API routing\n    location ~ ^/(xconf|loguploader|featureControl) {\n        proxy_pass http://xconf_dataservice;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header HA-Haproxy-xconf-http \"secure\";\n\n        # Health check for upstream\n        proxy_next_upstream error timeout http_500 http_502 http_503;\n        proxy_connect_timeout 5s;\n        proxy_send_timeout 30s;\n        proxy_read_timeout 30s;\n    }\n\n    # Admin API routing\n    location /xconfAdminService {\n        proxy_pass http://xconf_admin;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n}\n</code></pre></p>"},{"location":"device-management/docs/xconf-apis-ui/#use-case-5-log-analytics-and-business-intelligence","title":"Use Case 5: Log Analytics and Business Intelligence","text":"<p>Real-world Scenario: Aggregate XConf logs for operational analytics, troubleshooting, and business intelligence.</p> <p>ELK Stack Integration: <pre><code># logstash.conf configuration for XConf logs\ninput {\n  file {\n    path =&gt; \"/var/log/xconf/xconfwebconfig.log\"\n    type =&gt; \"xconf-dataservice\"\n    codec =&gt; \"json\"\n    start_position =&gt; \"beginning\"\n  }\n\n  file {\n    path =&gt; \"/var/log/xconf/xconfadmin.log\"\n    type =&gt; \"xconf-admin\"\n    codec =&gt; \"json\"\n    start_position =&gt; \"beginning\"\n  }\n}\n\nfilter {\n  if [type] == \"xconf-dataservice\" {\n    mutate {\n      add_field =&gt; {\n        \"service\" =&gt; \"xconf-dataservice\"\n        \"component\" =&gt; \"device-api\"\n      }\n    }\n\n    # Parse firmware request logs\n    if [path] =~ /\\/xconf\\/swu/ {\n      mutate {\n        add_field =&gt; { \"request_type\" =&gt; \"firmware_update\" }\n      }\n\n      # Extract device information\n      grok {\n        match =&gt; { \"message\" =&gt; \"eStbMac=%{MAC:device_mac}\" }\n      }\n      grok {\n        match =&gt; { \"message\" =&gt; \"model=%{WORD:device_model}\" }\n      }\n    }\n  }\n\n  if [type] == \"xconf-admin\" {\n    mutate {\n      add_field =&gt; {\n        \"service\" =&gt; \"xconf-admin\"\n        \"component\" =&gt; \"admin-api\"\n      }\n    }\n  }\n\n  # Add geolocation based on IP\n  if [ipAddress] {\n    geoip {\n      source =&gt; \"ipAddress\"\n      target =&gt; \"geoip\"\n    }\n  }\n}\n\noutput {\n  elasticsearch {\n    hosts =&gt; [\"elasticsearch:9200\"]\n    index =&gt; \"xconf-%{+YYYY.MM.dd}\"\n    template_name =&gt; \"xconf\"\n    template_pattern =&gt; \"xconf-*\"\n    template =&gt; \"/etc/logstash/templates/xconf-template.json\"\n  }\n\n  # Send critical errors to alerting system\n  if [level] == \"ERROR\" {\n    http {\n      url =&gt; \"https://alertmanager.example.com/api/v1/alerts\"\n      http_method =&gt; \"post\"\n      format =&gt; \"json\"\n      mapping =&gt; {\n        \"alerts\" =&gt; [{\n          \"labels\" =&gt; {\n            \"alertname\" =&gt; \"XConfError\"\n            \"service\" =&gt; \"%{service}\"\n            \"severity\" =&gt; \"critical\"\n          }\n          \"annotations\" =&gt; {\n            \"summary\" =&gt; \"%{message}\"\n            \"description\" =&gt; \"XConf error in %{service}: %{message}\"\n          }\n        }]\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"device-management/docs/xconf-apis-ui/#use-case-6-event-driven-integration-and-notifications","title":"Use Case 6: Event-Driven Integration and Notifications","text":"<p>Real-world Scenario: Implement real-time notifications and event-driven workflows for configuration changes and system alerts.</p> <p>Webhook and Event-Driven Integration: <pre><code>// Configuration Change Webhook for Slack notifications\ntype WebhookPayload struct {\n    Event       string                 `json:\"event\"`\n    Timestamp   time.Time             `json:\"timestamp\"`\n    Service     string                `json:\"service\"`\n    EntityType  string                `json:\"entity_type\"`\n    EntityID    string                `json:\"entity_id\"`\n    Changes     map[string]interface{} `json:\"changes\"`\n    User        string                `json:\"user\"`\n}\n\nfunc NotifyConfigurationChange(entityType, entityID, user string, changes map[string]interface{}) {\n    slackPayload := map[string]interface{}{\n        \"text\": \"XConf Configuration Change Alert\",\n        \"attachments\": []map[string]interface{}{\n            {\n                \"color\": \"warning\",\n                \"fields\": []map[string]interface{}{\n                    {\"title\": \"Entity Type\", \"value\": entityType, \"short\": true},\n                    {\"title\": \"Entity ID\", \"value\": entityID, \"short\": true},\n                    {\"title\": \"Modified By\", \"value\": user, \"short\": true},\n                    {\"title\": \"Timestamp\", \"value\": time.Now().Format(time.RFC3339), \"short\": true},\n                },\n            },\n        },\n    }\n\n    // Send to Slack webhook\n    http.Post(\"https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK\",\n              \"application/json\",\n              bytes.NewBuffer(jsonPayload))\n}\n</code></pre></p> <p>PagerDuty Integration: <pre><code># alertmanager.yml configuration for XConf alerts\nroute:\n  group_by: ['alertname']\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 1h\n  receiver: 'xconf-alerts'\n\nreceivers:\n- name: 'xconf-alerts'\n  pagerduty_configs:\n  - service_key: 'YOUR_PAGERDUTY_SERVICE_KEY'\n    description: 'XConf System Alert: {{ .GroupLabels.alertname }}'\n    details:\n      service: '{{ .CommonLabels.service }}'\n      severity: '{{ .CommonLabels.severity }}'\n      summary: '{{ .CommonAnnotations.summary }}'\n\n# Prometheus alerting rules for XConf\ngroups:\n- name: xconf.rules\n  rules:\n  - alert: XConfHighErrorRate\n    expr: rate(api_requests_total{code=~\"5..\"}[5m]) &gt; 0.1\n    for: 2m\n    labels:\n      severity: critical\n      service: xconf\n    annotations:\n      summary: \"High error rate detected in XConf\"\n      description: \"XConf is experiencing {{ $value }} errors per second\"\n\n  - alert: XConfServiceDown\n    expr: up{job=~\"xconf-.*\"} == 0\n    for: 1m\n    labels:\n      severity: critical\n      service: xconf\n    annotations:\n      summary: \"XConf service is down\"\n      description: \"XConf service {{ $labels.job }} has been down for more than 1 minute\"\n</code></pre></p>"},{"location":"device-management/docs/xconf-apis-ui/#use-case-7-configuration-management-and-gitops","title":"Use Case 7: Configuration Management and GitOps","text":"<p>Real-world Scenario: Implement GitOps workflows for XConf configuration management with version control and automated deployments.</p> <p>GitLab CI/CD Integration: <pre><code># .gitlab-ci.yml for XConf configuration management\nstages:\n  - validate\n  - deploy-staging\n  - deploy-production\n\nvariables:\n  XCONF_ADMIN_URL: \"https://xconf-admin.example.com\"\n\nvalidate-config:\n  stage: validate\n  script:\n    - |\n      # Validate firmware configuration JSON\n      for config in configs/firmware/*.json; do\n        echo \"Validating $config\"\n        jq empty \"$config\" || exit 1\n\n        # Test configuration against XConf Admin API\n        curl -X POST \"$XCONF_ADMIN_URL/xconfAdminService/firmwareconfig/testpage\" \\\n          -H \"Authorization: Bearer $XCONF_API_TOKEN\" \\\n          -H \"Content-Type: application/json\" \\\n          -d @\"$config\" \\\n          --fail\n      done\n\ndeploy-staging:\n  stage: deploy-staging\n  script:\n    - |\n      # Deploy to staging environment\n      for config in configs/firmware/*.json; do\n        CONFIG_ID=$(jq -r '.id' \"$config\")\n\n        # Update existing or create new configuration\n        curl -X PUT \"$XCONF_ADMIN_URL/xconfAdminService/firmwareconfig\" \\\n          -H \"Authorization: Bearer $XCONF_API_TOKEN\" \\\n          -H \"Content-Type: application/json\" \\\n          -d @\"$config\" \\\n          --fail\n\n        echo \"Deployed firmware config: $CONFIG_ID\"\n      done\n  environment:\n    name: staging\n  only:\n    - develop\n\ndeploy-production:\n  stage: deploy-production\n  script:\n    - |\n      # Deploy to production with approval\n      for config in configs/firmware/*.json; do\n        CONFIG_ID=$(jq -r '.id' \"$config\")\n\n        # Create deployment with percentage rollout\n        ROLLOUT_CONFIG=$(jq '. + {\"percentage\": 5}' \"$config\")\n\n        curl -X PUT \"$XCONF_ADMIN_URL/xconfAdminService/firmwareconfig\" \\\n          -H \"Authorization: Bearer $XCONF_API_TOKEN\" \\\n          -H \"Content-Type: application/json\" \\\n          -d \"$ROLLOUT_CONFIG\" \\\n          --fail\n\n        echo \"Deployed firmware config to production: $CONFIG_ID (5% rollout)\"\n      done\n  environment:\n    name: production\n  when: manual\n  only:\n    - main\n</code></pre></p> <p>Terraform Integration for Infrastructure as Code: <pre><code># terraform/xconf-infrastructure.tf\nresource \"kubernetes_deployment\" \"xconf_dataservice\" {\n  metadata {\n    name = \"xconf-dataservice\"\n    namespace = \"xconf\"\n  }\n\n  spec {\n    replicas = 3\n\n    selector {\n      match_labels = {\n        app = \"xconf-dataservice\"\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app = \"xconf-dataservice\"\n        }\n        annotations = {\n          \"prometheus.io/scrape\" = \"true\"\n          \"prometheus.io/port\" = \"9000\"\n          \"prometheus.io/path\" = \"/metrics\"\n        }\n      }\n\n      spec {\n        container {\n          name = \"xconf-dataservice\"\n          image = \"xconf/dataservice:${var.xconf_version}\"\n\n          port {\n            container_port = 9000\n            name = \"http\"\n          }\n\n          env {\n            name = \"CASSANDRA_HOSTS\"\n            value = \"${var.cassandra_hosts}\"\n          }\n\n          env {\n            name = \"TOKEN_API_ENABLED\"\n            value = \"true\"\n          }\n\n          liveness_probe {\n            http_get {\n              path = \"/healthz\"\n              port = 9000\n            }\n            initial_delay_seconds = 30\n            period_seconds = 10\n          }\n\n          readiness_probe {\n            http_get {\n              path = \"/healthz\"\n              port = 9000\n            }\n            initial_delay_seconds = 5\n            period_seconds = 5\n          }\n        }\n      }\n    }\n  }\n}\n\nresource \"kubernetes_service\" \"xconf_dataservice\" {\n  metadata {\n    name = \"xconf-dataservice\"\n    namespace = \"xconf\"\n    annotations = {\n      \"service.beta.kubernetes.io/aws-load-balancer-type\" = \"nlb\"\n    }\n  }\n\n  spec {\n    selector = {\n      app = \"xconf-dataservice\"\n    }\n\n    port {\n      port = 80\n      target_port = 9000\n      protocol = \"TCP\"\n    }\n\n    type = \"LoadBalancer\"\n  }\n}\n</code></pre></p>"},{"location":"device-management/docs/xconf-apis-ui/#use-case-8-business-intelligence-and-analytics","title":"Use Case 8: Business Intelligence and Analytics","text":"<p>Real-world Scenario: Extract business insights from XConf data for firmware adoption analysis and device management optimization.</p> <p>Apache Airflow DAG for Data Pipeline: <pre><code># airflow/dags/xconf_analytics_pipeline.py\nfrom airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\nfrom airflow.operators.bash_operator import BashOperator\nfrom datetime import datetime, timedelta\nimport requests\nimport pandas as pd\n\ndefault_args = {\n    'owner': 'data-team',\n    'depends_on_past': False,\n    'start_date': datetime(2023, 1, 1),\n    'email_on_failure': True,\n    'email_on_retry': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5)\n}\n\ndag = DAG(\n    'xconf_analytics_pipeline',\n    default_args=default_args,\n    description='XConf data analytics pipeline',\n    schedule_interval='@daily',\n    catchup=False\n)\n\ndef extract_firmware_penetration():\n    \"\"\"Extract firmware penetration data from XConf metrics\"\"\"\n    response = requests.get('http://xconf-dataservice:9000/metrics')\n    metrics_data = response.text\n\n    # Parse Prometheus metrics for firmware penetration\n    penetration_data = []\n    for line in metrics_data.split('\\n'):\n        if 'xconf_firmware_penetration_counts' in line and not line.startswith('#'):\n            # Parse metric line: xconf_firmware_penetration_counts{model=\"X1\",fw_version=\"1.0\"} 1500\n            parts = line.split(' ')\n            value = int(parts[1])\n            labels = parts[0].split('{')[1].split('}')[0]\n\n            # Extract labels\n            label_dict = {}\n            for label in labels.split(','):\n                key, val = label.split('=')\n                label_dict[key] = val.strip('\"')\n\n            penetration_data.append({\n                'model': label_dict.get('model'),\n                'firmware_version': label_dict.get('fw_version'),\n                'device_count': value,\n                'date': datetime.now().date()\n            })\n\n    # Save to data warehouse\n    df = pd.DataFrame(penetration_data)\n    df.to_sql('firmware_penetration_daily', con=warehouse_connection, if_exists='append')\n\ndef generate_analytics_report():\n    \"\"\"Generate daily analytics report\"\"\"\n    query = \"\"\"\n    SELECT\n        model,\n        firmware_version,\n        device_count,\n        LAG(device_count) OVER (PARTITION BY model, firmware_version ORDER BY date) as prev_count,\n        (device_count - LAG(device_count) OVER (PARTITION BY model, firmware_version ORDER BY date)) as daily_change\n    FROM firmware_penetration_daily\n    WHERE date = CURRENT_DATE\n    \"\"\"\n\n    df = pd.read_sql(query, warehouse_connection)\n\n    # Generate report\n    report = {\n        'total_devices': df['device_count'].sum(),\n        'models_updated': len(df[df['daily_change'] &gt; 0]),\n        'top_growing_firmware': df.nlargest(5, 'daily_change')[['model', 'firmware_version', 'daily_change']].to_dict('records')\n    }\n\n    # Send to business intelligence dashboard\n    requests.post('https://bi-dashboard.example.com/api/xconf-daily-report', json=report)\n\nextract_task = PythonOperator(\n    task_id='extract_firmware_penetration',\n    python_callable=extract_firmware_penetration,\n    dag=dag\n)\n\nanalytics_task = PythonOperator(\n    task_id='generate_analytics_report',\n    python_callable=generate_analytics_report,\n    dag=dag\n)\n\nextract_task &gt;&gt; analytics_task\n</code></pre></p>"},{"location":"device-management/docs/xconf-security-deployment/","title":"XConf Security &amp; Deployment","text":""},{"location":"device-management/docs/xconf-security-deployment/#authentication-authorization","title":"Authentication &amp; Authorization","text":"<p>XConf implements a comprehensive security model with flexible access control for different organizational structures. The system supports external authentication providers and role-based access control (RBAC) built on the principle of least privilege.</p>"},{"location":"device-management/docs/xconf-security-deployment/#token-based-authentication","title":"Token-based Authentication","text":"<p>XConf uses OAuth2 providers for secure access control with configurable token validation endpoints. This enables integration with existing organizational identity management systems while maintaining secure access to configuration functions.</p> <pre><code>type AuthConfig struct {\n    TokenAPIEnabled    bool   `json:\"token_api_enabled\"`\n    TokenValidationURL string `json:\"token_validation_url\"`\n    AuthProvider       string `json:\"auth_provider\"`\n}\n</code></pre> <p>Authentication Flow:</p> <ol> <li>User authenticates with external OAuth2 provider</li> <li>Provider issues authentication token</li> <li>XConf validates token with configured validation endpoint</li> <li>System determines user's authorized application types and permissions</li> <li>Access granted based on token validation and permission matrix</li> </ol> <p>Token Validation Features:</p> <ul> <li>Configurable validation endpoints for different OAuth2 providers</li> <li>Support for custom authentication systems</li> <li>Token refresh mechanisms for session management</li> <li>Automatic token expiration and renewal handling</li> </ul>"},{"location":"device-management/docs/xconf-security-deployment/#application-type-isolation","title":"Application Type Isolation","text":"<p>XConf ensures users can only access resources for their authorized application types (STB, xHome, rdkCloud) with strict isolation between environments. Each user's access is scoped to specific application types based on authentication credentials and role assignments.</p> <p>Isolation Benefits:</p> <ul> <li>Prevents cross-contamination between device populations</li> <li>Enables specialized teams to manage specific device types</li> <li>Supports multi-tenant deployments with clear boundaries</li> <li>Reduces risk of configuration errors affecting wrong device types</li> </ul> <p>Implementation:</p> <ul> <li>Application type embedded in authentication tokens</li> <li>API endpoints validate application type access</li> <li>Database queries filtered by application type</li> <li>UI dynamically adjusts based on user's application access</li> </ul>"},{"location":"device-management/docs/xconf-security-deployment/#permission-validation-flow","title":"Permission Validation Flow","text":"<p>The system follows structured validation that extracts and validates authentication tokens, determines authorized application types, and checks specific operation permissions. This includes both resource-level and operation-level access checks for granular permission control.</p> <p>Validation Steps:</p> <ol> <li>Token Extraction: Authentication token extracted from request headers</li> <li>Token Validation: Token verified with authentication provider</li> <li>Application Type Check: User's authorized application types determined</li> <li>Resource Access Check: Verify user can access requested resource type</li> <li>Operation Permission Check: Confirm user can perform specific operation</li> <li>Final Authorization: Grant or deny access based on complete validation</li> </ol>"},{"location":"device-management/docs/xconf-security-deployment/#security-features","title":"Security Features","text":"<p>XConf implements multiple security layers protecting against common attack vectors while maintaining usability and performance. The architecture addresses external threats and internal security requirements.</p>"},{"location":"device-management/docs/xconf-security-deployment/#request-validation-and-input-security","title":"Request Validation and Input Security","text":"<p>Input Sanitization:</p> <ul> <li>Comprehensive validation prevents injection attacks through input sanitization</li> <li>All user inputs undergo strict validation before processing</li> <li>Parameterized database queries prevent SQL injection</li> <li>Input length limits and format validation prevent buffer overflows</li> </ul> <p>XSS Protection:</p> <ul> <li>Cross-site scripting protection throughout the web interface</li> <li>Content Security Policy (CSP) headers prevent script injection</li> <li>Input encoding and output escaping for all user-generated content</li> <li>Secure cookie handling with HttpOnly and Secure flags</li> </ul> <p>Request Rate Limiting:</p> <ul> <li>DoS prevention through configurable rate limiting</li> <li>Per-user and per-IP request throttling</li> <li>Adaptive rate limiting based on system load</li> <li>Graceful degradation under high load conditions</li> </ul>"},{"location":"device-management/docs/xconf-security-deployment/#data-protection-and-encryption","title":"Data Protection and Encryption","text":"<p>Communication Security:</p> <ul> <li>All administrative communications use secure HTTPS channels</li> <li>TLS 1.2+ required for all external communications</li> <li>Certificate validation and pinning for enhanced security</li> <li>Secure WebSocket connections for real-time features</li> </ul> <p>Data Encryption:</p> <ul> <li>Sensitive configuration data encrypted at rest in database</li> <li>Encryption keys managed through secure key management system</li> <li>Field-level encryption for highly sensitive data</li> <li>Secure backup and recovery procedures for encrypted data</li> </ul> <p>Audit and Compliance:</p> <ul> <li>Comprehensive audit logging for all administrative actions</li> <li>Immutable audit trail for compliance reporting</li> <li>Detailed change tracking with modification histories</li> <li>Automated compliance reporting and alerting</li> </ul>"},{"location":"device-management/docs/xconf-security-deployment/#access-control-and-session-management","title":"Access Control and Session Management","text":"<p>Fine-grained Authorization:</p> <ul> <li>Role-based permissions beyond basic authentication</li> <li>Resource-level and operation-level access controls</li> <li>Dynamic permission evaluation based on context</li> <li>Principle of least privilege enforcement</li> </ul> <p>Session Security:</p> <ul> <li>Configurable session timeouts with automatic termination</li> <li>Secure session token generation and management</li> <li>Session invalidation on suspicious activity</li> <li>Multi-factor authentication support for sensitive operations</li> </ul> <p>Network Security:</p> <ul> <li>IP-based access restrictions for administrative interfaces</li> <li>VPN requirement options for remote access</li> <li>Network segmentation between components</li> <li>Firewall rules and network access controls</li> </ul>"},{"location":"device-management/docs/xconf-security-deployment/#deployment-and-configuration","title":"Deployment and Configuration","text":"<p>XConf's modular architecture supports flexible deployment from development setups to large-scale production environments serving millions of devices. Each component can be deployed independently for optimal scaling based on specific load characteristics.</p>"},{"location":"device-management/docs/xconf-security-deployment/#xconf-dataservice-configuration","title":"XConf DataService Configuration","text":"<p>Core service configuration emphasizing performance optimization for high-volume device requests:</p> <pre><code>xconfwebconfig {\n  # Build and version information\n  code_git_commit = \"xconfwebconfig-22.2.14-461.879f957\"\n  build_time = \"Thu Feb 14 02:14:00 2022 UTC\"\n  token_api_enabled = true\n\n  # Database configuration\n  cassandra {\n    hosts = [\"localhost:9042\"]\n    keyspace = \"ApplicationsDiscoveryDataService\"\n    consistency = \"ONE\"\n    timeout = \"10s\"\n    max_connections = 100\n    retry_policy = \"default\"\n  }\n\n  # HTTP server configuration\n  server {\n    port = 9000\n    read_timeout = \"30s\"\n    write_timeout = \"30s\"\n    idle_timeout = \"60s\"\n    max_header_bytes = 1048576\n  }\n\n  # Performance optimization\n  cache {\n    enabled = true\n    ttl = \"300s\"\n    max_entries = 10000\n    eviction_policy = \"LRU\"\n  }\n\n  # Logging configuration\n  logging {\n    level = \"INFO\"\n    format = \"json\"\n    output = \"stdout\"\n  }\n}\n</code></pre>"},{"location":"device-management/docs/xconf-security-deployment/#key-configuration-areas","title":"Key Configuration Areas:","text":"<ul> <li>Database Connection: Optimized for high-throughput device requests</li> <li>Caching Strategy: Reduces database load for frequently requested configurations</li> <li>Timeout Settings: Balanced for responsiveness and resource conservation</li> <li>Logging: Structured logging for operational visibility</li> </ul>"},{"location":"device-management/docs/xconf-security-deployment/#xconf-admin-configuration","title":"XConf Admin Configuration","text":"<p>Administrative service configuration focusing on security and external system integration:</p> <pre><code>xconfwebconfig {\n  ProjectName = \"xconfadmin\"\n\n  # Server configuration with security features\n  server {\n    port = 9001\n    cors_enabled = true\n    allowed_origins = [\"http://localhost:8081\", \"https://admin.example.com\"]\n    allowed_methods = [\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"]\n    allowed_headers = [\"Content-Type\", \"Authorization\"]\n  }\n\n  # Authentication and authorization\n  auth {\n    enabled = true\n    provider = \"oauth2\"\n    token_validation_url = \"https://auth.example.com/validate\"\n    required_scopes = [\"xconf:admin\"]\n    token_cache_ttl = \"300s\"\n  }\n\n  # Database configuration\n  cassandra {\n    hosts = [\"localhost:9042\"]\n    keyspace = \"ApplicationsDiscoveryDataService\"\n    consistency = \"QUORUM\"\n    timeout = \"30s\"\n  }\n\n  # Security settings\n  security {\n    session_timeout = \"3600s\"\n    max_login_attempts = 5\n    lockout_duration = \"900s\"\n  }\n}\n</code></pre>"},{"location":"device-management/docs/xconf-security-deployment/#security-focus-areas","title":"Security Focus Areas:","text":"<ul> <li>CORS Configuration: Secure cross-origin resource sharing</li> <li>Authentication Integration: OAuth2 provider integration</li> <li>Session Management: Secure session handling and timeouts</li> <li>Access Control: Role-based permissions and restrictions</li> </ul>"},{"location":"device-management/docs/xconf-security-deployment/#xconf-ui-configuration","title":"XConf UI Configuration","text":"<p>Web interface configuration for backend integration and security:</p> <pre><code>xconfui {\n  # Backend service endpoints\n  xconfadmin {\n    host = \"http://localhost:9001/xconfAdminService\"\n    timeout = \"30s\"\n    retry_attempts = 3\n  }\n\n  xconfdataservice {\n    host = \"http://localhost:9000\"\n    timeout = \"10s\"\n    retry_attempts = 2\n  }\n\n  # UI server configuration\n  server {\n    port = 8081\n    static_files = \"./app\"\n    index_file = \"index.html\"\n    gzip_enabled = true\n  }\n\n  # Security headers and policies\n  security {\n    content_security_policy = \"default-src 'self'; script-src 'self' 'unsafe-inline'\"\n    x_frame_options = \"DENY\"\n    x_content_type_options = \"nosniff\"\n    strict_transport_security = \"max-age=31536000; includeSubDomains\"\n  }\n\n  # Caching and performance\n  cache {\n    static_cache_duration = \"86400s\"\n    api_cache_duration = \"300s\"\n  }\n}\n</code></pre>"},{"location":"device-management/docs/xconf-security-deployment/#ui-specific-features","title":"UI-Specific Features:","text":"<ul> <li>Backend Integration: Optimized communication with admin and data services</li> <li>Security Headers: Comprehensive web security headers</li> <li>Performance Optimization: Caching and compression for better user experience</li> <li>Static Asset Management: Efficient serving of web application resources</li> </ul>"},{"location":"device-management/docs/xconf-security-deployment/#setup-and-deployment","title":"Setup and Deployment","text":"<p>XConf setup requires attention to system prerequisites, database configuration, and service coordination. The process is designed for straightforward deployment with flexibility for different operational environments.</p>"},{"location":"device-management/docs/xconf-security-deployment/#prerequisites","title":"Prerequisites","text":""},{"location":"device-management/docs/xconf-security-deployment/#system-requirements","title":"System Requirements","text":"Requirement Details OS Ubuntu 18.04+, CentOS 7+, RHEL 7+ RAM Minimum 4GB (8GB+ recommended) Disk Space 50GB+ for database and logs Network Required for device communication Firewall Proper configuration for service ports"},{"location":"device-management/docs/xconf-security-deployment/#software-dependencies","title":"Software Dependencies","text":"Dependency Version/Note Purpose Cassandra 3.x+ (4.x recommended) Database Go 1.18+ Required for building from source Git Latest Source code management Make Latest Build automation"},{"location":"device-management/docs/xconf-security-deployment/#go-module-dependencies","title":"Go Module Dependencies","text":"<pre><code>// Core dependencies managed through Go modules\nrequire (\n    github.com/gorilla/mux v1.8.0        // HTTP routing and middleware\n    github.com/gocql/gocql v1.0.0        // Cassandra database connectivity\n    github.com/sirupsen/logrus v1.8.1    // Structured logging\n    github.com/google/uuid v1.3.0        // UUID generation for entities\n    github.com/rs/cors v1.8.0            // CORS support for web APIs\n)\n</code></pre>"},{"location":"device-management/docs/xconf-security-deployment/#database-setup","title":"Database Setup","text":"<p>Cassandra Installation: <pre><code># Install Cassandra on Ubuntu/Debian\nsudo apt-get update\nsudo apt-get install openjdk-8-jdk\necho \"deb http://www.apache.org/dist/cassandra/debian 40x main\" | sudo tee -a /etc/apt/sources.list.d/cassandra.sources.list\ncurl https://www.apache.org/dist/cassandra/KEYS | sudo apt-key add -\nsudo apt-get update\nsudo apt-get install cassandra\n\n# Configure and start Cassandra\nsudo systemctl start cassandra\nsudo systemctl enable cassandra\n\n# Verify installation\nsudo systemctl status cassandra\ncqlsh localhost 9042\n</code></pre></p> <p>Schema Initialization: <pre><code># Create XConf database schema\ncqlsh localhost 9042\n\n# Execute schema creation script\nSOURCE 'xconfwebconfig/db/dbinit.cql';\n\n# Verify table creation\nDESCRIBE KEYSPACE \"ApplicationsDiscoveryDataService\";\n</code></pre></p> <p>Schema Structure: <pre><code>-- Create keyspace with appropriate replication\nCREATE KEYSPACE IF NOT EXISTS \"ApplicationsDiscoveryDataService\"\nWITH replication = {\n  'class': 'SimpleStrategy', \n  'replication_factor': 1\n};\n\nUSE \"ApplicationsDiscoveryDataService\";\n\n-- Create core configuration tables\nCREATE TABLE IF NOT EXISTS \"FirmwareConfig\" (\n    key text,\n    column1 text,\n    value blob,\n    PRIMARY KEY ((key), column1)\n) WITH COMPACT STORAGE;\n\nCREATE TABLE IF NOT EXISTS \"DcmRule\" (\n    key text,\n    column1 text,\n    value blob,\n    PRIMARY KEY ((key), column1)\n) WITH COMPACT STORAGE;\n\n-- Additional tables follow similar wide-row patterns\n</code></pre></p> <p>Production Considerations</p> <p>For production deployments, consider using NetworkTopologyStrategy for replication and adjust replication factors based on cluster size and availability requirements.</p>"},{"location":"device-management/docs/xconf-security-deployment/#application-deployment","title":"Application Deployment","text":"<p>Build and Deploy Services: <pre><code># Build XConf DataService\ncd xconfwebconfig\nmake build\nsudo cp xconfwebconfig /usr/local/bin/\nsudo cp sample_xconfwebconfig.conf /etc/xconf/\n\n# Build XConf Admin Service\ncd ../xconfadmin\nmake build\nsudo cp xconfadmin /usr/local/bin/\nsudo cp sample_xconfadmin.conf /etc/xconf/\n\n# Build XConf UI\ncd ../xconfui\nmake build\nsudo cp xconfui /usr/local/bin/\nsudo cp sample_xconfui.conf /etc/xconf/\n</code></pre></p> <p>Service Startup: <pre><code># Start services in dependency order\nsudo systemctl start cassandra\n\n# Start XConf DataService\nsudo systemctl start xconf-dataservice\n\n# Start XConf Admin Service\nsudo systemctl start xconf-admin\n\n# Start XConf UI\nsudo systemctl start xconf-ui\n</code></pre></p> <p>Verification: <pre><code># Check service health\ncurl http://localhost:9000/health\ncurl http://localhost:9001/xconfAdminService/health\ncurl http://localhost:8081/health\n\n# Test basic functionality\ncurl \"http://localhost:9000/xconf/swu/stb?eStbMac=AA:BB:CC:DD:EE:FF&amp;model=TEST_MODEL\"\n</code></pre></p>"},{"location":"device-management/docs/xconf-security-deployment/#production-deployment-considerations","title":"Production Deployment Considerations","text":"<p>High Availability:</p> <ul> <li>Deploy multiple instances behind load balancer (HAProxy, NGINX)</li> <li>Use Cassandra cluster with replication factor \u2265 3</li> <li>Implement health checks and auto-restart mechanisms</li> <li>Set up monitoring and alerting for service availability</li> </ul> <p>Performance Optimization:</p> <ul> <li>Configure appropriate JVM settings for Cassandra</li> <li>Tune database connection pools and timeouts</li> <li>Implement application-level caching strategies</li> <li>Monitor and optimize query performance</li> </ul> <p>Security Hardening:</p> <ul> <li>Enable HTTPS/TLS for all communications</li> <li>Configure proper authentication provider integration</li> <li>Set up network firewalls and access controls</li> <li>Implement regular security updates and patches</li> <li>Enable audit logging and monitoring</li> </ul> <p>Backup and Recovery:</p> <ul> <li>Regular Cassandra backups using nodetool snapshot</li> <li>Configuration file versioning and backup</li> <li>Disaster recovery procedures and testing</li> <li>Data retention policies and cleanup procedures</li> </ul>"},{"location":"devices/docs/overview/","title":"Place Holder markdown for Devices page","text":""},{"location":"entertainment/docs/","title":"Overview","text":"Getting Started with RDK for Entertainment Architecture <p>         The latest release of RDK6 comes with major changes in its architecture, including Firebolt - RDK's resident app platform - and the vendor porting kit - among other major changes. To know more details of the RDK Architecture, follow the below link          Click Here </p> Features <p>         A deciding factor of any software stack is the number of user centric features that are supported by that software.  To know what are the features supported by the RDK software stack for various target profiles, follow the below link          Click Here </p> Device Profiles <p>         From the fundamental RDK IP STB to the more sophisticated RDK TV, RDK offers a variety of device profiles: IP STB, Hybrid STB, and RDK TV. To know the details of core components available across profiles, as well as on the differentiating components, please follow below link          Click Here </p> Try Out RDK <p>         The best way to experience RDK is to try out RDK youself in a platform. Get yourself started in exploring RDK, by generating an RDK build of your own, and then getting it up on the popular generic reference platform Raspberry Pi 4          Click Here </p> Vendor Porting Guide <p>          If you are trying to bring up/ port RDK to your SOC platform, you can refer to the Hardware Porting Kit to understand the various HAL APIs that need to be implemented in order to complete the RDK Porting          Click Here </p> RDK Components <p>         To understand the architecture of each RDK component, how the component interfaces with other components as well as other layers of RDK, please follow the below link          Click Here </p>"},{"location":"entertainment/docs/architecture/","title":"Architecture","text":"<p>RDK Video (RDK-V ) Architecture is designed to enable service providers and device manufacturers to develop and deploy innovative video applications, services, and user experiences. It consists of several key components that work together seamlessly to provide a robust video platform.</p> <p>By leveraging the pluggable architecture of RDK-V, a variety of target device profiles can be supported, ranging from a basic IP streaming video platform to a full-fledged TV.</p> <ul> <li>IP provides a common method to manage video playback functions. The IP client device serves as an interface and receives video content from an in-home gateway device or from an external media server.</li> <li>Hybrid is an IP video platform device with capabilities such as tuning and conditional access for its video delivery to manage hybrid video functions.</li> <li>TV is an open-source smart TV profile that allows manufacturers and operations to build RDK-based TV and video solutions.</li> <li>RDK Hybrid TV is a combination of TV plus Hybrid capabilities such as tuning, conditional access, etc.</li> </ul>"},{"location":"entertainment/docs/architecture/#evolution-of-rdk","title":"Evolution of RDK","text":"<p>From RDK6, RDK-V shifted from quarterly to annual release cycles. This annual RDK release aims to synchronize RDK-V with standard industry release practices while comprehensively addressing shared challenges within the community. This approach facilitates the smoother and more consistent adoption of newly contributed features, utilizing the latest releases from technology partners. By aligning with SoC partners, the release enables better resource planning to support core RDK-V platforms. Furthermore, the RDK-V release aligns with SoC, OEM, and app releases, fostering a more cohesive and efficient ecosystem. The first annual release is RDK6, and its release notes can be accessed from RDK6 Release Notes.</p> <p></p>"},{"location":"entertainment/docs/architecture/#architecture-details","title":"Architecture Details","text":"<p>Below is an illustrative representation of the RDK-V software stack, depicting the various components and their interactions.</p> <p></p> <p>At its core, RDK-V consists of five main stack levels, each serving a specific purpose in the overall architecture. These levels are as follows:</p>"},{"location":"entertainment/docs/architecture/#applications","title":"Applications","text":"<p>The application layer primarily focuses on the end-user experience. This layer contains applications that provide various services, content, and features to the users. While the RDK-V ecosystem is continuously evolving, supported applications typically include popular OTT services like Netflix, Amazon Prime Video, and YouTube, alongside native broadcaster applications and other services.</p>"},{"location":"entertainment/docs/architecture/#application-platform","title":"Application Platform","text":"<p>The Application Platform Layer in the RDK-V ecosystem offers essential tools for developers to create applications. It includes components like a UI framework , HTML5 rendering engine, and a JavaScript runtime . This layer acts as a communication channel, serving as a middleware between applications and core RDK-V services. In the RDK-V framework, Firebolt\u00ae handles UI rendering and user input, enabling extensive customization. Lightning\u2122, an open-source JavaScript platform, manages the application lifecycle and integrates components using WebGL for rendering. Together, Firebolt\u00ae and Lightning\u2122 form a robust foundation for seamless and efficient application development in the RDK-V ecosystem.</p> <p>Firebolt\u00ae 1.0 (Ripple) - Firebol\u00ae 1.0 (Ripple) streamlines RDK-V app integration with standardized rules. Ripple, its open-source Rust-based Application gateway, facilitates dynamic extensions and serves as a Firebolt\u00ae gateway. RDK 6 is Firebolt\u00ae 1.0-certified, with a comprehensive test suite for compliance.</p> <p>Security - The Application Platform Layer ensures robust security with Dobby-managed containerization, leveraging Linux kernel features for process isolation. Downloadable Application Containers (DAC) enable the secure running of binary applications on\u00a0video platforms without modification, ensuring compatibility across RDK 6 devices. Access control is enforced through AppArmor, a proactive Linux security system. RDKM's open-sourced AppArmor profile generator tool for RDK 6 provides fine-grained control over process resources, contributing to a secure environment.</p>"},{"location":"entertainment/docs/architecture/#rdk-middleware","title":"RDK Middleware","text":"<p>Serving as a vital bridge between the Application Platform Layer and the hardware (HAL), the RDK Middleware Layer incorporates essential components that are pivotal for the seamless operation of the RDK-V platform. Core to this layer are RDK services, providing JSON-RPC services for interactive applications. In the realm of security, iCrypto handles critical cryptographic operations, ensuring secure communication and data protection. Rialto offers a secure solution for AV pipelines in containerized applications, and the Window Manager orchestrates GUI layout. Device management enables streamlined operations in RDK deployments, including bulk operations and firmware downloads. XCONF integration revolutionizes code downloads for a smoother deployment experience. Log uploads aid in comprehensive debugging, offering insights into system performance. RDK Feature Control (RFC) enables dynamic feature management for enhanced flexibility. Telemetry systematically collects essential data insights, while WebPA ensures secure communication between cloud servers and RDK devices. The Media Player, crucial for local rendering devices, manages various pipeline functions, supporting IP and QAM playback. The Open Content Decryption Module(OCDM) enforces Digital Rights Management (DRM) policies. Together with other RDK-V elements, these components ensure the efficient and secure functioning of the RDK-V platform.</p>"},{"location":"entertainment/docs/architecture/#rdk-hal-hardware-abstraction-layer","title":"RDK HAL (Hardware Abstraction Layer)","text":"<p>In the RDK-V stack, the HAL layer plays a vital role in facilitating communication between the video application software and hardware components like the GPU, video encoding/decoding hardware, and audio devices. It provides a standardized framework for functions, data structures, and protocols, enabling efficient hardware resource utilization. The HAL layer manages hardware initialization, input/output operations, and hardware-specific events, shielding software developers from hardware complexities and allowing them to prioritize user experience and functionality.</p> <p>RDK-V provides a set of HAL APIs that abstract the platform from RDK. Vendors need to implement the HAL APIs to meet the HAL specifications. With the help of the HAL API specification for different RDK-V components, vendors can successfully port RDK-V to their platform. Depending on the device profile (IP, TV, Hybrid, etc.), vendors may choose the relevant components and perform the port by implementing the HAL layer. For more details on the vendor porting process, refer to the Vendor Porting Guide.</p>"},{"location":"entertainment/docs/architecture/#soc","title":"SOC","text":"<p>The System on Chip (SOC) layer forms the foundational interface between hardware components, ensuring system security and reliability. It incorporates various crucial elements, such as DRM Libraries, which manage digital rights and secure content delivery to prevent unauthorized access and distribution. Trusted Applications (Apps TA) guarantee the secure execution of sensitive operations and protect critical data from unauthorized access. The Secure Store oversees the storage of DRM keys and apps triplets, maintaining the confidentiality and integrity of vital data. Additionally, MFR Libraries manage hardware functionality, providing access to specific hardware features and capabilities, thereby contributing to the overall security and functionality of the system.</p>"},{"location":"entertainment/docs/architecture/#application-scenario","title":"Application Scenario","text":"<p>Consider the use case of a user accessing a streaming application like Youtube on an RDK Video-supported device. The user interacts with the application through the Application Layer, selecting content and initiating playback. The Application Platform Layer, utilizing the Firebolt\u00ae and Lightning\u2122 frameworks, manages the user interface and application lifecycle. The RDK-V Layer ensures seamless communication between the application and the hardware, managing services, cryptographic operations, inter-component communication, window management, and content decryption through OpenCDM. The RDK HAL Layer then utilizes the Gstreamer media pipeline to decode and render the video content, ensuring a smooth and high-quality viewing experience. Finally, the SOC Layer provides a secure environment for the entire system, safeguarding the hardware, managing DRM policies, and securing sensitive data, ensuring a secure and reliable video streaming experience for the user.</p>"},{"location":"entertainment/docs/architecture/#useful-links","title":"Useful Links","text":"<p>RDK-V:</p> <p>You can find an overview of the RDK-V platform, detailing its key features and functionalities at RDK Video Documentation.</p> <p>Applications:</p> <p>To get the information about various applications supported by the RDK-V, aiding in understanding the diverse application landscape refer RDK Video Accelerator - Applications.</p> <p>Application Development:</p> <p>Developers interested in RDK-V application development using Firebolt \u00ae can refer Firebolt\u00ae Overview,</p> <p>Developers interested in RDK-V application development using Lightning\u2122 the inhouse JavaScript framework - can refer Lightning\u2122 Framework.</p> <p>Security:</p> <p>Understanding the concept of containerization in RDK-V is crucial for ensuring secure and efficient application deployment, and the 'Containerization in RDK' document provides in-depth insights into this aspect.</p> <p>To learn about the implementation and benefits of Downloadable Application Containers (DAC) within the RDK-V ecosystem, the 'DAC Documentation' offers comprehensive guidance for developers.</p> <p>For insight into the Access Control Mechanism in RDK-V using AppArmor, developers can refer to the 'AppArmor Documentation' to understand how to enforce security policies and restrict application access within the RDK-V environment.</p>"},{"location":"entertainment/docs/rdk7-architecture/","title":"RDK7 Architecture","text":""},{"location":"entertainment/docs/rdk7-architecture/#overview","title":"Overview","text":"<p>RDK7 is the newest open source software release, representing the first release of RDK-E (Entertainment), evolving from the previous RDK-V (Video) platform. It supports both IP and TV video platforms, integrating over-the-top (OTT) video apps through the Firebolt\u2122 framework, standardizing interfaces for video playback, digital rights management (DRM), graphics, and security. RDK7 builds upon previous RDK releases to further simplify app development, enhance security, and standardize functionality across diverse set-top box hardware.</p> <p>The following key principles of RDK7 illustrate the areas of change and focus from RDK-V previous releases:</p> <p></p> <p>The Layered Design provides clear separation of functional responsibilities through distinct vendor, middleware, and application layers with independent development and update cycles. Hardware Abstraction reduces the cost of SoC/OEM deliver &amp; platform through standardized hardware abstraction layer (HAL) and simplified platform adaptation. Application Community focuses on standardization of portable 3rd party apps, consistent APIs for application developers, and Firebolt framework for OTT integration. Quality &amp; Robustness involves major transformation of delivery process to ensure quality, independent testing of each layer, and consistent development environment. Rapid Innovation is achieved through utilization of common tooling and patterns. Broadcast Functionality enables separation of broadcast technology from IP platform.</p>"},{"location":"entertainment/docs/rdk7-architecture/#architecture","title":"Architecture","text":"<p>A quick architecture overview of RDK7 to help associate the capabilities with the software stack is given below.</p> <p></p> <p>The architecture consists of three main layers. The Application Layer contains Firebolt Apps, Lightning UI, and Firebolt Framework. The Middleware Layer contains Thunder Framework, ENT Services, Media Framework, DRM Systems, and Device Management. The Vendor Layer contains HAL Implementation, Drivers, BSP, and Hardware Adaptation. The Application Layer connects to the Middleware Layer, which connects to the Vendor Layer.</p>"},{"location":"entertainment/docs/rdk7-architecture/#vendor-layer","title":"Vendor Layer","text":"<p>The objective of the vendor layer is to minimize the amount of code required per hardware platform, thereby reducing development time to support scalability. All vendor layer implementations must be fully compliant with the HAL specification to ensure compatibility with a common middleware build and provide standardized interfaces to the middleware layer, abstracting hardware differences.</p> <p>The vendor layer contains hardware-specific drivers, BSPs, and platform-specific adaptations. Responsibility for build systems, updates, and security identification related to deliverables lies with the vendor implementer. To support management and cross-layer compatibility, a minimal subset of component implementations is specified, such as the Linux Kernel version, core libraries, and patches.</p> <p>Reference open-source software is provided to enable reuse of common components; however, usage of these components is not mandatory for the vendor implementer. Manufacturing and serialization requirements and processes are defined in the Entertainment OS device specifications and must be followed accordingly. The vendor layer can be updated independently without affecting other layers.</p>"},{"location":"entertainment/docs/rdk7-architecture/#middleware-layer","title":"Middleware Layer","text":"<p>The middleware layer aims to provide a single, consistent implementation of core Entertainment device functionality. Middleware components are expected to utilize the Thunder framework to implement functionality in a standardized manner with unified orchestration, providing standardized APIs for the application layer to access device capabilities.</p> <p>The middleware layer includes core RDK components, media playback, DRM systems, and device management. Middleware components are developed separately and delivered as binary packages (IPK), though all components should be delivered in source code unless agreed as an exception. The middleware layer owner holds responsibility for the quality of all components within the layer, including open-source and community contributions.</p> <p>The middleware is designed to have the most simple, robust and co-operative implementation of the core functionality while enabling rapid innovation through common tooling and patterns. Reference open-source software is provided to allow re-use of common components, but the middleware is not obligated to use any of these components.</p>"},{"location":"entertainment/docs/rdk7-architecture/#application-layer","title":"Application Layer","text":"<p>The application layer is distinct from the lower layers in that it doesn't have a single layer owner. Instead, it's a set of tools and applications that harness the underlying layers to provide customer features directly or indirectly. The layer contains user-facing applications and experiences and includes the Firebolt framework for standardizing OTT app integration.</p> <p>Third-party applications should use the Firebolt APIs, providing consistent APIs for application developers, and it is assumed all 3rd party applications are 'untrusted'. The layer supports various application types including native, web-based, and hybrid applications, and can be updated independently of the middleware and vendor layers.</p> <p>Examples of Applications include:</p> <ul> <li>Application Runtimes:     \u00a0     Browsers or runtimes that support execution of application code</li> <li>3rd Party applications:     \u00a0     Standardized portable apps for consistent user experience<ul> <li>Immersive Device Experience:\u00a0A trusted application that provides the UI and business logic to allow eOS managed devices to be configured by the user and host the operating system interactions (e.g., Voice overlays and application orchestration)</li> </ul> </li> </ul> <p>The application layer enables rapid development and deployment of new features and services while standardizing portable 3rd party apps for consistent user experience.</p>"},{"location":"entertainment/docs/rdk7-architecture/#detailed-architecture","title":"Detailed Architecture","text":"<p>The detailed architecture diagram illustrates the complete RDK7 software stack, showing the relationships between the different layers and components:</p> <p></p> <p>The RDK7 architecture includes key components across multiple layers. The Hardware Layer at the bottom is the physical hardware, which varies by device manufacturer. The Vendor Layer sits directly above the hardware, providing the necessary drivers and adaptations. The Middleware Layer serves as the core of the RDK7 platform, providing standardized services and APIs. The Application Layer forms the top layer, containing user-facing applications and experiences. The Thunder Framework provides a unified approach to component development and communication. The Firebolt Framework standardizes interfaces for OTT applications and services. The architecture emphasizes clear separation of concerns, standardized interfaces between layers, and modular component design to enable independent development and updates of different parts of the system.</p>"},{"location":"entertainment/docs/rdk7-architecture/#build-system","title":"Build System","text":"<p>RDK7 introduces a revolutionary layered build approach that significantly improves development efficiency. The build setup is divided into independent Stack layer projects, each comprising components that are developed separately and delivered as binary packages (IPK). These stack layers are then assembled into the final image using the Image Assembler tool.</p> <p></p> <p>The build system architecture includes the Reference OSS Layer that serves as a reference Yocto distribution layer with CVE patches, the Vendor Layer that contains vendor-specific code and hardware adaptations, the RDK Middleware Layer that contains core RDK middleware components, and the Application Layer that contains user-facing applications and services. The RDKE framework serves as the backbone of this layered architecture, designed to work seamlessly with Yocto without disrupting its normal functionalities while requiring minimal maintenance. It accommodates layering requirements without modifying Yocto's default tasks or variables.</p>"},{"location":"entertainment/docs/rdk7-architecture/#build-system-directory-structure","title":"Build System Directory Structure","text":"<pre><code>\u251c\u2500\u2500 application\n\u2502 \u2514\u2500\u2500 meta-application-release\n\u251c\u2500\u2500 common\n\u2502 \u251c\u2500\u2500 meta-openembedded\n\u2502 \u251c\u2500\u2500 meta-oss-reference-release\n\u2502 \u251c\u2500\u2500 meta-rdk-auxiliary\n\u2502 \u251c\u2500\u2500 meta-rdk-halif-headers\n\u2502 \u251c\u2500\u2500 meta-rdk-oss-reference\n\u2502 \u251c\u2500\u2500 meta-stack-layering-support\n\u2502 \u2514\u2500\u2500 poky\n\u251c\u2500\u2500 configs\n\u2502 \u2514\u2500\u2500 common\n\u2514\u2500\u2500 product-layer\n\u2514\u2500\u2500 meta-rdke\n</code></pre>"},{"location":"entertainment/docs/rdk7-architecture/#key-benefits-of-layered-builds","title":"Key Benefits of layered builds","text":"<p>The layered build approach offers several key benefits across multiple areas.\u00a0</p> <ul> <li>Scalability     is achieved as each layer can be updated independently without affecting or relying on other layers, and updating only the vendor layer can be achieved by using the latest tag from that layer and applying it to the stack.</li> <li>Quality     is ensured through each layer undergoing unit testing and layer-specific testing prior to release, with all requirements validated during this process and fully tested and tagged versions of the IPKs produced for quality assurance.</li> <li>Easy debugging     is facilitated as developers are required to compile only their own projects, IPKs from other components can be consumed directly eliminating the need to build the entire set of components, tagged versions of application cases can be used to verify individual components, and overall build time is significantly reduced.</li> <li>Less disk usage     is accomplished when working across multiple products as the middleware and application layers are designed to be as common as possible, the primary difference between products lies in the vendor layer, multiple vendor layers can be checked out and modified while using shared IPKs in the application layer, and this approach eliminates the need to check out the entire codebase for each product significantly saving disk space.</li> <li>Consistent development environment     is maintained as each developer builds components against tagged versions of other components, ensuring that regressions or issues in unrelated components do not affect development, and only tested and tagged versions are used.</li> </ul> <p>The RDKE framework accommodates specific requirements for the layered build system by resolving both direct and indirect interlayer build dependencies, generating proper packaging metadata for runtime dependencies, creating IPKs without disrupting layer and interlayer runtime dependency chains, supporting installation of specific release versions of layer packages, creating target rootfs using both development packages and release layer IPKs, and supporting prebuilt kernels and device trees.</p>"},{"location":"entertainment/docs/rdk7-architecture/#component-interaction-flow","title":"Component Interaction Flow","text":"<p>The typical flow of a request through the RDK7 stack:</p> <p></p> <p>The system follows a standardized request-response flow where the Application sends request to Firebolt Framework, Firebolt Framework translates request for ENT Services, ENT Services processes request and sends to Thunder Framework, Thunder Framework processes request and sends to Hardware Abstraction Layer, HAL executes command on Hardware, Hardware returns result to HAL, HAL processes result and sends to Thunder Framework, Thunder Framework formats response and sends to ENT Services, ENT Services translates response for Firebolt Framework, and Firebolt Framework returns result to Application. This standardized flow ensures consistent behavior across different hardware platforms and enables rapid innovation through common patterns.</p>"},{"location":"entertainment/docs/rdk7-architecture/#application-scenario","title":"Application Scenario","text":"<p>Consider the use case of a user accessing a streaming application like YouTube on an RDK7 Entertainment-supported device. The user interacts with the YouTube application through the Application Layer, selecting content and initiating playback, where the application utilizes the Firebolt Framework for standardized OTT app integration as a 3rd party 'untrusted' application. The Firebolt Framework translates the user's request into standardized API calls and sends them to the Thunder Framework, which processes the request using unified orchestration and coordinates between different middleware components with standardized communication patterns. The ENT Services within the Middleware Layer handle core Entertainment device functionality, including the Media Framework for video decoding and rendering, DRM Systems for content protection and digital rights management, and device management for optimal performance. The Hardware Abstraction Layer in the Vendor Layer executes commands on the hardware using standardized HAL specifications that abstract hardware differences across different SoC platforms, while the physical hardware processes the video content leveraging GPU, video encoding/decoding hardware, and audio devices. The response flows back through the same standardized path in reverse - hardware returns results to HAL, which processes and sends to ENT Services, then to Thunder Framework for translation, and finally the Firebolt Framework returns the result to the Application. This standardized request-response flow ensures consistent behavior across different hardware platforms while enabling rapid innovation through common patterns and modular component design, providing a seamless and secure YouTube streaming experience for the user with clear separation of concerns across the three-layer architecture.</p>"},{"location":"entertainment/docs/rdk7-features/","title":"RDK7 Features","text":"Category Sub-category Version details AV Player Gstreamer, AAMP AV Pipeline RIALTO Application Support / Prerequisites Container OCI Runtime + Dobby Firebolt Implementation Ripple DRM PlayReady 4.4, Widevine v16 Connectivity Ethernet &amp; Wi-Fi Bluetooth Bluetooth Bluez Remote Control Casting DIAL, Wi-Fi Direct (Miracast) Peripherals/Ports HDMI, USB, Optical Framework Thunder Thunder 4.4 Browser WPE Webkit 2.38 Interfaces /IPC Application Interfaces Firebolt Hardware / SOC interfaces RDK HAL Inter Process Communication IARM, RBUS, DBUS Protocol - Device Management TR69hostif AV Driver interface V4l2 Graphics and Rendering Graphics &amp; Rendering OpenGL 3.2 Composition Westeros / ESSOS, Wayland Build &amp; Platform Kernel ACK 5.15 64-bit Kernel SOC SDK BCM URSR25.1, RTK v1.2, AML 6.16 Silicon Broadcom, Amlogic, Realtek Build Framework Yocto 4.0 (Kirkstone) Logging support (Debugging) RDK Logger Firmware Upgrade Applications Native Apps / Runtimes Cobalt 25Amazon AVPK6 Application Management / Composition RDKShell Application Bundle LISA App checkpoint/restore MemCR Access Control AppArmor Casting Secure Time Manager Device management Device Management Web PA, XConf, Telemetry Debugging Gaming Support Game controller DAB Non root user support"},{"location":"entertainment/docs/rdk7-vendor-porting-guide/","title":"RDK7 Vendor Porting Guide","text":"<p>This document helps vendors understand how to create a successful port of RDK on their platform with the help of the HAL API Specification for different RDK Components, as well as how the port can be successfully certified. Depending on the device profile ( IP STB or IP TV ), vendors may choose the relevant components and perform the port by implementing the HAL layer.</p> <p>Details of how to port third-party software stacks or applications to a SoC platform are out of the scope of this porting guide.</p>"},{"location":"entertainment/docs/rdk7-vendor-porting-guide/#version-details","title":"Version details","text":"RDK Version Vendor Porting Kit Version Applicability RDK7 1.4.5 IP STB, IP TV profiles"},{"location":"entertainment/docs/rdk7-vendor-porting-guide/#prerequisites","title":"Prerequisites","text":"<p>The vendor is expected to have certain prerequisites before proceeding to the porting process, which include:</p> <ul> <li> <p>RDK device profile:</p> <ul> <li>Decide on the profile by referring to the available RDK profiles ( IP STB or IP TV ) and have a platform with the expected capabilities for the chosen profile. Depending on the device profile selected, the components that are required to be ported are available in the HAL table below. </li> </ul> </li> <li> <p>RDK HAL API Source code access:</p> <ul> <li>The RDK source code is distributed across multiple source code repositories which are available in RDK Central GitHub</li> </ul> </li> <li> <p>Platform-specific Kernel:</p> <ul> <li>It is highly recommended to use ACK for the target platform as RDK7 is recommended to run on top of ACK 5.15 64-bit version</li> </ul> </li> </ul>"},{"location":"entertainment/docs/rdk7-vendor-porting-guide/#porting","title":"Porting","text":"<p>The Hardware Porting Kit ( HPK ) provide both Hardware Abstraction Layer (API) Header files, and software tests to ensure compatibility with the RDK Middleware Stack. HPK enables vendor to implement the required interfaces that will enable them to bring RDK on top of their platform. Once the HAL layer for each component is implemented, vendors can use the respective test component to certify their port</p> <p>The elaborated documentation on HAL APIs, the test suites and how to build and execute them are all available at the HPK Documentation portal</p> <p>For an exhaustive list of component versions, as well as test suite version for each of the HAL component, please refer below table</p> # Component Name HAL Interface Version Change Info Previous HAL Testing Suite Version Change Info Previous Current Change Info Previous Current Change Info Previous 1 Deep Sleep Manager No change 1.0.4 No change 1.3.0 2 Power Manager No change 1.0.3 No change 1.4.0 3 Device Settings 4.1.2 4.1.1...4.1.2 4.1.1 No change 3.5.0 4 HDMI CEC 1.3.10 1.3.9...1.3.10 1.3.9 No change 1.4.0 5 RMF Audio Capture No change 1.0.5 No change 1.4.0 6 RDK-V TVSettings No change 2.1.0 No change 2.1.3 7 RDK-V WiFi No change 2.0.0 No change 1.0.0 8 LibDRM No change 1.0.0 NYA 9 AvSync No change 1.0.0 NYA 10 V4L2 No change 1.0.0 NYA"},{"location":"entertainment/docs/rdk7-vendor-porting-guide/#certification","title":"Certification","text":"<p>While the test suite associated with the vendor porting kit helps to certify the port is working as expected, RDK certification program facilitates users to get their product certified as an RDK compliance device.</p> <p>RDKM provides the RDK Certification Suites RDK Certification suite to verify the compliance of the RDK Video Accelerator device. The certification program includes testing that validates the RDK \u00a0stack on the user platform with a defined test suite called as RDK Certification Test Suite. \u00a0It is mandatory to go through this program in order to brand the user\u2019s platform as an RDK-compliant product.</p>"},{"location":"entertainment/docs/rdkv_components/","title":"Place Holder markdown for Entertainment  core component landing page","text":""},{"location":"entertainment/docs/tryout_rdkv/","title":"Placeholder page for Getting started in RDK","text":""},{"location":"entertainment/docs/video_profiles/","title":"Placeholder page for RDK Device Profiles","text":""},{"location":"entertainment/docs/components/westeros/","title":"Westeros Wayland Compositor","text":""},{"location":"entertainment/docs/components/westeros/#overview","title":"Overview","text":"<p>Westeros is a lightweight Wayland compositor library designed for embedded systems and set-top boxes. It provides a flexible framework for creating normal, nested, and embedded Wayland compositors with support for hardware-accelerated video rendering and multiple backend platforms.</p> <p>The compositor implements the Wayland protocol and is designed to be compatible with applications built to use Wayland compositors. It enables applications to create one or more Wayland displays and supports three distinct compositor types: normal compositors that display output directly to the screen, nested compositors that send output to another compositor as a client surface, and embedded compositors that allow applications to incorporate composited output into their UI for seamless integration of third-party applications.</p>"},{"location":"entertainment/docs/components/westeros/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph \"Application Layer\"\n        A[Client Applications]\n        B[GStreamer Pipeline]\n    end\n\n    subgraph \"Westeros Core\"\n        C[westeros-compositor.cpp]\n        D[Wayland Protocol Handler]\n        E[Surface Management]\n        F[Output Management]\n    end\n\n    subgraph \"Protocol Extensions\"\n        G[XDG Shell v4/v5/stable]\n        H[Simple Shell]\n        I[Simple Buffer]\n        J[VPC Protocol]\n    end\n\n    subgraph \"Sink Modules\"\n        K[westeros-sink-drm]\n        L[westeros-sink-v4l2]\n    end\n\n    subgraph \"Render Backends\"\n        M[GL Renderer]\n        N[Embedded Renderer]\n    end\n\n    subgraph \"Platform Abstraction\"\n        O[DRM/KMS]\n        P[V4L2]\n    end\n\n    A --&gt; D\n    B --&gt; K\n    B --&gt; L\n    C --&gt; E\n    C --&gt; F\n    D --&gt; G\n    D --&gt; H\n    D --&gt; I\n    D --&gt; J\n    K --&gt; O\n    L --&gt; P\n    M --&gt; O\n    N --&gt; O</code></pre>"},{"location":"entertainment/docs/components/westeros/#core-components","title":"Core Components","text":""},{"location":"entertainment/docs/components/westeros/#1-westeros-compositor-core","title":"1. Westeros Compositor Core","text":"<ul> <li>File: <code>westeros-compositor.cpp</code></li> <li>Purpose: Main compositor implementation handling Wayland protocol, surface management, and client coordination</li> <li>Key Structures:</li> <li><code>WstCompositor</code>: Represents the main compositor context, managing state, client connections, and coordinating Wayland displays and subsystems</li> <li><code>WstOutput</code>: Manages display output configurations like resolution and refresh rate, abstracting hardware differences for a consistent application interface.</li> <li><code>WstModule</code>: Enables runtime loading of platform-specific modules, allowing the compositor to support multiple hardware platforms with a single build.</li> </ul>"},{"location":"entertainment/docs/components/westeros/#2-westeros-sink-modules","title":"2. Westeros Sink Modules","text":"<p>The sink modules are hardware-specific GStreamer sink elements that handle video rendering on different platforms. Each sink module is tailored to leverage the specific capabilities and APIs of its target platform while providing a consistent GStreamer interface.</p>"},{"location":"entertainment/docs/components/westeros/#drm-sink-westeros-sinkdrm","title":"DRM Sink (<code>westeros-sink/drm/</code>)","text":"<ul> <li>Direct Rendering Manager support \u2013 The DRM sink supports generic Linux graphics stacks via the DRM/KMS framework, making it compatible with a wide range of Linux platforms using standard graphics drivers.</li> <li>Generic Linux graphics stack \u2013 It uses GBM for efficient buffer allocation and supports both video overlay and texture rendering, choosing the best method based on hardware and system conditions.</li> <li>KMS (Kernel Mode Setting) integration \u2013 The sink manages display settings like resolution, refresh rate, and multi-monitor support through KMS. It supports both atomic and legacy APIs for broad kernel compatibility.</li> </ul>"},{"location":"entertainment/docs/components/westeros/#v4l2-sink-westeros-sinkv4l2","title":"V4L2 Sink (<code>westeros-sink/v4l2/</code>)","text":"<ul> <li>Video4Linux2 API support \u2013 The V4L2 sink offers broad compatibility using the standard Video4Linux2 API, making it ideal for systems without specialized video interfaces.</li> <li>Capture and display buffer management \u2013 It handles both capture and display buffers, supports various pixel formats and DMA buffers for zero-copy operations, and negotiates formats for optimal hardware performance.</li> <li>Cross-platform video handling \u2013 Supports hardware-accelerated decoding with graceful fallback to software, and maintains proper audio-video synchronization during playback.</li> </ul>"},{"location":"entertainment/docs/components/westeros/#3-protocol-extensions","title":"3. Protocol Extensions","text":""},{"location":"entertainment/docs/components/westeros/#xdg-shell-support","title":"XDG Shell Support","text":"<p>Westeros provides full support for XDG Shell protocol versions v4, v5, and stable, allowing applications to manage surfaces as toplevel or popup windows. It supports window states like maximized, minimized, fullscreen, and resizable, with constraint handling. Surface roles, input focus, and event routing are properly implemented. Bindings are auto-generated from XML using the Wayland scanner, ensuring compatibility with standard Wayland clients.</p>"},{"location":"entertainment/docs/components/westeros/#simple-shell-simpleshell","title":"Simple Shell (<code>simpleshell/</code>)","text":"<p>A custom Westeros extension designed for embedded systems, offering lightweight window management. It supports basic functions such as window creation, positioning, and state transitions, with reduced complexity compared to full-featured shell protocols like XDG Shell\u2014ideal for low-resource environments.</p>"},{"location":"entertainment/docs/components/westeros/#simple-buffer-simplebuffer","title":"Simple Buffer (<code>simplebuffer/</code>)","text":"<p>A protocol extension focused on efficient cross-process buffer sharing. It minimizes memory overhead by supporting shared memory, DMA buffers, and platform-specific formats. Reference counting and lifecycle management are included to ensure proper cleanup and resource handling\u2014critical for performance in embedded systems.</p>"},{"location":"entertainment/docs/components/westeros/#platform-support-matrix","title":"Platform Support Matrix","text":"Platform Sink Module Renderer Hardware Acceleration Key Features Generic Linux drm gl \u2713 DRM/KMS GBM, Atomic KMS, Multi-display V4L2 Devices v4l2 gl \u2713 Hardware Decode Cross-platform, Standard APIs"},{"location":"entertainment/docs/components/westeros/#key-features","title":"Key Features","text":""},{"location":"entertainment/docs/components/westeros/#compositor-types","title":"Compositor Types","text":"<p>Westeros supports three distinct compositor configurations, each designed for specific use cases and deployment scenarios.</p> <p>Normal Compositor operates as a standalone display server, directly controlling screen output and managing all client applications. This configuration is typical for embedded devices where Westeros serves as the primary display system. The normal compositor handles all aspects of display management, including resolution setting, refresh rate control, and multi-monitor support where available.</p> <p>Nested Compositor functions as a client to another Wayland compositor while simultaneously serving as a compositor for its own clients. This configuration enables complex display hierarchies and is useful for scenarios like running multiple UI environments or creating sandboxed application spaces. The nested compositor can be moved, resized, and managed like any other window while maintaining full compositor functionality for its clients.</p> <p>Embedded Compositor allows applications to integrate Wayland compositor functionality directly into their user interface. This enables seamless incorporation of external applications into a host application's UI, creating unified user experiences where third-party applications appear as native components of the host interface.</p>"},{"location":"entertainment/docs/components/westeros/#video-capabilities","title":"Video Capabilities","text":"<p>Westeros supports hardware-accelerated video decoding across all platform backends, automatically selecting the optimal decoding path based on system and hardware capabilities. It handles multiple video planes for features like picture-in-picture and multi-stream rendering, with per-stream scaling and effects.</p> <p>Aspect ratio management ensures proper display adaptation through modes like letterboxing, pillarboxing, and custom configurations. Frame stepping and seeking allow for frame-accurate navigation and variable playback rates, essential for advanced media playback.</p> <p>Audio/video synchronization is maintained through precise timing mechanisms that consider processing delays and hardware latency, ensuring smooth, accurate playback across various configurations.</p>"},{"location":"entertainment/docs/components/westeros/#advanced-features","title":"Advanced Features","text":"<p>ERM (External Resource Manager) integration enables robust resource handling across applications, with support for conflict resolution, priority-based allocation, and graceful degradation under load.</p> <p>Westeros supports seamless dynamic resolution switching without restarting apps or the compositor. It also handles multi-display setups with independent resolution, refresh, and color settings\u2014enabling mirroring and extended desktop modes.</p> <p>Comprehensive input handling includes support for multi-touch displays, external keyboards, and embedded system input devices, ensuring flexible user interaction across platforms.</p>"},{"location":"entertainment/docs/components/westeros/#build-configuration","title":"Build Configuration","text":""},{"location":"entertainment/docs/components/westeros/#platform-specific-builds","title":"Platform-Specific Builds","text":"<p>The build system supports multiple platform configurations through autotools-based configuration options. Each platform can be enabled independently, allowing for custom builds tailored to specific deployment requirements.</p> <pre><code># DRM platform with OpenGL rendering\n./configure --enable-drm=yes --enable-rendergl --enable-gbm\n\n# V4L2 support with cross-platform compatibility\n./configure --enable-v4l2=yes --enable-rendergl\n\n# Embedded compositor configuration\n./configure --enable-embedded=yes --enable-rendergl\n</code></pre>"},{"location":"entertainment/docs/components/westeros/#protocol-generation","title":"Protocol Generation","text":"<p>Protocol bindings are generated using the Wayland scanner tool, which processes XML protocol specifications and creates the necessary C code for client and server implementations.</p> <pre><code># Generate all Wayland protocol bindings\nmake -C protocol westeros-protocols\n\n# Generate specific protocol versions\nexport SCANNER_TOOL=/usr/bin/wayland-scanner\nmake -C protocol xdg-shell-v4 xdg-shell-v5 simpleshell simplebuffer\n</code></pre>"},{"location":"entertainment/docs/components/westeros/#usage-examples","title":"Usage Examples","text":""},{"location":"entertainment/docs/components/westeros/#basic-compositor-launch","title":"Basic Compositor Launch","text":"<p>Different launch configurations demonstrate the flexibility of the Westeros compositor across various platforms and use cases.</p> <pre><code># DRM backend with OpenGL renderer\nLD_PRELOAD=libwesteros_gl.so westeros --renderer libwesteros_render_gl.so\n\n# Embedded compositor with specific display\nwesteros --embedded --display :1 --renderer libwesteros_render_embedded.so\n\n# Nested compositor configuration\nwesteros --nested --parent-display wayland-0 --renderer libwesteros_render_gl.so\n\n# Display-specific launch with debugging\nWESTEROS_DEBUG=1 westeros_test --display westeros-2455-0\n</code></pre>"},{"location":"entertainment/docs/components/westeros/#gstreamer-pipeline-integration","title":"GStreamer Pipeline Integration","text":"<p>Westeros sink integration with GStreamer enables sophisticated media processing pipelines with hardware acceleration.</p> <pre><code># Basic video playback with hardware acceleration\ngst-launch-1.0 filesrc location=video.mp4 ! decodebin ! westerossink\n\n# Advanced pipeline with scaling and effects\ngst-launch-1.0 filesrc location=input.mp4 ! decodebin ! videoscale ! \\\n  video/x-raw,width=1920,height=1080 ! westerossink window-set=\"0,0,1920,1080\"\n\n# Multi-stream pipeline with picture-in-picture\ngst-launch-1.0 filesrc location=main.mp4 ! decodebin ! westerossink name=main \\\n  filesrc location=pip.mp4 ! decodebin ! westerossink name=pip window-set=\"1440,810,480,270\"\n</code></pre>"},{"location":"entertainment/docs/components/westeros/#dependencies","title":"Dependencies","text":""},{"location":"entertainment/docs/components/westeros/#core-dependencies","title":"Core Dependencies","text":"<p>The Westeros compositor requires several core libraries that provide essential functionality for Wayland protocol handling, input processing, and graphics rendering.</p> <p>Wayland (&gt;= 1.6.0) provides the fundamental protocol implementation and client-server communication mechanisms. The compositor uses both client and server-side Wayland libraries for different operational modes.</p> <p>libxkbcommon (&gt;= 0.8.3) and xkeyboard-config (&gt;= 2.18) handle keyboard input processing, including keymap loading, key symbol translation, and internationalization support.</p> <p>GStreamer (&gt;= 1.10.4) integration enables sophisticated media processing capabilities and provides the plugin architecture for the Westeros sink modules.</p> <p>EGL (&gt;= 1.4) and OpenGL ES (&gt;= 2.0) provide hardware-accelerated graphics rendering capabilities across different platforms.</p>"},{"location":"entertainment/docs/components/westeros/#platform-specific-dependencies","title":"Platform-Specific Dependencies","text":"<p>Each platform backend requires specific libraries and development packages for optimal functionality.</p> <p>DRM platforms need libdrm for direct rendering manager access and GBM (Generic Buffer Manager) for efficient buffer allocation and management.</p> <p>V4L2 platforms need Video4Linux2 kernel headers and may benefit from additional codec libraries for enhanced format support.</p>"},{"location":"entertainment/docs/components/westeros/#testing-and-coverage","title":"Testing and Coverage","text":""},{"location":"entertainment/docs/components/westeros/#automated-testing-framework","title":"Automated Testing Framework","text":"<p>The testing system provides comprehensive validation across multiple platforms and configurations. Located in the <code>test/</code> directory, the framework includes platform-specific test suites and code coverage analysis.</p> Test Category Coverage Platform Support Core Compositor Protocol compliance, surface management All platforms Video Rendering Hardware acceleration, format support DRM, V4L2 Input Handling Touch, keyboard, pointer devices All platforms Resource Management ERM integration, memory optimization All platforms <p>Code coverage analysis uses gcov integration to provide detailed reports on test coverage, helping identify areas that need additional testing and ensuring comprehensive validation of critical code paths.</p>"},{"location":"entertainment/docs/components/westeros/#test-execution-and-coverage-analysis","title":"Test Execution and Coverage Analysis","text":"<pre><code># Execute platform-specific test suites\n./run-tests.sh drm     # DRM platform tests\n./run-tests.sh v4l2    # V4L2 platform tests\n\n# Generate comprehensive coverage reports\n./get-coverage.sh drm     # DRM coverage analysis\n\n# Run specific test categories\nmake -f Makefile.test clean &amp;&amp; make -f Makefile.test\n</code></pre>"},{"location":"entertainment/docs/components/westeros/#release-information","title":"Release Information","text":""},{"location":"entertainment/docs/components/westeros/#current-release-10157-november-25-2024","title":"Current Release: 1.01.57 (November 25, 2024)","text":"<p>The latest release introduces several significant improvements and new features:</p> Feature Description Impact Active Format Descriptor (AFD) Video presentation metadata support Enhanced video formatting capabilities Shutdown Robustness Race condition and cleanup improvements Better system stability Timecode PTS Processing Accurate timestamp handling fixes Professional video application support ALLM Management Auto Low Latency Mode updates Improved gaming performance"},{"location":"entertainment/docs/components/westeros/#notable-version-history","title":"Notable Version History","text":"<pre><code>timeline\n    title Westeros Version History\n\n    section 2024\n        1.01.57 : AFD support\n                : Shutdown improvements\n                : Timecode PTS fixes\n                : ALLM management\n\n    section Earlier Versions\n        1.01.48 : V4L2 frame step improvements\n                : ERM serialization enhancements\n\n        1.01.46 : Tunnelled operation support\n                : Thread name optimization\n\n        1.01.44 : Stop-keep-frame property\n                : Enhanced tunnelled operations\n\n        1.01.30 : MJPEG support\n                : TSM mode restoration</code></pre>"},{"location":"entertainment/docs/components/westeros/#api-documentation","title":"API Documentation","text":""},{"location":"entertainment/docs/components/westeros/#module-interface-specifications","title":"Module Interface Specifications","text":"Interface Purpose Key Methods <code>WstModuleInit</code> Primary initialization function Resource allocation, hardware initialization, capability registration <code>WstModuleTerm</code> Cleanup functionality Resource deallocation, system state restoration <code>WstOutput</code> Display output configuration Resolution setting, refresh rate control, multi-display management <code>WstCompositor</code> Main compositor context Primary API for application integration <p>The Westeros module system provides standardized entry points for platform-specific implementations. The <code>WstOutput</code> interface abstracts display output configuration across different platforms, providing consistent methods for resolution setting, refresh rate control, and multi-display management.</p>"},{"location":"entertainment/docs/components/westeros/#protocol-binding-generation","title":"Protocol Binding Generation","text":"<p>Protocol bindings are automatically generated from XML specifications using the Wayland scanner tool. The generated headers in <code>protocol/</code> directories provide both client and server implementations for each supported protocol extension.</p> <pre><code>flowchart LR\n    A[XML Protocol Specs] --&gt; B[Wayland Scanner]\n    B --&gt; C[Generated Headers]\n    C --&gt; D[Client Implementation]\n    C --&gt; E[Server Implementation]\n    D --&gt; F[Application Integration]\n    E --&gt; F</code></pre> <p>The build system integrates Wayland scanner tool execution, automatically regenerating protocol bindings when XML specifications are updated. This ensures that protocol implementations remain synchronized with specification changes and maintain compatibility with standard Wayland applications.</p>"},{"location":"entertainment/docs/components/westeros/#development-guidelines","title":"Development Guidelines","text":""},{"location":"entertainment/docs/components/westeros/#adding-new-platform-support","title":"Adding New Platform Support","text":"Step Task Details 1 Create Sink Module New module in <code>westeros-sink/&lt;platform&gt;/</code> 2 Implement Renderer Platform-specific video rendering and display management 3 Protocol Extensions Add specialized functionality if needed 4 Build Configuration Update autotools, add compilation flags 5 Testing Develop platform-specific test suites <p>Platform-specific rendering backends must implement the standard Westeros renderer interface while leveraging platform-specific APIs for optimal performance. This typically involves integrating with the platform's graphics drivers, video acceleration APIs, and display management systems.</p>"},{"location":"entertainment/docs/components/westeros/#protocol-extension-development","title":"Protocol Extension Development","text":"<pre><code>flowchart TD\n    A[Define XML Protocol Specs] --&gt; B[Generate Bindings]\n    B --&gt; C[Implement Client Handlers]\n    B --&gt; D[Implement Server Handlers]\n    C --&gt; E[Compositor Integration]\n    D --&gt; E\n    E --&gt; F[Testing &amp; Validation]</code></pre> <p>Creating new protocol extensions requires careful design to ensure compatibility and maintainability. Protocol binding generation uses the wayland-scanner tool to create client and server implementation code from XML specifications.</p>"},{"location":"entertainment/docs/components/westeros/#troubleshooting","title":"Troubleshooting","text":""},{"location":"entertainment/docs/components/westeros/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"Issue Type Observed Behavior Diagnostic Steps Solutions Resource Conflicts Multi-application failures Check ERM configuration Configure resource priorities Display Initialization Screen output problems Verify driver configuration Check kernel modules, permissions Video Rendering Playback issues Test hardware acceleration Verify codec support, drivers Protocol Errors Application crashes Check version compatibility Update protocol versions"},{"location":"entertainment/docs/components/westeros/#debug-options-and-diagnostic-tools","title":"Debug Options and Diagnostic Tools","text":"Tool Environment Variable Purpose Usage Verbose Logging <code>WESTEROS_DEBUG=1</code> Detailed operation info Compositor debugging Protocol Debugging <code>WAYLAND_DEBUG=1</code> Message tracing Client-server communication Test Utility <code>westeros_test</code> Display verification Basic functionality testing Platform Tools Platform-specific Resource monitoring Hardware state analysis <p>Resource conflicts often arise in multi-application environments where multiple processes compete for limited hardware resources. Display initialization problems typically stem from incorrect driver configuration or hardware compatibility issues. Video rendering issues may indicate problems with hardware acceleration support or codec compatibility.</p>"},{"location":"entertainment/docs/components/rdkshell/apis/","title":"RDKShell APIs","text":""},{"location":"entertainment/docs/components/rdkshell/apis/#overview","title":"Overview","text":"<p>RDKShell provides multiple API interfaces to accommodate different integration scenarios and programming languages. The system supports JSON-RPC over both traditional socket-based IPC and modern WebSocket connections, as well as direct C++ APIs for native code integration. All APIs provide access to the same underlying functionality through the CompositorController interface.</p> JSON-RPC API WebSocket API <p>RDKShell supports WebSocket-based communication for real-time interaction. The WebSocket API uses the same method names and parameters as the JSON-RPC API but operates over WebSocket connections for lower latency and bidirectional communication.</p> <p>Connection Endpoint: <code>ws://localhost:3000</code></p> <p>Message Format: <pre><code>{\n  \"msg\": \"methodName\",\n  \"params\": {\n    \"parameter1\": \"value1\",\n    \"parameter2\": \"value2\"\n  }\n}\n</code></pre></p> C++ Native API <p>For native code integration, RDKShell provides direct C++ APIs through the CompositorController class. These APIs offer the same functionality as the JSON-RPC interfaces but with direct function calls for maximum performance.</p>"},{"location":"entertainment/docs/components/rdkshell/apis/#application-management-apis","title":"Application Management APIs","text":"createDisplay <p>Method: <code>org.rdk.RDKShell.1.createDisplay</code></p> <p>Parameters: - <code>client</code> (string, required): Unique identifier for the application - <code>displayName</code> (string, optional): Custom name for the display surface - <code>displayWidth</code> (uint32, optional): Width of the display surface - <code>displayHeight</code> (uint32, optional): Height of the display surface - <code>virtualDisplayEnabled</code> (boolean, optional): Enable virtual display mode - <code>virtualWidth</code> (uint32, optional): Virtual display width - <code>virtualHeight</code> (uint32, optional): Virtual display height - <code>topmost</code> (boolean, optional): Create display in topmost layer - <code>focus</code> (boolean, optional): Give focus to the new display - <code>autodestroy</code> (boolean, optional): Automatically destroy when client disconnects</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"3\",\n  \"result\": {\n    \"success\": true\n  }\n}\n</code></pre></p> <p>Example Request: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"3\",\n  \"method\": \"org.rdk.RDKShell.1.createDisplay\",\n  \"params\": {\n    \"client\": \"netflix\",\n    \"displayWidth\": 1920,\n    \"displayHeight\": 1080,\n    \"topmost\": true,\n    \"focus\": true\n  }\n}\n</code></pre></p> launchApplication <p>Method: <code>org.rdk.RDKShell.1.launchApplication</code></p> <p>Parameters: - <code>client</code> (string, required): Application identifier - <code>uri</code> (string, required): Application URI or path - <code>mimeType</code> (string, required): MIME type of the application - <code>topmost</code> (boolean, optional): Launch in topmost layer - <code>focus</code> (boolean, optional): Give focus to launched application</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"4\",\n  \"result\": {\n    \"success\": true\n  }\n}\n</code></pre></p> kill <p>Method: <code>org.rdk.RDKShell.1.kill</code></p> <p>Parameters: - <code>client</code> (string, required): Application identifier to terminate</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"5\",\n  \"result\": {\n    \"success\": true\n  }\n}\n</code></pre></p>"},{"location":"entertainment/docs/components/rdkshell/apis/#display-management-apis","title":"Display Management APIs","text":"getScreenResolution <p>Method: <code>org.rdk.RDKShell.1.getScreenResolution</code></p> <p>Parameters: None</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"6\",\n  \"result\": {\n    \"w\": 1920,\n    \"h\": 1080,\n    \"success\": true\n  }\n}\n</code></pre></p> setScreenResolution <p>Method: <code>org.rdk.RDKShell.1.setScreenResolution</code></p> <p>Parameters: - <code>w</code> (uint32, required): Screen width in pixels - <code>h</code> (uint32, required): Screen height in pixels</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"7\",\n  \"result\": {\n    \"success\": true\n  }\n}\n</code></pre></p> getBounds <p>Method: <code>org.rdk.RDKShell.1.getBounds</code></p> <p>Parameters: - <code>client</code> (string, required): Application identifier</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"8\",\n  \"result\": {\n    \"bounds\": {\n      \"x\": 100,\n      \"y\": 50,\n      \"w\": 800,\n      \"h\": 600\n    },\n    \"success\": true\n  }\n}\n</code></pre></p> setBounds <p>Method: <code>org.rdk.RDKShell.1.setBounds</code></p> <p>Parameters: - <code>client</code> (string, required): Application identifier - <code>x</code> (int32, required): X coordinate - <code>y</code> (int32, required): Y coordinate - <code>w</code> (uint32, required): Width in pixels - <code>h</code> (uint32, required): Height in pixels</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"9\",\n  \"result\": {\n    \"success\": true\n  }\n}\n</code></pre></p>"},{"location":"entertainment/docs/components/rdkshell/apis/#visibility-and-appearance-apis","title":"Visibility and Appearance APIs","text":"getVisibility <p>Method: <code>org.rdk.RDKShell.1.getVisibility</code></p> <p>Parameters: - <code>client</code> (string, required): Application identifier</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"10\",\n  \"result\": {\n    \"visible\": true,\n    \"success\": true\n  }\n}\n</code></pre></p> setVisibility <p>Method: <code>org.rdk.RDKShell.1.setVisibility</code></p> <p>Parameters: - <code>client</code> (string, required): Application identifier - <code>visible</code> (boolean, required): Visibility state</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"11\",\n  \"result\": {\n    \"success\": true\n  }\n}\n</code></pre></p> getOpacity <p>Method: <code>org.rdk.RDKShell.1.getOpacity</code></p> <p>Parameters: - <code>client</code> (string, required): Application identifier</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"12\",\n  \"result\": {\n    \"opacity\": 255,\n    \"success\": true\n  }\n}\n</code></pre></p> setOpacity <p>Method: <code>org.rdk.RDKShell.1.setOpacity</code></p> <p>Parameters: - <code>client</code> (string, required): Application identifier - <code>opacity</code> (uint32, required): Opacity value (0-255)</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"13\",\n  \"result\": {\n    \"success\": true\n  }\n}\n</code></pre></p>"},{"location":"entertainment/docs/components/rdkshell/apis/#z-order-management-apis","title":"Z-Order Management APIs","text":"moveToFront <p>Method: <code>org.rdk.RDKShell.1.moveToFront</code></p> <p>Parameters: - <code>client</code> (string, required): Application identifier</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"14\",\n  \"result\": {\n    \"success\": true\n  }\n}\n</code></pre></p> moveToBack <p>Method: <code>org.rdk.RDKShell.1.moveToBack</code></p> <p>Parameters: - <code>client</code> (string, required): Application identifier</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"15\",\n  \"result\": {\n    \"success\": true\n  }\n}\n</code></pre></p> moveBehind <p>Method: <code>org.rdk.RDKShell.1.moveBehind</code></p> <p>Parameters: - <code>client</code> (string, required): Application to move - <code>target</code> (string, required): Application to move behind</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"16\",\n  \"result\": {\n    \"success\": true\n  }\n}\n</code></pre></p> getZOrder <p>Method: <code>org.rdk.RDKShell.1.getZOrder</code></p> <p>Parameters: None</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"17\",\n  \"result\": {\n    \"clients\": [\"app1\", \"app2\", \"app3\"],\n    \"success\": true\n  }\n}\n</code></pre></p>"},{"location":"entertainment/docs/components/rdkshell/apis/#focus-management-apis","title":"Focus Management APIs","text":"setFocus <p>Method: <code>org.rdk.RDKShell.1.setFocus</code></p> <p>Parameters: - <code>client</code> (string, required): Application identifier</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"18\",\n  \"result\": {\n    \"success\": true\n  }\n}\n</code></pre></p> getFocused <p>Method: <code>org.rdk.RDKShell.1.getFocused</code></p> <p>Parameters: None</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"19\",\n  \"result\": {\n    \"client\": \"netflix\",\n    \"success\": true\n  }\n}\n</code></pre></p>"},{"location":"entertainment/docs/components/rdkshell/apis/#input-management-apis","title":"Input Management APIs","text":"addKeyIntercept <p>Method: <code>org.rdk.RDKShell.1.addKeyIntercept</code></p> <p>Parameters: - <code>client</code> (string, required): Application identifier - <code>keyCode</code> (uint32, required): Key code to intercept - <code>modifiers</code> (array, optional): Modifier keys (ctrl, shift, alt)</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"20\",\n  \"result\": {\n    \"success\": true\n  }\n}\n</code></pre></p> <p>Example Request: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"20\",\n  \"method\": \"org.rdk.RDKShell.1.addKeyIntercept\",\n  \"params\": {\n    \"client\": \"netflix\",\n    \"keyCode\": 48,\n    \"modifiers\": [\"ctrl\", \"shift\"]\n  }\n}\n</code></pre></p> removeKeyIntercept <p>Method: <code>org.rdk.RDKShell.1.removeKeyIntercept</code></p> <p>Parameters: - <code>client</code> (string, required): Application identifier - <code>keyCode</code> (uint32, required): Key code to remove - <code>modifiers</code> (array, optional): Modifier keys</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"21\",\n  \"result\": {\n    \"success\": true\n  }\n}\n</code></pre></p>"},{"location":"entertainment/docs/components/rdkshell/apis/#system-information-apis","title":"System Information APIs","text":"getClients <p>Method: <code>org.rdk.RDKShell.1.getClients</code></p> <p>Parameters: None</p> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"22\",\n  \"result\": {\n    \"clients\": [\"netflix\", \"youtube\", \"settings\"],\n    \"success\": true\n  }\n}\n</code></pre></p>"},{"location":"entertainment/docs/components/rdkshell/apis/#key-c-api-functions","title":"Key C++ API Functions","text":"<pre><code>// Application management\nbool CompositorController::createDisplay(const std::string&amp; client, const std::string&amp; displayName);\nbool CompositorController::kill(const std::string&amp; client);\nbool CompositorController::launchApplication(const std::string&amp; client, const std::string&amp; uri, const std::string&amp; mimeType);\n\n// Display management\nbool CompositorController::setBounds(const std::string&amp; client, uint32_t x, uint32_t y, uint32_t width, uint32_t height);\nbool CompositorController::getBounds(const std::string&amp; client, uint32_t &amp;x, uint32_t &amp;y, uint32_t &amp;width, uint32_t &amp;height);\nbool CompositorController::setVisibility(const std::string&amp; client, bool visible);\nbool CompositorController::getVisibility(const std::string&amp; client, bool&amp; visible);\n\n// Focus and z-order management\nbool CompositorController::setFocus(const std::string&amp; client);\nbool CompositorController::moveToFront(const std::string&amp; client);\nbool CompositorController::moveToBack(const std::string&amp; client);\nbool CompositorController::moveBehind(const std::string&amp; client, const std::string&amp; target);\n\n// Input management\nbool CompositorController::addKeyIntercept(const std::string&amp; client, uint32_t keyCode, uint32_t flags);\nbool CompositorController::removeKeyIntercept(const std::string&amp; client, uint32_t keyCode, uint32_t flags);\n</code></pre>"},{"location":"entertainment/docs/components/rdkshell/apis/#error-handling","title":"Error Handling","text":"<p>All APIs return success/failure indicators and provide detailed error information when operations fail. Common error conditions include:</p> <ul> <li>Invalid client identifier: Specified application does not exist</li> <li>Resource constraints: Insufficient memory or graphics resources</li> <li>Permission denied: Application lacks required permissions</li> <li>Invalid parameters: Malformed or out-of-range parameter values</li> <li>System state conflicts: Operation conflicts with current system state</li> </ul> <p>Error responses follow the JSON-RPC error format: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"23\",\n  \"error\": {\n    \"code\": -32602,\n    \"message\": \"Invalid params\",\n    \"data\": \"Client 'invalid_app' not found\"\n  }\n}\n</code></pre></p>"},{"location":"entertainment/docs/components/rdkshell/architecture/","title":"RDKShell Architecture","text":""},{"location":"entertainment/docs/components/rdkshell/architecture/#architectural-design","title":"Architectural Design","text":"<p>RDKShell follows a modular, event\u2011driven architecture with clear separation of concerns:</p> <pre><code>graph TB\n    A[Main Loop&lt;br/&gt;rdkshell.cpp] --&gt; B[Compositor Controller&lt;br/&gt;compositorcontroller.cpp]\n    A --&gt; C[Essos Instance&lt;br/&gt;essosinstance.cpp]\n    A --&gt; D[Input Management&lt;br/&gt;linuxinput.cpp]\n    A --&gt; E[Communication Layer]\n\n    B --&gt; F[RDK Compositor&lt;br/&gt;Surface Management]\n    B --&gt; G[Animation System&lt;br/&gt;animation.cpp]\n    B --&gt; H[Application Registry]\n\n    C --&gt; I[Wayland Integration&lt;br/&gt;Westeros]\n    C --&gt; J[OpenGL Context&lt;br/&gt;GLES2]\n\n    D --&gt; K[Linux Input Handler&lt;br/&gt;Device Management]\n    D --&gt; L[Key Mapping&lt;br/&gt;linuxkeys.cpp]\n    D --&gt; M[Event Router]\n\n    E --&gt; N[JSON-RPC Handler&lt;br/&gt;servermessagehandler.cpp]\n    E --&gt; O[WebSocket Handler&lt;br/&gt;messageHandler.cpp]\n\n    style A fill:#e1f5fe\n    style B fill:#f3e5f5\n    style C fill:#e8f5e8\n    style D fill:#fff3e0\n    style E fill:#fce4ec</code></pre> Key Architectural Principles <p>\u2022 Event\u2011Driven Design - Central main loop coordinates all subsystems through timed events and callbacks \u2022 Modular Components - Each subsystem (compositor, input, communication) operates independently with well\u2011defined interfaces \u2022 Performance\u2011Focused - 40 FPS rendering loop with frame rate limiting and efficient resource management \u2022 Cross\u2011Platform Compatibility - Abstraction layers (Essos/Westeros) enable deployment across different hardware platforms \u2022 Extensible Communication - Multiple IPC protocols (JSON\u2011RPC, WebSocket) support diverse integration scenarios  </p>"},{"location":"entertainment/docs/components/rdkshell/architecture/#core-components","title":"Core Components","text":"Main Application Loop <p>The central component of RDKShell is the main application loop implemented in <code>rdkshell.cpp</code>. This component orchestrates all system operations through a carefully timed rendering loop that maintains consistent frame rates while processing input events, updating application states, and managing system resources. The main loop operates at a configurable frame rate (default 40 FPS) and coordinates between all other subsystems.</p> <p>The main loop implements sophisticated timing logic that adapts to system load while maintaining smooth visual output. It includes frame rate limiting to prevent excessive CPU usage and provides mechanisms for other subsystems to register for periodic callbacks. The loop also handles system shutdown procedures and ensures proper cleanup of all resources when the system terminates.</p> Compositor Controller <p>The CompositorController serves as the primary interface for all application management operations. It maintains the master list of active applications, manages their z-order relationships, handles focus management, and coordinates display composition operations. This component implements the core business logic for window management including bounds calculation, visibility control, opacity management, and animation coordination.</p> <p>The CompositorController provides a unified API that abstracts the complexity of the underlying graphics and windowing systems. It handles the translation between high-level application management operations and low-level graphics operations, ensuring that applications can be managed consistently regardless of the underlying hardware capabilities.</p> Essos Instance Manager <p>The EssosInstance component provides the abstraction layer between RDKShell and the underlying windowing system. It handles the creation and management of Wayland surfaces, manages OpenGL ES contexts, and provides the rendering surface for the compositor. This component enables RDKShell to work with different windowing systems and graphics hardware through a consistent interface.</p> <p>The EssosInstance manager handles the complex initialization sequences required for graphics systems and provides fallback mechanisms when specific capabilities are not available. It manages the relationship between logical displays and physical output devices, enabling support for multiple display configurations and dynamic display management.</p> RDK Compositor System <p>The RdkCompositor hierarchy (RdkCompositor, RdkCompositorSurface, RdkCompositorNested) implements the actual display composition logic. These components handle the low-level details of surface management, texture handling, and rendering operations. They coordinate with the graphics hardware to ensure efficient composition of multiple application surfaces into the final display output.</p> <p>The compositor system includes sophisticated damage tracking to minimize unnecessary redraws and optimize performance. It supports both hardware-accelerated composition when available and software fallback modes for systems with limited graphics capabilities. The system can handle complex composition scenarios including transparency, scaling, and rotation effects.</p> Input Management System <p>The input management system consists of multiple components working together to provide comprehensive input handling. The LinuxInput component handles low-level input device management, while LinuxKeys provides key code mapping and translation. The system supports both physical input devices and virtual input generation, with sophisticated routing capabilities that allow applications to register for specific key combinations regardless of focus state.</p> <p>The input system includes support for multiple input device types and provides configurable key mapping capabilities. It handles device hotplug events and can adapt to changing input device configurations at runtime. The system also provides input event filtering and transformation capabilities to support different application requirements.</p> Communication Subsystem <p>RDKShell implements multiple communication protocols through a pluggable architecture. The ServerMessageHandler provides JSON-RPC over socket-based IPC, while the MessageHandler implements WebSocket-based communication. Both systems use the same underlying CompositorController APIs, ensuring consistent behavior across different communication methods.</p> <p>The communication subsystem is designed to be extensible, allowing for the addition of new protocols and communication methods. It includes built-in security mechanisms and access control to ensure that only authorized applications can access sensitive functionality. The system supports both synchronous and asynchronous communication patterns.</p>"},{"location":"entertainment/docs/components/rdkshell/architecture/#component-interaction-flow","title":"Component Interaction Flow","text":"<pre><code>graph TB\n    A[Main Application Loop] --&gt; B[Compositor Controller]\n    A --&gt; C[Essos Instance]\n    A --&gt; D[Input Manager]\n    A --&gt; E[Communication Handlers]\n\n    B --&gt; F[RDK Compositor]\n    B --&gt; G[Animation System]\n    B --&gt; H[Application Registry]\n\n    C --&gt; I[Wayland Surface Manager]\n    C --&gt; J[OpenGL Context]\n\n    D --&gt; K[Linux Input Handler]\n    D --&gt; L[Key Mapping System]\n    D --&gt; M[Event Router]\n\n    E --&gt; N[JSON-RPC Handler]\n    E --&gt; O[WebSocket Handler]\n    E --&gt; P[Socket Communication]\n\n    F --&gt; Q[Surface Composition]\n    F --&gt; R[Texture Management]\n\n    style A fill:#e1f5fe\n    style B fill:#f3e5f5\n    style C fill:#e8f5e8\n    style D fill:#fff3e0\n    style E fill:#fce4ec</code></pre>"},{"location":"entertainment/docs/components/rdkshell/architecture/#data-flow-architecture","title":"Data Flow Architecture","text":"Application Lifecycle Data Flow <p>When an application is launched, the request flows through the communication layer to the CompositorController, which coordinates with the EssosInstance to create the necessary Wayland surfaces. The RdkCompositor system then manages the ongoing rendering and composition of the application's visual output. State changes are propagated back through the system to update client applications and maintain consistency.</p> Input Event Processing Flow <p>Input events originate from the LinuxInput system, which captures raw input from various devices. These events are processed through the key mapping system to translate hardware-specific codes into standardized key codes. The CompositorController then applies the configured input routing rules to determine which applications should receive each event, supporting both focused application delivery and global key intercepts.</p> Rendering and Composition Flow <p>The rendering pipeline begins with the main application loop triggering a frame update. The CompositorController coordinates with all active RdkCompositor instances to update their visual state, including position, size, opacity, and any active animations. The EssosInstance provides the OpenGL context and manages the final composition to the display surface.</p>"},{"location":"entertainment/docs/components/rdkshell/architecture/#initialization-sequence","title":"Initialization Sequence","text":"<pre><code>sequenceDiagram\n    participant Main as Main Process\n    participant RDK as RdkShell Core\n    participant Essos as Essos Instance\n    participant Comp as Compositor Controller\n    participant Input as Input System\n    participant Comm as Communication\n\n    Main-&gt;&gt;RDK: initialize()\n    RDK-&gt;&gt;RDK: Load configuration\n    RDK-&gt;&gt;RDK: Setup key mappings\n    RDK-&gt;&gt;RDK: Configure memory monitoring\n    RDK-&gt;&gt;Essos: Initialize windowing system\n    Essos-&gt;&gt;Essos: Create OpenGL context\n    Essos-&gt;&gt;Essos: Setup Wayland surfaces\n    RDK-&gt;&gt;Comp: Initialize compositor\n    Comp-&gt;&gt;Comp: Setup application registry\n    RDK-&gt;&gt;Input: Initialize input handling\n    Input-&gt;&gt;Input: Configure input devices\n    Input-&gt;&gt;Input: Setup key routing\n    RDK-&gt;&gt;Comm: Start communication handlers\n    Comm-&gt;&gt;Comm: Initialize IPC channels\n    RDK-&gt;&gt;Main: Initialization complete\n    Main-&gt;&gt;RDK: run()\n    RDK-&gt;&gt;RDK: Enter main loop</code></pre>"},{"location":"entertainment/docs/components/rdkshell/architecture/#memory-and-resource-management","title":"Memory and Resource Management","text":"Memory Monitoring Architecture <p>RDKShell implements a sophisticated memory monitoring system that operates in a separate thread to avoid impacting the main rendering loop performance. The system continuously monitors system RAM, swap usage, and application-specific memory consumption. Configurable thresholds trigger notifications to applications and system components, enabling proactive resource management.</p>"},{"location":"entertainment/docs/components/rdkshell/architecture/#extension-and-plugin-architecture","title":"Extension and Plugin Architecture","text":"Westeros Plugin Integration <p>RDKShell supports Westeros plugins that can extend the core functionality with platform-specific customizations and additional functionality. The plugin system is designed with security and stability in mind, providing isolation between different extensions and the core system. Extensions can be loaded and unloaded dynamically, enabling flexible deployment scenarios and reducing memory usage when specific functionality is not required. The system includes comprehensive APIs for extensions to interact with the core functionality while maintaining appropriate access controls.</p> Built-in Extension System <p>The architecture includes built-in extensions for client control and extended input handling. These extensions demonstrate the plugin architecture and provide commonly needed functionality that can be enabled or disabled based on deployment requirements. The extension system is designed to be modular and allows for easy addition of new capabilities.</p>"},{"location":"entertainment/docs/components/rdkshell/architecture/#performance-considerations","title":"Performance Considerations","text":"Frame Rate Management <p>The architecture is designed around maintaining consistent frame rates through careful timing and resource management. The main loop includes sophisticated timing logic that adapts to system load while maintaining smooth visual output. The system can dynamically adjust frame rates based on system capabilities and current load conditions.</p> Efficient Event Processing <p>Input event processing is optimized to minimize latency while supporting complex routing scenarios. The system uses efficient data structures and algorithms to ensure that input responsiveness is maintained even with multiple applications and complex key intercept configurations.</p> Graphics Pipeline Optimization <p>The rendering pipeline is optimized for the specific requirements of set-top box and smart TV applications, with careful attention to memory bandwidth and GPU utilization patterns typical in these environments. The system includes sophisticated optimization techniques to maximize performance while maintaining visual quality.</p>"},{"location":"entertainment/docs/components/rdkshell/configuration/","title":"RDKShell Configuration","text":""},{"location":"entertainment/docs/components/rdkshell/configuration/#overview","title":"Overview","text":"<p>RDKShell provides extensive configuration capabilities through environment variables, configuration files, and compile-time options. The configuration system is designed to support both development scenarios with detailed debugging capabilities and production deployments with optimized performance characteristics. The system supports hierarchical configuration sources, allowing for system-wide defaults, platform-specific overrides, and application-specific customizations.</p>"},{"location":"entertainment/docs/components/rdkshell/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"entertainment/docs/components/rdkshell/configuration/#core-system-configuration","title":"Core System Configuration","text":"Variable Type Default Description <code>RDKSHELL_LOG_LEVEL</code> string \"Information\" Sets the verbosity level for logging output. Valid values are \"Debug\", \"Information\", \"Warn\", \"Error\", and \"Fatal\". When set to \"Debug\", detailed runtime information is printed to help with development and troubleshooting. <code>RDKSHELL_FRAMERATE</code> integer 40 Controls the target frame rate for the main rendering loop. Higher values provide smoother animation but consume more CPU resources. The system will attempt to maintain this frame rate while processing input events and updating application states. <code>RDKSHELL_ENABLE_IPC</code> boolean \"0\" Enables the socket-based IPC communication system when set to \"1\". This allows external applications to communicate with RDKShell through JSON-RPC over Unix domain sockets. <code>RDKSHELL_ENABLE_WS_IPC</code> boolean \"0\" Enables the WebSocket-based IPC communication system when set to \"1\". This provides real-time bidirectional communication capabilities for web-based applications and modern client frameworks."},{"location":"entertainment/docs/components/rdkshell/configuration/#memory-management-configuration","title":"Memory Management Configuration","text":"Variable Type Default Description <code>RDKSHELL_LOW_MEMORY_THRESHOLD</code> double 200.0 Sets the threshold in megabytes for low memory notifications. When available system memory falls below this threshold, RDKShell will send low memory notifications to registered applications, allowing them to free up resources proactively. <code>RDKSHELL_CRITICALLY_LOW_MEMORY_THRESHOLD</code> double 100.0 Defines the critically low memory threshold in megabytes. When system memory falls below this level, RDKShell will send critical memory notifications and may take more aggressive resource management actions. This value must be less than or equal to the low memory threshold. <code>RDKSHELL_SWAP_MEMORY_INCREASE_THRESHOLD</code> double 50.0 Sets the threshold in megabytes for swap memory increase notifications. When swap usage increases by more than this amount, applications will be notified of potential memory pressure conditions."},{"location":"entertainment/docs/components/rdkshell/configuration/#input-system-configuration","title":"Input System Configuration","text":"Variable Type Default Description <code>RDKSHELL_KEY_INITIAL_DELAY</code> integer 500 Configures the initial delay in milliseconds before key repeat events begin. This affects how long a user must hold a key before it starts repeating, providing control over input responsiveness and preventing accidental repeated inputs. <code>RDKSHELL_KEY_REPEAT_INTERVAL</code> integer 100 Sets the interval in milliseconds between key repeat events once repeating has started. Lower values result in faster key repetition, while higher values provide more controlled input for navigation scenarios."},{"location":"entertainment/docs/components/rdkshell/configuration/#display-configuration","title":"Display Configuration","text":"Variable Type Default Description <code>RDKSHELL_SET_GRAPHICS_720</code> boolean \"0\" Forces the graphics system to initialize in 720p mode (1280x720) when set to \"1\". This is useful for devices with limited graphics capabilities or when 720p output is specifically required. The system will initialize with these dimensions regardless of the display's native resolution. <code>RDKSHELL_SHOW_SPLASH_SCREEN</code> string undefined When defined, enables the splash screen functionality. The splash screen provides visual feedback during system initialization and can be customized with specific images or animations. <code>RDKSHELL_DISABLE_SPLASH_SCREEN_FILE</code> string undefined Specifies a file path that, when present, will disable the splash screen even if <code>RDKSHELL_SHOW_SPLASH_SCREEN</code> is set. This provides a mechanism for runtime control of splash screen behavior."},{"location":"entertainment/docs/components/rdkshell/configuration/#plugin-and-extension-configuration","title":"Plugin and Extension Configuration","text":"Variable Type Default Description <code>RDKSHELL_WESTEROS_PLUGIN_DIRECTORY</code> string \"/usr/lib/plugins/westeros/\" Specifies the directory path where Westeros plugins are located. RDKShell will search this directory for compatible plugins that extend the core functionality with platform-specific features."},{"location":"entertainment/docs/components/rdkshell/configuration/#configuration-files","title":"Configuration Files","text":""},{"location":"entertainment/docs/components/rdkshell/configuration/#input-device-configuration-inputdevicesconf","title":"Input Device Configuration (<code>inputdevices.conf</code>)","text":"<pre><code>{\n    \"inputDevices\": [\n        {\n            \"vendor\": \"0x119b\",\n            \"product\": \"0x2101\", \n            \"deviceType\": \"0x00\",\n            \"deviceMode\": \"0x00\"\n        },\n        {\n            \"vendor\": \"0x119b\",\n            \"product\": \"0x212b\",\n            \"deviceType\": \"0x01\", \n            \"deviceMode\": \"0x0f\"\n        },\n        {\n            \"vendor\": \"0x06e7\",\n            \"product\": \"0x8038\",\n            \"deviceType\": \"0x02\",\n            \"deviceMode\": \"0x03\"\n        }\n    ],\n    \"irInputDeviceTypeMapping\": [\n        {\n            \"filterCode\": 19,\n            \"deviceType\": \"0xf2\"\n        },\n        {\n            \"filterCode\": 20,\n            \"deviceType\": \"0xf1\"\n        },\n        {\n            \"filterCode\": 21,\n            \"deviceType\": \"0xf3\"\n        }\n    ]\n}\n</code></pre>"},{"location":"entertainment/docs/components/rdkshell/configuration/#input-device-parameters","title":"Input Device Parameters","text":"Parameter Type Description <code>vendor</code> string USB vendor ID in hexadecimal format. This identifies the manufacturer of the input device and is used for device-specific handling and configuration. <code>product</code> string USB product ID in hexadecimal format. Combined with the vendor ID, this uniquely identifies the specific device model and determines appropriate input handling behavior. <code>deviceType</code> string Device type classification in hexadecimal format. This determines how the device's input events are processed and which input handling routines are applied. <code>deviceMode</code> string Device mode configuration in hexadecimal format. This controls specific operational characteristics of the device, such as key repeat behavior and input event filtering."},{"location":"entertainment/docs/components/rdkshell/configuration/#ir-input-device-mapping","title":"IR Input Device Mapping","text":"Parameter Type Description <code>filterCode</code> integer IR filter code that identifies specific IR signal patterns. This allows the system to distinguish between different types of IR input devices and remote controls. <code>deviceType</code> string Device type mapping for IR devices in hexadecimal format. This determines how IR input events are translated into standard input events within the system."},{"location":"entertainment/docs/components/rdkshell/configuration/#permissions-configuration-rdkshellpermissionsconf","title":"Permissions Configuration (<code>rdkshellPermissions.conf</code>)","text":"<pre><code>{\n    \"clients\": [\n        {\n            \"client\": \"trusted_application\",\n            \"extensions\": [\"libwesteros_plugin_rdkshell_client_control.so\"]\n        },\n        {\n            \"client\": \"system_service\",\n            \"extensions\": [\n                \"libwesteros_plugin_rdkshell_client_control.so\",\n                \"libwesteros_plugin_rdkshell_extended_input.so\"\n            ]\n        }\n    ],\n    \"default\": {\n        \"extensions\": []\n    }\n}\n</code></pre>"},{"location":"entertainment/docs/components/rdkshell/configuration/#permission-parameters","title":"Permission Parameters","text":"Parameter Type Description <code>client</code> string Application identifier that matches the client name used in API calls. <code>extensions</code> array List of extension library names that the client is permitted to use. <code>default.extensions</code> array Default extension permissions applied to clients not explicitly listed in the configuration."},{"location":"entertainment/docs/components/rdkshell/configuration/#compile-time-configuration-options","title":"Compile-Time Configuration Options","text":""},{"location":"entertainment/docs/components/rdkshell/configuration/#build-configuration-flags","title":"Build Configuration Flags","text":"Option Default Description <code>RDKSHELL_BUILD_APP</code> ON Controls whether the main RDKShell executable is built. <code>RDKSHELL_BUILD_WEBSOCKET_IPC</code> OFF Enables WebSocket-based IPC communication support. <code>RDKSHELL_BUILD_KEY_METADATA</code> OFF Enables extended key metadata support that provides additional information about input events. <code>RDKSHELL_BUILD_IPC</code> ON Enables traditional socket-based IPC communication. <code>RDKSHELL_BUILD_CLIENT</code> ON Controls whether the RDKShell client library is built. <code>RDKSHELL_BUILD_FORCE_1080</code> OFF Enables compile-time support for forcing 1080p resolution. <code>RDKSHELL_BUILD_ENABLE_KEYREPEATS</code> OFF Enables advanced key repeat functionality with configurable timing and behavior."},{"location":"entertainment/docs/components/rdkshell/configuration/#advanced-build-options","title":"Advanced Build Options","text":"Option Default Description <code>RDKSHELL_BUILD_HIDDEN_SUPPORT</code> OFF Enables support for hidden application states. <code>RDKSHELL_BUILD_EXTERNAL_APPLICATION_SURFACE_COMPOSITION</code> ON Enables support for compositing surfaces from external applications. <code>RDKSHELL_BUILD_KEYBUBBING_TOP_MODE</code> ON Enables key bubbling to topmost applications. <code>RDKSHELL_BUILD_KEY_METADATA_EXTENDED_SUPPORT_FOR_IR</code> OFF Enables extended IR support that provides additional metadata for infrared input devices."},{"location":"entertainment/docs/components/rdkshell/configuration/#runtime-configuration","title":"Runtime Configuration","text":""},{"location":"entertainment/docs/components/rdkshell/configuration/#memory-monitor-configuration","title":"Memory Monitor Configuration","text":"<pre><code>// Configure memory monitoring with specific parameters\nstd::map&lt;std::string, RdkShellData&gt; config;\nconfig[\"enable\"] = true;\nconfig[\"interval\"] = 2.0;  // Check every 2 seconds\nconfig[\"lowRam\"] = 150.0;  // 150MB threshold\nconfig[\"criticallyLowRam\"] = 75.0;  // 75MB critical threshold\nconfig[\"swapIncreaseLimit\"] = 25.0;  // 25MB swap increase limit\nRdkShell::setMemoryMonitor(config);\n</code></pre>"},{"location":"entertainment/docs/components/rdkshell/configuration/#dynamic-display-configuration","title":"Dynamic Display Configuration","text":"<p>Display parameters can be adjusted at runtime through the API system, allowing applications to adapt to changing display conditions or user preferences. This includes resolution changes, display mode adjustments, and multi-display configuration management.</p>"},{"location":"entertainment/docs/components/rdkshell/configuration/#input-device-runtime-configuration","title":"Input Device Runtime Configuration","text":"<p>Input device behavior can be modified at runtime through the input management APIs, enabling dynamic adaptation to different input scenarios and user preferences. This includes key mapping changes, device enable/disable operations, and input routing configuration.</p>"},{"location":"entertainment/docs/components/rdkshell/configuration/#best-practices","title":"Best Practices","text":"Development <p>Enable debug logging and extended metadata collection to facilitate troubleshooting and performance analysis.</p> <p>Use higher frame rates for smoother development experience but be aware of increased resource consumption.</p> <p>Enable additional build options that provide debugging capabilities and detailed system information.</p> Production <p>Use optimized logging levels and carefully tuned memory thresholds based on the specific hardware platform and application requirements.</p> <p>Disable unnecessary features to minimize resource usage and potential security exposure.</p> <p>Use conservative memory thresholds to ensure system stability under varying load conditions.</p> Security <p>Carefully configure the permissions system to ensure that only trusted applications have access to sensitive extensions and capabilities.</p> <p>Regularly review and update permission configurations as applications are added or removed from the system.</p> <p>Use the principle of least privilege when granting extension access to applications.</p> Performance <p>Configure frame rates and memory thresholds based on the specific hardware capabilities and performance requirements of the target deployment.</p> <p>Monitor system performance under typical usage scenarios and adjust configuration parameters to optimize for the specific use case and hardware platform.</p>"},{"location":"entertainment/docs/components/rdkshell/keymapping/","title":"RDKShell Key Mappings and Input Management","text":""},{"location":"entertainment/docs/components/rdkshell/keymapping/#overview","title":"Overview","text":"<p>RDKShell implements a comprehensive key mapping system that translates between different key code formats and provides sophisticated input event routing capabilities. The system supports both Wayland key codes for low-level input handling and RDKShell virtual key codes for application-level input processing. This dual-layer approach ensures compatibility with various input devices while providing a consistent interface for applications.</p> <p>The key mapping system is designed to handle the diverse input requirements of set-top box and smart TV environments, where applications must work with various remote controls, keyboards, and specialized input devices. The system provides flexible mapping capabilities that can be configured for different device types and user preferences.</p>"},{"location":"entertainment/docs/components/rdkshell/keymapping/#key-code-translation-system","title":"Key Code Translation System","text":"Wayland Key Codes <p>RDKShell uses Wayland key codes as the foundation for low-level input processing. These codes correspond directly to Linux input event codes and provide the interface between hardware input devices and the RDKShell input processing system. Wayland key codes are hardware-specific and may vary between different input devices and platforms.</p> RDKShell Virtual Key Codes <p>The virtual key code system provides a standardized interface for applications, abstracting away hardware-specific details and ensuring consistent behavior across different input devices and platforms. Virtual key codes are designed to be stable across different hardware configurations and provide a consistent programming interface for application developers.</p>"},{"location":"entertainment/docs/components/rdkshell/keymapping/#standard-key-mappings","title":"Standard Key Mappings","text":""},{"location":"entertainment/docs/components/rdkshell/keymapping/#alphanumeric-keys","title":"Alphanumeric Keys","text":"Key Wayland Code RDKShell Code Description 0 11 48 Number zero key 1 2 49 Number one key 2 3 50 Number two key 3 4 51 Number three key 4 5 52 Number four key 5 6 53 Number five key 6 7 54 Number six key 7 8 55 Number seven key 8 9 56 Number eight key 9 10 57 Number nine key A 30 65 Letter A key B 48 66 Letter B key C 46 67 Letter C key D 32 68 Letter D key E 18 69 Letter E key F 33 70 Letter F key G 34 71 Letter G key H 35 72 Letter H key I 23 73 Letter I key J 36 74 Letter J key K 37 75 Letter K key L 38 76 Letter L key M 50 77 Letter M key N 49 78 Letter N key O 24 79 Letter O key P 25 80 Letter P key Q 16 81 Letter Q key R 19 82 Letter R key S 31 83 Letter S key T 20 84 Letter T key U 22 85 Letter U key V 47 86 Letter V key W 17 87 Letter W key X 45 88 Letter X key Y 21 89 Letter Y key Z 44 90 Letter Z key"},{"location":"entertainment/docs/components/rdkshell/keymapping/#function-keys","title":"Function Keys","text":"Key Wayland Code RDKShell Code Description F1 59 112 Function key F1 F2 60 113 Function key F2 F3 61 114 Function key F3 F4 62 115 Function key F4 F5 63 116 Function key F5 F6 64 117 Function key F6 F7 65 118 Function key F7 F8 66 119 Function key F8 F9 67 120 Function key F9 F10 68 121 Function key F10 F11 87 122 Function key F11 F12 88 123 Function key F12 F13 183 124 Function key F13 F14 184 125 Function key F14 F15 185 126 Function key F15 F16 186 127 Function key F16 F17 187 129 Function key F17 F18 188 130 Function key F18 F19 189 131 Function key F19 F20 190 132 Function key F20 F21 191 133 Function key F21 F22 192 134 Function key F22 F23 193 135 Function key F23 F24 194 136 Function key F24"},{"location":"entertainment/docs/components/rdkshell/keymapping/#navigation-keys","title":"Navigation Keys","text":"Key Wayland Code RDKShell Code Description Up Arrow 103 38 Directional up navigation key Down Arrow 108 40 Directional down navigation key Left Arrow 105 37 Directional left navigation key Right Arrow 106 39 Directional right navigation key Home 102 36 Home navigation key End 107 35 End navigation key Page Up 104 33 Page up navigation key Page Down 109 34 Page down navigation key Insert 110 45 Insert key Delete 111 46 Delete key"},{"location":"entertainment/docs/components/rdkshell/keymapping/#control-and-modifier-keys","title":"Control and Modifier Keys","text":"Key Wayland Code RDKShell Code Flag Value Description Escape 1 27 - Escape key for canceling operations Tab 15 9 - Tab key for navigation and focus control Enter 28 13 - Enter key for confirmation and line breaks Space 57 32 - Space bar for text input and selection Backspace 14 8 - Backspace key for deleting characters Left Shift 42 16 8 Left shift modifier key Right Shift 54 16 8 Right shift modifier key Left Ctrl 29 17 16 Left control modifier key Right Ctrl 97 17 16 Right control modifier key Left Alt 56 18 32 Left alt modifier key Right Alt 100 18 32 Right alt modifier key Caps Lock 58 20 - Caps lock toggle key Num Lock 69 144 - Numeric keypad lock toggle Scroll Lock 70 145 - Scroll lock toggle key Pause 119 19 - Pause/break key"},{"location":"entertainment/docs/components/rdkshell/keymapping/#special-media-and-remote-control-keys","title":"Special Media and Remote Control Keys","text":"Key Wayland Code RDKShell Code Description Red 0x190 405 Red colored key typically found on remote controls Green 0x191 406 Green colored key typically found on remote controls Yellow 0x18e 403 Yellow colored key typically found on remote controls Blue 0x18f 404 Blue colored key typically found on remote controls Back 158 407 Back navigation key for returning to previous screens Menu 139 408 Menu key for accessing application menus Home Page 172 409 Home page key for returning to main interface Volume Up 115 175 Volume increase key Volume Down 114 174 Volume decrease key Mute 113 173 Audio mute toggle key Play/Pause 164 227 Media play/pause toggle key Play 207 226 Media play key Fast Forward 208 223 Media fast forward key Rewind 168 224 Media rewind key"},{"location":"entertainment/docs/components/rdkshell/keymapping/#numeric-keypad","title":"Numeric Keypad","text":"Key Wayland Code RDKShell Code Description Keypad 0 82 96 Numeric keypad zero Keypad 1 79 97 Numeric keypad one Keypad 2 80 98 Numeric keypad two Keypad 3 81 99 Numeric keypad three Keypad 4 75 100 Numeric keypad four Keypad 5 76 101 Numeric keypad five Keypad 6 77 102 Numeric keypad six Keypad 7 71 103 Numeric keypad seven Keypad 8 72 104 Numeric keypad eight Keypad 9 73 105 Numeric keypad nine Keypad Plus 78 107 Numeric keypad addition operator Keypad Minus 74 109 Numeric keypad subtraction operator Keypad Multiply 55 106 Numeric keypad multiplication operator Keypad Divide 98 111 Numeric keypad division operator Keypad Decimal 83 110 Numeric keypad decimal point Keypad Enter 96 13 Numeric keypad enter key"},{"location":"entertainment/docs/components/rdkshell/keymapping/#modifier-key-flags","title":"Modifier Key Flags","text":"<p>RDKShell uses flag values to represent modifier key states that can be combined with regular key codes to create complex key combinations. These flags can be combined using bitwise OR operations to represent multiple simultaneous modifier keys.</p> Modifier Flag Value Description Shift 8 Shift key modifier for uppercase letters and symbol access Control 16 Control key modifier for keyboard shortcuts and commands Alt 32 Alt key modifier for alternative character input and shortcuts Command 64 Command/Windows key modifier for system-level shortcuts"},{"location":"entertainment/docs/components/rdkshell/keymapping/#modifier-combination-examples","title":"Modifier Combination Examples","text":"<pre><code>// Ctrl+C combination\nuint32_t keyCode = 67;  // C key\nuint32_t flags = 16;    // Control modifier\n\n// Ctrl+Shift+F combination  \nuint32_t keyCode = 70;  // F key\nuint32_t flags = 24;    // Control (16) + Shift (8)\n\n// Alt+Tab combination\nuint32_t keyCode = 9;   // Tab key\nuint32_t flags = 32;    // Alt modifier\n\n// Ctrl+Alt+Delete combination\nuint32_t keyCode = 46;  // Delete key\nuint32_t flags = 48;    // Control (16) + Alt (32)\n</code></pre>"},{"location":"entertainment/docs/components/rdkshell/keymapping/#input-event-processing","title":"Input Event Processing","text":"Key Event Types <p>RDKShell processes two primary types of key events: key press events and key release events. Each event includes the key code, modifier flags, and timing metadata. The system maintains state information about which keys are currently pressed to support complex input scenarios and modifier key combinations.</p> Key Repeat Handling <p>The system supports configurable key repeat functionality with separate settings for initial delay and repeat interval. Key repeat events are marked with a special flag to distinguish them from initial key press events. The repeat behavior can be configured globally or on a per-application basis.</p> <pre><code>#define RDKSHELL_KEYDOWN_REPEAT 128\n</code></pre> <p>The key repeat system includes sophisticated logic to handle modifier keys correctly and ensure that repeat events are only generated for appropriate key types. Navigation keys and character keys typically support repeat, while modifier keys and special function keys do not.</p> Event Routing and Interception <p>Applications can register to intercept specific key combinations even when they are not in focus. This enables global hotkey functionality and allows background applications to respond to specific input events. The interception system supports complex routing scenarios where multiple applications may be interested in the same key events.</p> <p>The event routing system includes priority mechanisms to ensure that critical system functions can always access required key combinations. Applications can register for different types of key interception, including exclusive access, shared access, and monitoring-only access.</p>"},{"location":"entertainment/docs/components/rdkshell/keymapping/#mouse-and-pointer-input","title":"Mouse and Pointer Input","text":""},{"location":"entertainment/docs/components/rdkshell/keymapping/#mouse-button-mappings","title":"Mouse Button Mappings","text":"Button Flag Value Description Left Button 1 Primary mouse button for selection and activation Middle Button 2 Middle mouse button typically used for scrolling Right Button 4 Secondary mouse button for context menus"},{"location":"entertainment/docs/components/rdkshell/keymapping/#pointer-event-processing","title":"Pointer Event Processing","text":"<p>RDKShell processes pointer motion events and button press/release events, providing applications with precise cursor position information and button state changes. The system supports both absolute and relative pointer positioning and can handle multiple pointer devices simultaneously.</p> <p>The pointer event system includes support for touch interfaces and gesture recognition when available. It provides coordinate transformation capabilities to support different display resolutions and scaling factors.</p>"},{"location":"entertainment/docs/components/rdkshell/keymapping/#input-device-configuration","title":"Input Device Configuration","text":"Device Type Classifications <p>The input system supports various device type classifications that determine how input events are processed and routed through the system. Different device types may have different key mappings, repeat behaviors, and event processing characteristics.</p> Custom Input Device Support <p>RDKShell can be configured to support custom input devices through the input device configuration file, allowing for specialized remote controls and input hardware commonly used in set-top box and smart TV environments. The system includes support for device-specific key mappings and behavior customization.</p>"},{"location":"entertainment/docs/components/rdkshell/keymapping/#virtual-key-support","title":"Virtual Key Support","text":"Virtual Key Generation <p>The system supports programmatic generation of virtual key events, enabling applications to simulate user input for automation and testing scenarios. Virtual key events are processed through the same routing and interception mechanisms as physical key events.</p> Virtual Key Mapping <p>Virtual keys can be mapped to physical key codes through string-based identifiers, providing a flexible interface for dynamic key mapping scenarios. This enables applications to define custom key mappings that can be configured at runtime.</p>"},{"location":"entertainment/docs/components/rdkshell/keymapping/#best-practices","title":"Best Practices","text":"Key Intercept Registration <p>Applications should register for key intercepts only for the specific key combinations they need to handle globally. Excessive key intercept registrations can impact system performance and interfere with other applications. Applications should also properly remove their key intercept registrations when they are suspended or terminated.</p> Modifier Key Handling <p>When processing key events with modifiers, applications should check for the specific modifier combinations they support and ignore unexpected modifier states to ensure robust input handling. Applications should also be prepared to handle cases where modifier keys are pressed or released independently of other keys.</p> Input Event Cleanup <p>Applications should properly remove their key intercept registrations when they are suspended or terminated to prevent resource leaks and ensure proper input routing for other applications. The system includes automatic cleanup mechanisms, but applications should not rely solely on these mechanisms.</p> Performance Considerations <p>Input event processing should be optimized to minimize latency and ensure responsive user interaction. Applications should avoid performing heavy processing in input event handlers and should use efficient data structures for key mapping and event routing operations.</p>"},{"location":"entertainment/docs/components/rdkshell/overview/","title":"RDKShell Overview","text":""},{"location":"entertainment/docs/components/rdkshell/overview/#introduction","title":"Introduction","text":"<p>RDKShell is a native component that serves as the foundational application management, composition, and input handling system within the RDK (Reference Design Kit) ecosystem. It functions as a sophisticated window manager and compositor that provides comprehensive control over application lifecycle, display composition, and advanced input event processing for set-top boxes, smart TVs, and other RDK-enabled devices.</p>"},{"location":"entertainment/docs/components/rdkshell/overview/#core-functionalities","title":"Core Functionalities","text":"<p>RDKShell operates as the central orchestrator between the underlying graphics subsystem and applications running on RDK devices. It bridges the gap between low-level graphics capabilities and high-level application requirements by providing a unified interface for application management and display composition. The component integrates deeply with the Wayland display server protocol through Westeros and leverages Essos for flexible windowing system connectivity, enabling it to work seamlessly across different hardware platforms and display configurations.</p> <p>Info</p> <p>Wayland + Westeros + Essos: RDKShell uses these to ensure cross-platform compatibility and modern graphics integration.</p> <p>The module serves as the primary interface for system-level operations such as launching applications, managing their visual presentation, controlling their z-order positioning, and handling complex input event routing. This makes RDKShell essential for creating cohesive user experiences where multiple applications can coexist and interact appropriately within the same display environment.</p>"},{"location":"entertainment/docs/components/rdkshell/overview/#core-capabilities","title":"Core Capabilities","text":""},{"location":"entertainment/docs/components/rdkshell/overview/#application-lifecycle-management","title":"Application Lifecycle Management","text":"<p>RDKShell provides comprehensive application lifecycle management capabilities that extend beyond simple process control. It manages the complete lifecycle from application launch through suspension, resumption, and termination. The system maintains detailed state information for each managed application, including their display properties, input event subscriptions, and resource allocations. This enables sophisticated power management scenarios where applications can be suspended to conserve resources while maintaining their visual state for quick resumption.</p> <p>Note</p> <p>Applications can register for lifecycle events to preserve state and perform cleanup during transitions.</p> <p>The lifecycle management system supports both traditional application models where applications run continuously and modern power-efficient models where applications can be dynamically suspended and resumed based on user interaction patterns and system resource availability. Applications can register for lifecycle events to perform appropriate cleanup and state preservation operations during transitions.</p>"},{"location":"entertainment/docs/components/rdkshell/overview/#advanced-display-composition","title":"Advanced Display Composition","text":"<p>The composition engine within RDKShell handles complex multi-application display scenarios with pixel-perfect precision. It supports arbitrary positioning, scaling, rotation, and opacity control for each application window. The system can handle both traditional rectangular windows and more complex shapes through its integration with OpenGL ES 2.0 rendering pipelines. Advanced features include support for virtual displays, where applications can render to off-screen buffers for scenarios like picture-in-picture or thumbnail generation.</p> <p>Tip</p> <p>Supports both hardware-accelerated and software rendering, with fallback to software when hardware isn't available.</p> <p>The compositor supports hardware-accelerated composition when available, automatically falling back to software rendering when necessary. It includes sophisticated damage tracking to minimize unnecessary redraws and optimize performance on resource-constrained devices. The system can handle multiple display outputs simultaneously, enabling scenarios where different applications are displayed on different screens or display zones.</p>"},{"location":"entertainment/docs/components/rdkshell/overview/#sophisticated-input-event-management","title":"Sophisticated Input Event Management","text":"<p>RDKShell implements a highly configurable input event management system that goes far beyond simple key forwarding. Applications can register for specific key combinations even when they are not in focus, enabling global hotkey functionality and complex input routing scenarios. The system supports both physical key events from various input devices and virtual key generation for programmatic input simulation. Input event metadata is preserved and can be used for advanced input processing scenarios.</p> <p>Note</p> <p>Global hotkeys and key remapping are supported across devices including remote controls and touch interfaces.</p> <p>The input management system includes support for multiple input device types including traditional keyboards, remote controls, game controllers, and touch interfaces. It provides sophisticated key mapping capabilities that can translate between different input device protocols and key code formats. The system supports configurable key repeat rates, modifier key combinations, and complex input event filtering based on application requirements and system policies.</p>"},{"location":"entertainment/docs/components/rdkshell/overview/#memory-and-resource-monitoring","title":"Memory and Resource Monitoring","text":"<p>The component includes comprehensive system resource monitoring capabilities with configurable thresholds and automatic notification systems. It continuously monitors RAM usage, swap utilization, and can trigger low-memory notifications to applications and system components. This enables proactive resource management and helps prevent system instability due to resource exhaustion.</p> <p>Warning</p> <p>Applications should respond to low-memory warnings by reducing cache or suspending non-critical features.</p> <p>The monitoring system operates in a separate thread to avoid impacting the main rendering loop performance. It provides both immediate notifications for critical resource conditions and periodic reports for trend analysis. Applications can register for different types of resource notifications and adjust their behavior accordingly, such as reducing cache sizes or suspending non-essential operations during low-memory conditions.</p>"},{"location":"entertainment/docs/components/rdkshell/overview/#multi-protocol-communication","title":"Multi-Protocol Communication","text":"<p>RDKShell supports multiple communication protocols to accommodate different integration scenarios. It provides JSON-RPC APIs over both traditional socket-based IPC and modern WebSocket connections. Additionally, it offers direct C++ APIs for native code integration. This flexibility allows it to integrate with various system architectures and application frameworks commonly used in the RDK ecosystem.</p> <p>Info</p> <p>RDKShell supports both synchronous and asynchronous APIs for efficient system communication.</p> <p>The communication system is designed to be extensible, allowing for the addition of new protocols and communication methods as requirements evolve. It includes built-in security mechanisms to ensure that only authorized applications can access sensitive functionality. The system supports both synchronous and asynchronous communication patterns, enabling efficient integration with different application architectures.</p>"},{"location":"entertainment/docs/components/rdkshell/overview/#technical-components","title":"Technical Components","text":""},{"location":"entertainment/docs/components/rdkshell/overview/#graphics-and-windowing-integration","title":"Graphics and Windowing Integration","text":"<p>RDKShell builds upon industry-standard graphics technologies including OpenGL ES 2.0 for hardware-accelerated rendering and the Wayland display server protocol for modern windowing system integration. Through its use of Westeros, it can create Wayland surfaces and displays that applications can connect to, while Essos provides the flexibility to connect to either native windowing systems or existing Wayland compositors depending on the deployment scenario.</p> <p>Info</p> <p>Rendering strategies are dynamically selected based on available GPU/CPU capabilities.</p> <p>The graphics integration is designed to work efficiently across a wide range of hardware capabilities, from high-end devices with dedicated GPUs to resource-constrained embedded systems. The system automatically detects available graphics capabilities and adjusts its rendering strategies accordingly to provide optimal performance while maintaining visual quality.</p>"},{"location":"entertainment/docs/components/rdkshell/overview/#threading-and-performance-architecture","title":"Threading and Performance Architecture","text":"<p>The system is designed with performance as a primary consideration, implementing a carefully tuned main loop that maintains consistent frame rates while handling multiple concurrent operations. The default 40 FPS rendering loop can be adjusted based on system capabilities and requirements. Memory monitoring and other background operations are handled in separate threads to avoid impacting the critical rendering path.</p> <p>Tip</p> <p>Uses separate threads for background tasks to ensure smooth UI performance.</p> <p>The threading architecture is designed to minimize contention and maximize parallelism where possible. Critical operations are prioritized to ensure responsive user interaction, while background tasks are scheduled to use available system resources without interfering with real-time requirements. The system includes sophisticated timing and synchronization mechanisms to coordinate between different subsystems.</p>"},{"location":"entertainment/docs/components/rdkshell/overview/#extension-and-plugin-system","title":"Extension and Plugin System","text":"<p>RDKShell includes a sophisticated extension system that allows for platform-specific customizations and additional functionality. The system supports Westeros plugins and includes built-in extensions for client control and extended input handling. This extensibility ensures that RDKShell can be adapted to specific hardware platforms and use cases while maintaining a consistent core architecture.</p> <p>The plugin system is designed with security and stability in mind, providing isolation between different extensions and the core system. Extensions can be loaded and unloaded dynamically, enabling flexible deployment scenarios and reducing memory usage when specific functionality is not required. The system includes comprehensive APIs for extensions to interact with the core functionality while maintaining appropriate access controls.</p>"},{"location":"entertainment/docs/components/rdkshell/overview/#configuration-and-deployment-flexibility","title":"Configuration and Deployment Flexibility","text":"<p>The component supports extensive configuration through environment variables, configuration files, and runtime parameters. This includes display resolution control, memory monitoring thresholds, input device mappings, and permission systems. The configuration system is designed to support both development scenarios with extensive debugging capabilities and production deployments with optimized performance characteristics.</p> <p>Note</p> <p>Configuration changes can be applied at runtime where possible \u2014 no reboot required.</p> <p>The configuration system supports hierarchical configuration sources, allowing for system-wide defaults, platform-specific overrides, and application-specific customizations. Configuration changes can be applied at runtime where appropriate, enabling dynamic adaptation to changing system conditions and requirements without requiring system restarts.</p>"},{"location":"entertainment/docs/components/rdkshell/overview/#system-integration","title":"System Integration","text":"<p>RDKShell integrates with multiple layers of the RDK stack, from low-level graphics drivers through high-level application frameworks. It communicates with the Thunder framework for system-level coordination, integrates with various input subsystems for comprehensive input handling, and provides the foundation for application frameworks to build upon. The component's design ensures that it can adapt to different hardware capabilities while providing consistent APIs and behavior across different RDK implementations.</p> <p>Info</p> <p>Integration interfaces are consistent across platforms, even with different display/input backends.</p> <p>The integration architecture is designed to be modular and extensible, allowing for easy adaptation to new hardware platforms and software frameworks. The system provides well-defined interfaces for integration with external components while maintaining appropriate abstraction layers to ensure compatibility across different deployment scenarios.</p>"},{"location":"entertainment/docs/components/rdkshell/overview/#use-cases-and-applications","title":"Use Cases and Applications","text":"<p>RDKShell is designed to support a wide range of use cases common in modern entertainment and smart home devices. These include traditional set-top box scenarios with multiple video applications, smart TV interfaces with app stores and content discovery, and advanced scenarios like multi-room audio/video distribution and home automation integration.</p> Scenario Description Set-top boxes Multi-app video playback, z-order management Smart TVs App store navigation, content discovery, responsive UI Multi-room AV Render to off-screen buffers, distributed playback Home automation integration Input event routing, control overlay apps, support for virtual assistants and voice <p>The system's flexibility enables it to support both simple single-application scenarios and complex multi-application environments with sophisticated user interfaces. It can handle everything from basic remote control navigation to advanced touch-based interactions and voice control integration, making it suitable for a wide range of device types and user interaction models.</p>"},{"location":"preview-rdk/docs/getting-started/","title":"Getting Started","text":"Entertainment Connectivity <p>RDK is a fully modular, portable, and customizable open source software solution that standardizes core functions used in video, broadband, and IoT devices. Deployed on over a hundred million devices around the globe, RDK enables operators to manage devices and easily customize their UIs and apps, providing analytics to improve the customer experience. RDK is platform and operator agnostic, so it can easily be ported &amp; adopted by multiple SoC/OEM/Operators, significantly reducing the time to market. With over 600 companies, RDK has an active open source community that regularly contributes cutting edge technologies to the stack.</p> <p>RDK for Entertainment </p> <p> RDK middleware enables operators to add video streaming capabilities to their IP or hybrid devices. The latest version of the RDK Video software stack is designed to simplify app development and integration on any set-top device, while allowing companies to maintain complete control of their apps, device data, and customer experience. This is achieved through Firebolt\u2122, the RDK application platform, which ensures compatibility with the latest app releases, eliminating the need for future updates. The seamless integration of global streaming apps provides operators with an easy path to offer subscribers today's most popular content.</p> <p>Video User Interface Preview</p> <p>The front end of any video device is the user interface that consumers will see. RDK comes with an open-source UI written in Lightning\u2122, or you can create your own. To experience the RDK UI, watch the Video:  </p> <p>Try Out RDK</p> <p>If you want to play around RDK, a port of RDK is available on the popular open source platform Raspberry Pi. A guide on how to bring up RDK for Entertainment in Raspberry Pi is available here</p> Preview RDK Broadband <p>RDK Broadband (RDK-B)  software is capable of powering next-gen gateways across DOCSIS, PON, DSL, 5G, and Ethernet, enabling OEMs to standardize elements of their modems, gateways, and converged devices. It provides common functionalities such as routing, Wi-Fi, DNS, diagnostics, remote management, and IoT interfaces, such as Bluetooth, Thread, and Zigbee.</p> RDK Architecture <p>RDK middleware is powered by generic open source software along with RDK specific open source components. The RDK Broadband middleware stack architecture is pictured below:</p> Implementing RDK <p>Getting started with RDK is easy. A simple image depicting adoption of RDK is below:</p> Broadband User Interface <p>WebUI is a graphical user interface that is available on connected devices. It acts as an application running on the RDK-B stack and performs the functions of a device management interface similar to TR69 &amp; SNMP. Users can monitor and modify RDK-B feature settings/rules using WebUI. It is a client\u2013server application: the client runs in a web browser (as part of devices connected over LAN) and Lighttpd on the RDK-B stack acts as server.</p> <p>WebUi can be accessed by both the LAN clients and from the WAN Side.</p> WebUI From WAN Side: <p>Give <code>http://&lt;WAN IP Address of RaspberryPi&gt;:8080</code> in browser.</p> <p>Example: If you use erouter0 IP, then it opens admin page</p> <p>Login Credentials:</p> <ol> <li>Username: admin</li> <li>Password: password</li> </ol> <p>Once the login is successful, the user can verify and control various aspects of the Network Connection (like the SSID of the network, password of the network etc.).</p> WebUI For LAN Clients: <p>In browser on the LAN client/machine give the URL to launch the captive portal page.</p> Try Out RDK Further Reading <ul> <li>RDK-B Raspberry Pi</li> <li>RDK-B R-Pi Build guide</li> <li>RDK Broadband Documentation</li> <li>RDK Documentation</li> </ul>"},{"location":"preview-rdk/docs/preview-rdk-broadband/","title":"Preview RDK Broadband","text":"<p>RDK</p> <p>RDK is a fully modular, portable, and customizable open source software solution that standardizes core functions used in video, broadband, and IoT devices. Deployed on over a hundred million devices around the globe, RDK enables operators to manage devices and easily customize their UIs and apps, providing analytics to improve the customer experience. RDK is platform and operator agnostic, so it can easily be ported &amp; adopted by multiple SoC/OEM/Operators, significantly reducing the time to market . With over 600 companies, RDK has an active open source community that regularly contributes cutting edge technologies to the stack.</p> <p>RDK Broadband (RDK-B) software is capable of powering next-gen gateways across DOCSIS, PON, DSL, 5G, and Ethernet, enabling OEMs to standardize elements of their modems, gateways, and converged devices. It provides common functionalities such as routing, Wi-Fi, DNS, diagnostics, remote management, and IoT interfaces, such as Bluetooth, Thread, and Zigbee.</p>"},{"location":"preview-rdk/docs/preview-rdk-broadband/#rdk-architecture","title":"RDK Architecture","text":"<p>RDK middleware is powered by generic open source software along with RDK specific open source components. The RDK Broadband middleware stack architecture is pictured below:</p> <p></p>"},{"location":"preview-rdk/docs/preview-rdk-broadband/#implementing-rdk","title":"Implementing RDK","text":"<p>Getting started with RDK is easy. A simple image depicting adoption of RDK is below:</p> <p></p>"},{"location":"preview-rdk/docs/preview-rdk-broadband/#broadband-user-interface","title":"Broadband User Interface","text":"<p>WebUI is a graphical user interface that is available on connected devices. It acts as an application running on the RDK-B stack and performs the functions of a device management interface similar to TR69 &amp; SNMP. Users can monitor and modify RDK-B feature settings/rules using WebUI. It is a client\u2013server application: the client runs in a web browser (as part of devices connected over LAN) and Lighttpd on the RDK-B stack acts as server.</p> <p>WebUi can be accessed by both the LAN clients and from the WAN Side.</p> <p>WebUI From WAN Side:</p> <p>Give 'http://&lt;WAN IP Address of RaspberryPi&gt;:8080' in browser.</p> <ul> <li>Example:\u00a0     http://192.168.1.35:8080</li> </ul> <p>If you use erouter0 IP, then it opens admin page</p> <p>Login Credentials:</p> <p>Username: admin Password: password</p> <p>Once the login is successful, the user can verify and control various aspects of the Network Connection (like the SSID of the network, password of the network etc.).</p> <p></p> <p>WebUI For LAN Clients :</p> <p>In browser on the LAN client/machine give the url http://10.0.0.1 to launch the captive portal page.</p> <p></p>"},{"location":"preview-rdk/docs/preview-rdk-video/","title":"Preview rdk video","text":"<p>RDK is a fully modular, portable, and customizable open-source software solution that standardizes core functions used in video, broadband, and IoT devices. Deployed on over a hundred million devices around the globe, RDK enables operators to manage devices and easily customize their UIs and apps, providing analytics to improve the customer experience. RDK is platform and operator agnostic, so it can easily be ported &amp; adopted by multiple SoC/OEM/Operators, significantly reducing the time to market. With over 600 companies, RDK has an active open-source community that regularly contributes cutting edge technologies to the stack.</p> <p></p> <p>RDK for Entertainment RDK middleware enables operators to add video streaming capabilities to their IP or hybrid devices. The latest version of the RDK Video software stack is designed to simplify app development and integration on any set-top device, while allowing companies to maintain complete control of their apps, device data, and customer experience. This is achieved through Firebolt\u2122, the RDK application platform, which ensures compatibility with the latest app releases, eliminating the need for future updates. The seamless integration of global streaming apps provides operators with an easy path to offer subscribers today's most popular content.  </p> <p>Video User Interface Preview</p> <p>The front end of any video device is the user interface that consumers will see. RDK comes with an open-source UI written in Lightning\u2122  , or you can create your own. To experience the RDK UI, watch the Video:  </p> <p>Try Out RDK</p> <p>If you want to play around RDK, a port of RDK is available on the popular open source platform Raspberry Pi. A guide on how to bring up RDK for Entertainment in Raspberry Pi is available here</p>"},{"location":"source/docs/build-system/","title":"Build System","text":""},{"location":"source/docs/build-system/#yocto-build-system-overview","title":"Yocto Build System Overview","text":"<p>The Yocto Project is an open source collaboration project that provides templates, tools and methods to help create custom Linux-based systems for embedded products. It is an open source project initiated by the Linux Foundation in 2010. The Yocto Project uses the OpenEmbedded build system to construct complete Linux images.</p> <p>The core components of the Yocto Project are:</p> <ul> <li>BitBake     , the build engine is a task scheduler, like make. It interprets configuration files and recipes (also called metadata) to perform a set of tasks, to download, configure and build specified packages and filesystem images.</li> <li>OpenEmbedded-Core     , a set of base layers. It is a set of recipes, layers and classes which are shared between all OpenEmbedded based systems. Recipes have a specific syntax and describe how to fetch, configure, compile and package applications and images. Layers are sets of recipes, matching a common purpose. Multiple layers are used within a same distribution, depending on the requirements.</li> </ul>"},{"location":"source/docs/build-system/#yocto-architecture","title":"Yocto Architecture","text":""},{"location":"source/docs/build-system/#bitbake","title":"BitBake","text":"<p>BitBake is the task executor and scheduler used by the OpenEmbedded build system to build images. BitBake is a generic task execution engine that allows shell and Python tasks to be run efficiently and in parallel while working within complex inter-task dependency constraints. BitBake stores the output of each task in a directory, the shared state cache. Its location is controlled by the SSTATE_DIR variable. This cache is use to speed up compilation.</p> <p>Usage: <pre><code>bitbake [options] [recipename/target ...]\u00a0\n</code></pre> Bitbake executes all the layers starting with a prefix \u2018meta\u2019.</p> <p>The build/ directory</p> <ul> <li>conf/     \u00a0: Configuration files - image specific and layer configuration.</li> <li>downloads/     \u00a0: This folder stores the downloaded upstream tarballs of the packages used in the builds, facilitating fast rebuilds. If the content of this folder is deleted, the builds will go and refetch the source tars again.</li> <li>sstate-cache/     \u00a0: Shared state cache, it is the local prebuilt store used by all builds. It will be populated when you do the builds. It is important to keep this directory safe for sstate reuse.</li> <li>tmp/     \u00a0: Holds all the build.</li> <li>tmp/buildstats/     \u00a0: Build statistics for all packages built (CPU usage, elapsed time, host, timestamps).</li> <li>tmp/deploy/     \u00a0: Final output of the build.</li> <li>tmp/deploy/images/     \u00a0: Contains the complete images built by the OpenEmbedded build system. These images are used to flash the target.</li> <li>tmp/work/     \u00a0: Set of specific work directories, split by architecture. They are used to unpack, configure and build the packages. Contains the patched sources, generated objects and logs.</li> <li>tmp/sysroots/     \u00a0: Shared libraries and headers used to compile packages for the target but also for the host.</li> </ul> <p>Note: \u00a0build-(e.g. build-oem-platform) - This is the object/build directory, all objects and intermediate files for all components are stored in this folder. if you want to do a clean build you can delete this folder, then run ./meta-cmf/setup-environment and rebuild. The build will be very fast since it will reuse the sstate (prebuilts) during this build, assuming the sstate-cache directory was populated with previous builds already."},{"location":"source/docs/build-system/#meta-layers","title":"Meta-layers","text":"<p>Meta-layer contains configuration, recipes, classes, patches.</p> <ul> <li>Configuration (*.conf) files: global definition of variables</li> <li>Classes (*.bbclass): encapsulation and inheritance of build logic, packaging etc.</li> <li>Recipes (*.bb, *.bbappend): logical units of software/Images to build\u00a0</li> </ul> <p>Bitbake parses the build classes, config files, and recipes. For every task, a shell script on-the-fly is created and executed.</p>"},{"location":"source/docs/build-system/#recipe","title":"Recipe","text":"<p>Recipes are essentially a set of instructions for building packages. A recipe describes where you get source code and which patches to apply. Recipes describe dependencies for libraries or for other recipes, and they also contain configuration and compilation options. Recipes contain the logical unit of execution, the software to build, the images to build, and use the .bb file extension.</p> <p>The recipes are parsed by the BitBake build engine. The format of a recipe file name is  _.bb <p>A recipe contains configuration variables: name, license, dependencies, path to retrieve the source code etc. It also contains functions that can be run (fetch, configure, compile. . .), called tasks.</p> <p>Recipe provides:</p> <ul> <li>Descriptive information about the package.</li> <li>Existing dependencies (both build and runtime dependencies)</li> <li>DEPENDS &amp; RDEPENDS variables holds the build &amp; runtime dependencies e.g.</li> <li>Where the source code resides and how to fetch it: SRC_URI variable holds the URL path to fetch</li> <li>The version of the recipe</li> <li>Whether the source code requires any patches, where to find them, and how to apply them</li> <li>How to configure and compile the source code</li> <li>Where on the target machine to install the package or packages created</li> </ul>"},{"location":"source/docs/build-system/#append-files","title":"Append Files","text":"<p>Files that append build information to a recipe file. Append files are known as BitBake append files and .bbappend files. The OpenEmbedded build system expects every append file to have a corresponding recipe (.bb) file. Furthermore, the append file and corresponding recipe file must use the same root filename. The filenames can differ only in the file type suffix used (e.g. formfactor_0.0.bb and formfactor_0.0.bbappend).</p> <p>Information in append files overrides the information in the similarly-named recipe file.</p>"},{"location":"source/docs/build-system/#patches","title":"Patches","text":"<p>Patches can be applied to recipe files. Patch files should be having extension *.patch. Place the patch file in subdirectory of recipe named (component) folder.\u00a0 The subdirectory should be preferably named as that of component or as \u2018files\u2019. Add the below line to the recipe file</p> <p>SRC_URI += file://filename.patch/ \u00a0</p>"},{"location":"source/docs/build-system/#external-src","title":"External SRC","text":"<p>By default, the OpenEmbedded build system uses the Build Directory when building source code. The build process involves fetching the source files, unpacking them, and then patching them if necessary before the build takes place.\u00a0</p> <p>Yocto place individual components at discrete locations for the build purpose. For example; consider emulator build</p> <p>../../&lt; Project Folder &gt;/build-qemux86mc/tmp/work/i586-rdk-linux/iarmbus</p> <p>../../&lt; Project Folder &gt;/build-qemux86mc/tmp/work/qemux86mc-rdk-linux/devicesettings</p> <p>It will be difficult for a developer to do a code walk through since the entire source code is spread across multiple directories. You might want to\u00a0build software from source files that are external to and thus outside of the OpenEmbedded build system.For example</p> <p>../../&lt; Project Folder&gt;/generic</p> <p>You want the recipe's SRC_URI variable to point to the external directory and use it as is, not copy it.\u00a0Yocto provides a solution to this by its external SRC support. By this all the components will be pulled to a single place.\u00a0Say, you are component owner and only focused to modify source code of that component and build it alone.\u00a0Modify the files under\u00a0../../&lt; Project Folder &gt;/generic/iarmbus\u00a0(as an example; you can modify any component like this)</p> <p>bitbake iarmbus (as an example; you can build any component like this)</p> <p>To build from software that comes from an external source, all you need to do is inherit the externalsrc class and then set the EXTERNALSRC variable to point to your external source code.</p> <p>The statements to put in your local.conf file are illustrated below:</p> <pre><code>INHERIT += \"externalsrc\"\nEXTERNALSRC_pn-myrecipe = \"path-to-your-source-tree\"\n</code></pre> <p>By default, externalsrc.bbclass builds the source code in a directory separate from the external source directory as specified by EXTERNALSRC. If you need to have the source built in the same directory in which it resides, or some other nominated directory, you can set EXTERNALSRC_BUILD to point to that directory: <pre><code>EXTERNALSRC_BUILD_pn-myrecipe = \"path-to-your-source-tree\"\n</code></pre> To know the components building from external SRC, see the content of the file\u00a0../../&lt;  Project Folder &gt;/build-qemux86mc/conf/auto.conf (In case of emulator)</p>"},{"location":"source/docs/build-system/#yocto-build-types","title":"Yocto Build Types","text":""},{"location":"source/docs/build-system/#references","title":"References","text":"<ul> <li>The Yocto Project</li> <li>Yocto Developer Manual</li> <li>SystemD</li> </ul>"},{"location":"source/docs/creating-yocto-sdk/","title":"Creating Yocto SDK","text":""},{"location":"source/docs/creating-yocto-sdk/#introduction","title":"Introduction","text":"<p>Welcome to the Yocto Software Development Kit (SDK) Guide. SDK allows developers in quick development and testing during development stage. It eliminates the need of downloading &amp; setting-up of full repository environments.</p> <p>Setting a full RDK stack is also quite time consuming and requires a high end machine having good disk space and CPU power for the build process. In the other hand SDK supports following features to overcome above challenges.</p> <ul> <li>A minimal collection of tool chain, development binaries, supporting headers &amp; libraries are shipped in the form of a self extracting script.</li> <li>Allows to build any component using generic auto tool or similar build approach.</li> <li>Supports packaging so as to install the modified software in target in a easy manner while taking care of the dependencies.</li> </ul> <p>This page provides information that explains how to use both the Yocto SDK to develop images and components using the Yocto Project.\u00a0A SDK consists of the following:</p> <ul> <li>Cross-Development Toolchain     : This toolchain contains a compiler, debugger, and various miscellaneous tools.</li> <li>Libraries, Headers, and Symbols     : The libraries, headers, and symbols are specific to the image (i.e. they match the image).</li> <li>Environment Setup Script     : This *.sh file, once run, sets up the cross-development environment by defining variables and preparing for SDK use.</li> </ul> <p>We can use the standard SDK to independently develop and test code that is destined to run on some target machine.</p> <p>SDKs are completely self-contained. The binaries are linked against their own copy of libc, which results in no dependencies on the target system. To achieve this, the pointer to the dynamic loader is configured at install time since that path cannot be dynamically altered. This is the reason for a wrapper around the populate_sdk and populate_sdk_ext archives.</p> <p>Another feature for the SDKs is that only one set of cross-compiler toolchain binaries are produced per architecture. This feature takes advantage of the fact that the target hardware can be passed to gcc as a set of compiler options. Those options are set up by the environment script and contained in variables such as CC and LD. This reduces the space needed for the tools. Understand, however, that a sysroot is still needed for every target since those binaries are target-specific.</p> <p>The SDK development environment consists of the following:</p> <ul> <li> <p>The self-contained SDK, which is an architecture-specific cross-toolchain and matching sysroots (target and native) all built by the OpenEmbedded build system (e.g. the SDK). The toolchain and sysroots are based on a Metadata configuration and extensions, which allows you to cross-develop on the host machine for the target hardware. </p> </li> <li> <p>Various user-space tools that greatly enhance your application development experience. These tools are also separate from the actual SDK but can be independently obtained and used in the development process.</p> </li> </ul>"},{"location":"source/docs/creating-yocto-sdk/#the-cross-development-toolchain","title":"The Cross-Development Toolchain","text":"<p>The\u00a0Cross-Development Toolchain\u00a0consists of a cross-compiler, cross-linker, and cross-debugger that are used to develop user-space applications for targeted hardware. This toolchain is created by running a toolchain installer script or through a\u00a0Build Directory\u00a0that is based on your Metadata configuration or extension for your targeted device. The cross-toolchain works with a matching target sysroot.</p>"},{"location":"source/docs/creating-yocto-sdk/#sysroots","title":"Sysroots","text":"<p>The native and target sysroots contain needed headers and libraries for generating binaries that run on the target architecture. The target sysroot is based on the target root filesystem image that is built by the OpenEmbedded build system and uses the same Metadata configuration used to build the cross-toolchain.</p>"},{"location":"source/docs/creating-yocto-sdk/#user-space-tools","title":"User-Space Tools","text":"<p>User-space tools, which are available as part of the SDK development environment, can be helpful. The tools include LatencyTOP, PowerTOP, Perf, SystemTap, and Lttng-ust. These tools are common development tools for the Linux platform.</p> <ul> <li> <p>LatencyTOP:     \u00a0LatencyTOP focuses on latency that causes skips in audio, stutters in your desktop experience, or situations that overload your server even when you have plenty of CPU power left.</p> </li> <li> <p>PowerTOP:     \u00a0Helps you determine what software is using the most power.\u00a0</p> </li> <li> <p>Perf:     \u00a0Performance counters for Linux used to keep track of certain types of hardware and software events.\u00a0</p> </li> <li> <p>SystemTap:     \u00a0A free software infrastructure that simplifies information gathering about a running Linux system. This information helps you diagnose performance or functional problems. l.</p> </li> <li> <p>Lttng-ust:     \u00a0A User-space Tracer designed to provide detailed information on user-space activity.\u00a0</p> </li> </ul>"},{"location":"source/docs/creating-yocto-sdk/#sdk-development-model","title":"SDK Development Model","text":"<p>Fundamentally, the SDK fits into the development process as follows:</p> <p></p> <p>The SDK is installed on any machine and can be used to develop applications, images, and kernels. An SDK can even be used by a QA Engineer or Release Engineer. The fundamental concept is that the machine that has the SDK installed does not have to be associated with the machine that has the Yocto Project installed. A developer can independently compile and test an object on their machine and then, when the object is ready for integration into an image, they can simply make it available to the machine that has the Yocto Project. Once the object is available, the image can be rebuilt using the Yocto Project to produce the modified image.</p> <p>You just need to follow these general steps:</p> <ol> <li> <p>Install the SDK for your target hardware: For information on how to install the SDK, see the \"Installing the SDK\" section.</p> </li> <li> <p>Download the Target Image: The Yocto Project supports several target architectures and has many pre-built kernel images and root filesystem images. If you are going to develop your application on hardware, go to the machines\u00a0download area and choose a target machine area from which to download the kernel image and root filesystem. This download area could have several files in it that support development using actual hardware. For example, the area might contain <code>.hddimg</code> files that combine the kernel image with the filesystem, boot loaders, and so forth. Be sure to get the files you need for your particular development process.</p> </li> <li> <p>Develop and Test your Application: At this point, you have the tools to develop your application. If you need to separately install and use the emulator, you can go to Emulator to download and learn about the emulator.\u00a0</p> </li> </ol>"},{"location":"source/docs/creating-yocto-sdk/#using-the-sdk","title":"Using the SDK","text":""},{"location":"source/docs/creating-yocto-sdk/#generating-sdk","title":"Generating SDK","text":"<p>To generate SDK use the following command: <pre><code>$ bitbake  &lt;image&gt;  -c populate_sdk\n#e.g: $ bitbake\u00a0rdk-generic-broadband-image -c populate_sdk\n</code></pre> The command results in a toolchain installer that contains the sysroot that matches your target root filesystem. Another powerful feature is that the toolchain is completely self-contained. The binaries are linked against their own copy of libc, which results in no dependencies on the target system. To achieve this, the pointer to the dynamic loader is configured at install time since that path cannot be dynamically altered. This is the reason for a wrapper around the populate_sdk archive.</p> <p>Remember, before using BitBake command, you must source the build environment setup script and you must make sure yourconf/local.conf variables are correct. In particular, you need to be sure the MACHINE variable matches the architecture for which you are building and that the SDKMACHINE variable is correctly set if you are building a toolchain designed to run on an architecture that differs from your current development host machine (i.e. the build machine).</p> <p>When the bitbake command completes, the SDK will be populated in tmp/deploy/sdk location.</p>"},{"location":"source/docs/creating-yocto-sdk/#installing-sdk","title":"Installing SDK","text":"<p>The first thing you need to do is install the SDK on your host development machine by running the\u00a0 <code>*.sh</code> \u00a0installation script.</p> <p>The toolchains the Yocto Project provides are based off the\u00a0 <code>core-image-sato</code> \u00a0image and contain libraries appropriate for developing against that image. Each type of development system supports five or more target architectures.</p> <p>The names of the tarball installer scripts are such that a string representing the host system appears first in the filename and then is immediately followed by a string representing the target architecture.</p> <p><pre><code>rdk-glibc-host_system-image_type-arch-toolchain-release_version.sh\n</code></pre> Where:  - <code>host_system</code> is a string representing your development system: For e.g. <code>i686</code> or <code>x86_64</code>  - <code>image_type</code> is the image for which the SDK was built.  - <code>arch</code> is a string representing the tuned target architecture: For e.g., <code>i586</code>, <code>x86_64</code>, <code>powerpc</code>, <code>mips</code>, <code>armv7a</code> or <code>armv5te</code>  - <code>release_version</code>  is a string representing the release number of the Yocto Project: For e.g., <code>2.0</code> </p> <p>For example, the following toolchain installer is for a 64-bit development host system and a i586-tuned target architecture based off the SDK for <code>core-image-sato</code> and using the  2.1 snapshot: <pre><code>rdk-glibc-x86_64-arm-toolchain-2.0.sh\n</code></pre></p> <p>The SDK and toolchains are self-contained and by default are installed into <code>/opt/poky</code> . . However, when you run the SDK installer, you can choose an installation directory.</p> <p>Note</p> <p>You must change the permissions on the toolchain installer script so that it is executable: <pre><code>$ chmod +x rdk-glibc-x86_64-arm-toolchain-2.0.sh\n</code></pre> The following command shows how to run the installer given a toolchain tarball for a 64-bit x86 development host system and a 32-bit x86 target architecture. The example assumes the toolchain installer is located in <code>~/Downloads/</code></p> <p>RW Permissions</p> <p>If you do not have write permissions for the directory into which you are installing the SDK, the installer notifies you and exits. Be sure you have write permissions in the directory and run the installer again.</p> <pre><code>$ ./rdk-glibc-x86_64-arm-toolchain-2.0.sh \n\nRDK (A Yocto Project based Distro) SDK installer version 2.0 \n============================================================  \nEnter target directory for SDK (default: /opt/rdk/2.0): \nYou are about to install the SDK to \"/opt/rdk/2.0\". Proceed[Y/n]? Y \nExtracting SDK............................................................................done \nSetting it up...done \nSDK has been successfully set up and is ready to be used\nEach time you wish to use the SDK in a new shell session, you need to source the environment setup script e.g. \n$ . /opt/rdk/2.0/environment-setup-cortexa7t2hf-neon-vfpv4-rdk-linux-gnueabi\n</code></pre>"},{"location":"source/docs/creating-yocto-sdk/#running-the-sdk-environment-setup-script","title":"Running the SDK Environment Setup Script","text":"<p>Once you have the SDK installed, you must run the SDK environment setup script before you can actually use it. This setup script resides in the directory you chose when you installed the SDK.\u00a0</p> <p>Before running the script, be sure it is the one that matches the architecture for which you are developing. Environment setup scripts begin with the string \" <code>environment-setup</code> \" and include as part of their name the tuned target architecture. For example, the command to source a setup script for an IA-based target machine using i586 tuning and located in the default SDK installation directory is as follows:</p> <pre><code>$ source /mnt/sdk/environment-setup-cortexa7hf-neon-vfpv4-rdk-linux-gnueabi\n</code></pre> <p>When you run the setup script, many environment variables are defined:</p> <pre><code>SDKTARGETSYSROOT - The path to the sysroot used for cross-compilation\nPKG_CONFIG_PATH - The path to the target pkg-config files\nCONFIG_SITE - A GNU autoconf site file preconfigured for the target\nCC - The minimal command and arguments to run the C compiler \nCXX - The minimal command and arguments to run the C++ compiler\nCPP - The minimal command and arguments to run the C preprocessor\nAS - The minimal command and arguments to run the assembler\nLD - The minimal command and arguments to run the linker\nGDB - The minimal command and arguments to run the GNU Debugger\nSTRIP - The minimal command and arguments to run 'strip', which strips symbols \nRANLIB - The minimal command and arguments to run 'ranlib'\nOBJCOPY - The minimal command and arguments to run 'objcopy' \nOBJDUMP - The minimal command and arguments to run 'objdump'\nAR - The minimal command and arguments to run 'ar' \nNM - The minimal command and arguments to run 'nm' \nTARGET_PREFIX - The toolchain binary prefix for the target tools \nCROSS_COMPILE - The toolchain binary prefix for the target tools\nCONFIGURE_FLAGS - The minimal arguments for GNU configure\nCFLAGS - Suggested C flags\nCXXFLAGS - Suggested C++ flags\nLDFLAGS - Suggested linker flags when you use CC to link \nCPPFLAGS - Suggested preprocessor flags\n</code></pre>"},{"location":"source/docs/creating-yocto-sdk/#autotools-based-projects","title":"Autotools-Based Projects","text":"<p>Once you have a suitable cross-toolchain installed, it is very easy to develop a project outside of the OpenEmbedded build system. This section presents a simple \"Helloworld\" example that shows how to set up, compile, and run the project.</p>"},{"location":"source/docs/creating-yocto-sdk/#creating-and-running-a-project-based-on-gnu-autotools","title":"Creating and Running a Project Based on GNU Autotools","text":"<p>Create a Project Directory</p> <p>Create and enter a clean project directory</p> <pre><code>mkdir -p $HOME/helloworld\ncd $HOME/helloworld\n</code></pre> <p>Populate the Project Files</p> <p>Create the following three files in your project directory:</p> <p>hello.c</p> <pre><code>#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"Hello World!\\n\");\n    return 0;\n}\n</code></pre> <p>Makefile.am</p> <pre><code>bin_PROGRAMS = hello\nhello_SOURCES = hello.c\n</code></pre> <p>configure.in</p> <pre><code>AC_INIT(hello.c)\nAM_INIT_AUTOMAKE(hello, 0.1)\nAC_PROG_CC\nAC_PROG_INSTALL\nAC_OUTPUT(Makefile)\n</code></pre> <p>Source the Cross-Toolchain Environment</p> <p>Before building, source the environment setup script provided by your cross-toolchain SDK. This script is typically named <code>environment-setup-*</code>.</p> <p>Example:</p> <pre><code>source /opt/rdk/2.0/environment-setup-cortexa7t2hf-neon-vfpv4-rdk-linux-gnueabi\n</code></pre> <p>Create GNU Standard Files</p> <p>Create placeholder files required by GNU coding standards:</p> <pre><code>touch NEWS README AUTHORS ChangeLog\n</code></pre> <p>Generate the <code>configure</code> Script</p> <p>Run Autotools to generate the <code>configure</code> script:</p> <pre><code>autoreconf -i\n</code></pre> <p>Configure the Build (Cross-Compile)</p> <p>Use the cross-compiler to configure the build:</p> <pre><code>./configure ${CONFIGURE_FLAGS}\n</code></pre> <p>Replace <code>${CONFIGURE_FLAGS}</code> with any required options specific to your target platform.</p> <p>Build and Install the Project</p> <p>Compile and install the project locally:</p> <pre><code>make\nmake install DESTDIR=./tmp\n</code></pre> <p>The binary will be installed to <code>./tmp/usr/local/bin/hello</code>.</p> <p>Verify the Installation</p> <p>Check the binary to ensure it's built for the correct architecture:</p> <pre><code>file ./tmp/usr/local/bin/hello\n</code></pre> <p>Run the Project</p> <p>Run the binary (either locally or on the target device):</p> <pre><code>./hello\n</code></pre> <p>Expected output:</p> <pre><code>Hello World!\n</code></pre>"},{"location":"source/docs/creating-yocto-sdk/#passing-host-options","title":"Passing Host Options","text":"<p>For an Autotools-based project, you can use the cross-toolchain by just passing the appropriate host option to\u00a0<code>configure.sh</code> . The host option you use is derived from the name of the environment setup script found in the directory in which you installed the cross-toolchain. For example, the host option for an ARM-based target that uses the GNU EABI is  <code>armv5te-poky-linux-gnueabi</code> . You will notice that the name of the script is <code>environment-setup-armv5te-poky-linux-gnueabi</code> . Thus, the following command works to update your project and rebuild it using the appropriate cross-toolchain tools:</p> <pre><code>$ ./configure --host=arm-rdk-linux-gnueabi --prefix=/usr --with-libtool-sysroot=sysroot_dir\n</code></pre> <p>Note</p> <p>If the\u00a0<code>configure</code> \u00a0script results in problems recognizing the <code>--with-libtool-sysroot=</code><code>sysroot-dir</code> \u00a0option, regenerate the script to enable the support by doing the following and then run the script again</p> <pre><code>$ libtoolize --automake\n$ aclocal -I ${OECORE_NATIVE_SYSROOT};/usr/share/aclocal   [-I dir_containing_your_project-specific_m4_macros]\n$ autoconf\n$ autoheader\n$ automake -a\n</code></pre>"},{"location":"source/docs/creating-yocto-sdk/#makefile-based-projects","title":"Makefile-Based Projects","text":"<p>For Makefile-based projects, the cross-toolchain environment variables established by running the cross-toolchain environment setup script are subject to general\u00a0<code>make</code> \u00a0rules.</p> <p>To illustrate this, consider the following four cross-toolchain environment variables: <pre><code>CC=i586-poky-linux-gcc -m32 -march=i586 --sysroot=/opt/poky/2.1/sysroots/i586-poky-linux\nLD=i586-poky-linux-ld --sysroot=/opt/poky/2.1/sysroots/i586-poky-linux\nCFLAGS=-O2 -pipe -g -feliminate-unused-debug-types\nCXXFLAGS=-O2 -pipe -g -feliminate-unused-debug-types\n</code></pre> Now, consider the following three cases:</p> <ul> <li> <p>Case 1 - No Variables Set in the <code>Makefile</code>:     Because these variables are not specifically set in the <code>Makefile</code> , the variables retain their values based on the environment.</p> </li> <li> <p>Case 2 - Variables Set in the\u00a0<code>Makefile</code> :      Specifically setting variables in the <code>Makefile</code> during the build results in the environment settings of the variables being overwritten.</p> </li> <li> <p>Case 3 - Variables Set when the\u00a0<code>Makefile</code> is Executed from the Command Line:     \u00a0Executing the\u00a0<code>Makefile</code> from the command line results in the variables being overwritten with command-line content regardless of what is being set in the <code>Makefile</code> . In this case,  environment variables are not considered unless you use the \"-e\" flag during the build: <pre><code>$ make -e file\n</code></pre> If you use this flag, then the environment values of the variables override any variables specifically set in the <code>Makefile</code></p> </li> </ul>"},{"location":"source/docs/how-to-contribute/","title":"How to Contribute","text":""},{"location":"source/docs/how-to-contribute/#before-you-contribute","title":"Before You Contribute","text":"<p>In order to contribute code, first-time users are requested to agree to the license at\u00a0RDK Central Wiki. As an unaffiliated individual, you must sign the  CLA . You can complete that process online.</p>"},{"location":"source/docs/how-to-contribute/#what-is-a-cla","title":"What is a CLA?","text":"<p>The Contributor License Agreement is necessary mainly because you own the copyright to your changes, even after your contribution becomes part of our codebase, so we need your permission to use and distribute your code. We also need to be sure of various other things \u2014 for instance that you\u2018ll tell us if you know that your code infringes on other people\u2019s patents.</p> <p>You don\u2018t have to sign the CLA until after you\u2019ve submitted your code for review and a member has approved it, but you must do it before we can put your code into our codebase. Before you start working on a larger contribution, get in touch with us to discuss your idea so that we can help out and possibly guide you. Early coordination makes it much easier to avoid frustration later on.</p>"},{"location":"source/docs/how-to-contribute/#code-reviews","title":"Code Reviews","text":"<p>All submissions, including submissions by project members, require review. We use both Gerrit ( Gerrit Code Review ) and Github ( Github Code Review ) depending on where the repo is hosted. Currently, team-member submissions are reviewed privately, and external submissions go through public reviews.</p>"},{"location":"source/docs/how-to-contribute/#code-submission-process","title":"Code Submission Process","text":"<p>The following steps explain the submission process:</p> <ul> <li>Ensure you or your company have signed the appropriate CLA as discussed in the     \u00a0     Before You Contribute     \u00a0     section above.</li> <li>Rebase your changes down into a single git commit.</li> <li>Run     \u00a0     <code>git push command</code>     \u00a0     to upload the review to     \u00a0     code.rdkcentral     .</li> <li>Someone from the maintainers team reviews the code, adding comments on any things that need to change before the code can be submitted.</li> <li>If you need to make changes, make them locally, test them, then     \u00a0     <code>git commit \u00a0 -- amend</code>     \u00a0     to add them to the     \u00a0     existing     \u00a0     commit. Then return to step 2.</li> <li>If you do not need to make any more changes, a maintainer integrates the change into our private repository, and it is pushed out to the public repository after some time.</li> </ul>"},{"location":"source/docs/how-to-contribute/#contributor-license-agreement-cla-rdk-central-github","title":"Contributor License Agreement (CLA) - RDK Central Github","text":"<p>The RDK CLA facilitates the acceptance and sharing of RDK contributions within the community.</p> <p>When you contribute to an RDK open source project on GitHub via a new pull request, a bot will evaluate whether you have signed the CLA. The bot will comment on the pull request, including a link to accept the agreement.</p> <p>CLA assistant enables contributors to sign CLAs from within a pull request. The CLA is stored as a GitHub Gist file and linked with the repository/organization in CLA assistant.</p>"},{"location":"source/docs/how-to-contribute/#cla-assistant","title":"CLA assistant","text":"<ul> <li>Comments on each opened pull request to ask the contributor to sign the CLA.</li> <li>Allows contributors to sign a CLA from within a pull request.</li> <li>Authenticates the signee with his or her GitHub account.</li> <li>Updates the status of a pull request when the contributor agrees to the CLA.</li> <li>Automatically asks users to re-sign the CLA for each new pull request in the event the associated Gist &amp; CLA has changed.</li> <li>Repository owners can review a list of users who signed the CLA for each version of it.</li> </ul> <p>Note - CLA assistant is provided by SAP as a free hosted offering under:\u00a0 cla-assistant.io </p>"},{"location":"source/docs/how-to-contribute/#code-contribution-process","title":"Code Contribution Process","text":""},{"location":"source/docs/how-to-contribute/#code-contribution-workflow","title":"Code Contribution Workflow","text":"<p>The Code Contribution Workflow is designed to facilitate community involvement in the development of RDK components. The structured process ensures that contributions are reviewed, validated and integrated effectively, maintaining high standards of quality throughout.</p>"},{"location":"source/docs/how-to-contribute/#branch-overview","title":"Branch Overview","text":"<ol> <li> <p>Product Branch</p> <ul> <li>The Product Branch is a deployment-ready branch where the community submits changes for review. This branch serves as the main integration point for code that meets rigorous testing qualifications.</li> <li>For more information on the components hosted in the product branch, refer to the CMF Gerrit and the RDK Central GitHub repository.</li> </ul> </li> <li> <p>Monthly Sprint Branch (rdk-dev-yymm)</p> <ul> <li>Created monthly as a new CMF integration branch, this branch is based on the product branch.</li> <li>It is hosted per repository and aims to incorporate community changes as early as possible.</li> <li>Once community changes are approved, they will be cherry-picked to the monthly sprint branch, making them available before the final down-streaming to the regression branch.</li> </ul> </li> <li> <p>Regression Branch</p> <ul> <li>This branch is used for validating contributions.</li> <li>Approved changes are down-streamed here for pre-deployment validation through the established testing process.</li> <li>Defects and features will be planned in monthly sprints, with timelines published to contributors.</li> <li>Contributions pending validation will be available in monthly development iteration branches.</li> </ul> </li> </ol>"},{"location":"source/docs/how-to-contribute/#contribution-process","title":"Contribution Process","text":"<ul> <li>Users will make code contributions to the rdk-next branch. This process includes:<ul> <li>Code reviews</li> <li>Build verification</li> <li>License compliance scans</li> <li>Test validation</li> </ul> </li> <li>Once the changes are successfully validated, changes are cherry-picked to the monthly sprint branch (rdk-dev-yymm).</li> <li>These changes are then down-streamed to the regression branch for further pre-deployment testing.</li> <li>After successful validation, the changes are cherry-picked to the product branch, completing the integration into the main deployment-ready branch.</li> </ul> <p>Component owners/reviewers/approvers, defined as specific groups in Gerrit, will be added to the review by default. You may request additional feedback by specifically adding reviewers via the Gerrit web GUI.\u00a0</p>"},{"location":"source/docs/how-to-contribute/#development-workflow","title":"Development Workflow","text":"<p>This section describes the general RDK development work-flow and related topics. The general pattern for successfully accepting a change is as follows:</p> <ul> <li>Discuss on mailing list to get general consensus about approach.</li> <li>Pull latest code.</li> <li>Build on your supported platform.</li> <li>Develop features or fix bugs following     \u00a0     RDK Coding standards     .</li> <li>Submit to Gerrit for review.</li> <li>Review and respond to reviewer comments.</li> <li>Change accepted and merged.</li> </ul> <p>For a detailed step by step description, please refer:\u00a0Gerrit Development Workflow .</p>"},{"location":"source/docs/how-to-contribute/#code-management-facility-cmf","title":"Code Management Facility (CMF)","text":"<p>On a periodic basis, RDK code is tested and released to the community as \u00a0 CMF releases . This will be generic RDK code without dependency to any platform. CMF code can be built for \u00a0 raspberry-pi \u00a0 or can be ported to a specific platform ( RDK Porting ). And once the component owner approves this change, it will be available to the community in RDK central.</p>"},{"location":"source/docs/how-to-contribute/#cmf-contributions","title":"CMF Contributions","text":"<p>While working with CMF stack, one might find ways to enhance RDK code by adding new features or bug fixes as RDK contribution. The general CMF contribution workflow is as follows:</p> <p></p> <p>Detailed information on contributing code changes to RDK can be found here:\u00a0 Code Management Documentation</p>"},{"location":"source/docs/how-to-contribute/#getting-support","title":"Getting Support","text":"<p>Support tickets can be raised to get request support from RDK Community Support team. This can be for the bugs you face, doubts you have or any code contributions which you think might enhance RDK. RDK Support ticket can be raised here: support@rdkcentral .</p>"},{"location":"source/docs/how-to-contribute/#jira-guidelines","title":"JIRA Guidelines","text":""},{"location":"source/docs/how-to-contribute/#where-to-create-a-jira-ticket","title":"Where to Create a JIRA ticket","text":"<ul> <li>Log in to JIRA\u00a0     jira.rdkcentral     \u00a0using rdkcentral credentials</li> <li>Create a JIRA ticket under     RDKDEV     (for Video) or     RDKBDEV     (for Broadband).</li> <li>Click on the Create button</li> </ul> <p>A Snap shot for how to create a JIRA.</p> <p></p>"},{"location":"source/docs/how-to-contribute/#jira-guideline-for-patches-contributions","title":"JIRA Guideline for Patches Contributions","text":"<p>Issue type corresponds to the type of contributions we are making. The following issue types can be possible for patches contribution \u221a Incident - Build failure incident issues with the code verification steps such as Black duck scan, Jenkins verification etc. \u221a Bug - Bugs in existing component code. To report a bug, users must create a ticket with type Bug and provide as much information as possible, including:</p> <ul> <li>A clear and concise description of the bug</li> <li>Steps to reproduce the bug</li> <li>The expected behavior</li> <li>The actual behavior</li> <li>Any relevant screenshots, logs or videos</li> </ul> <p>\u221a Task - An individual task which may be part of enhancement of existing feature, etc. \u221a\u00a0Improvement - Improvements such as code refactoring or enhancements in current code.</p> <p>Summary and Descriptions are mandatory fields need to be filled.</p> <p>Click on Create button to Create a new JIRA. Sample example is provided below.</p> <p></p> <p>Note: To know more about how to refresh the patches click\u00a0here .</p>"},{"location":"source/docs/how-to-contribute/#jira-guideline-for-new-feature-contribution","title":"JIRA Guideline for New Feature Contribution","text":"<p>A feature contribution should follow after creating an appropriate JIRA project. This will present a clear picture about the architecture, testing details and other information which will be helpful during the acceptance process of the contribution.</p>"},{"location":"source/docs/how-to-contribute/#mandatory-information","title":"Mandatory information","text":""},{"location":"source/docs/how-to-contribute/#project","title":"Project","text":"<pre><code>For Video &amp; build system (Yocto) related contributions, the ticket should be created under RDKDEV. For broadband, the ticket should be created under RDKBDEV project.\n</code></pre>"},{"location":"source/docs/how-to-contribute/#issue-type","title":"Issue Type","text":"<pre><code>\u221a\u00a0New feature - New feature contributions.\n</code></pre>"},{"location":"source/docs/how-to-contribute/#ticket-status","title":"Ticket Status","text":"<pre><code>Status should be initially Open, and transitioned to the appropriate value while the contribution is being worked on.\n</code></pre>"},{"location":"source/docs/how-to-contribute/#summary","title":"Summary","text":"<p>A brief summary about what we are trying to contribute\u00a0</p>"},{"location":"source/docs/how-to-contribute/#description","title":"Description","text":"<p>A descriptive information about the contribution should be present so that component developers &amp; architecture team can do assessment of the feature. Below details are desirable if the contribution is a new feature or having an significant impact on the current architecture.</p> <p><pre><code>Brief introduction on what the current system lacks &amp; what needs to be done:\n1. Individual task/highlighted point \\#1 brief description.\n2. Individual task/highlighted point \\#2 brief description.\n</code></pre> <pre><code>The following items should be considered/addressed in the documentation for any RDK design initiative\nJIRA Update Checklist\n-----------------------\nThe following JIRA fields MUST be filled in to be considered \"Definition Complete\":\n\\* RDK SoC, RDK OEM - populate these fields for any user story where we have dependency on OEM and/or SoC to perform work in the completion of this user story. Select all that apply, or \u201cNone\u201d if there is no dependency.\n\\* OEM/SoC Impact Details - description of impact (or \"see Solution Overview\" if included in the architecture specification)\n\\* Platforms - ensure correct list of devices\n\\* Validation - type of testing\n\\* Regression - is regression required?\n\\* Dependency - Internal/External\n\\* Description - Solution Overview and Architecture Checklist\nTesting impact/Guidance\n------------------------\n\\* Impacted modules\n\\* Test process\nAutomated Testing\n------------------\n\\* Automation test procedure.\nDiagnostics, Telemetry and Logging\n-----------------------------------\n\\* N/A\nOutbound Network Connections\n------------------------------\n\\* Does this component make outbound connection requests?\n\\* If yes, do the connection requests retry in the case of failure?\n\\*\\* Do the repeated requests use an exponential back-off?\n\\*\\* If a maximum back-off has been defined, is it greater than 10 minutes?\nSecurity\n----------\n\\* For Security Review - Do feature elements:\n\\*\\* make any changes to network port assignments?\n\\*\\* change iptables rules?\n\\*\\* require credentials, passwords, secret data?\n\\*\\* make any changes to our network connections?\n\\*\\* connect to new services or servers?\n\\*\\* use data input from users or external tools?\n\\*\\* use any cryptographic functions?\n\\*\\* create or disclose proprietary or sensitive Co. or device data?\n\\*\\* properly log operational and configuration changes?\n\\*\\* If possible describe what could happen if feature elements are:\n\\*\\*\\* spoofed?\n\\*\\*\\* tampered with?\n\\*\\*\\* used by an unauthorized actor?\n\\*\\* Advanced questions (optional)\n\\*\\*\\* what happens if a record of actions taken is destroyed?\n\\*\\*\\* what happens if an attacker attempts to DOS with the feature?\nSI Concerns\n-------------\n\\* Yes/No/Any\nPerformance expectations\n-------------------------\n\\* Yes/No/Any\nTiming consideration\n----------------------\n\\* If Any.\n</code></pre></p>"},{"location":"source/docs/how-to-contribute/#supplementary-information","title":"Supplementary Information","text":"<ol> <li>Impacted component(s) - Fill in list of impacted RDK components</li> <li>RDK SI Impact - System Integration impacts</li> <li>CPE SW Components - Component names.</li> <li>Test Notes - Describe what tests are performed to validate this contribution and the procedure.</li> <li>Unit Test Result - Description.</li> </ol>"},{"location":"source/docs/how-to-contribute/#code-submission-process-rdk-central-gerrit","title":"Code Submission Process - RDK Central Gerrit","text":"<p>In order to contribute code, first-time users are requested to agree to the license at wiki.rdkcentral .</p> <p>RDK components are hosted at\u00a0 code.rdkcentral . You can submit your code changes for review via that site using the workflow outlined below.</p>"},{"location":"source/docs/how-to-contribute/#create-a-jira-ticket","title":"Create a JIRA ticket","text":"<ul> <li>Refer to\u00a0 JIRA Guidelines for creating a JIRA before pushing your code changes in rdkcentral.</li> </ul>"},{"location":"source/docs/how-to-contribute/#clone-the-repository","title":"Clone the Repository","text":"<p>Clone the component repository from the Gerrit server code.rdkcentral\u00a0into a local workspace</p> <p>Clone with commit-msg hook \u00a0(to add Change-ID footer to commit messages)</p> <pre><code>git clone\u00a0https://code.rdkcentral.com/r/&amp;lt;component-name&amp;gt;\u00a0&amp;lt;component-name&amp;gt; -b &amp;lt;branch-name&amp;gt;\ncd &amp;lt;component-name&amp;gt;\ngitdir=$(git rev-parse --git-dir); curl -o $&amp;#123;gitdir&amp;#125;/hooks/commit-msg https://code.rdkcentral.com/r/tools/hooks/commit-msg ; chmod +x $&amp;#123;gitdir&amp;#125;/hooks/commit-msg\n</code></pre> <p>Click here to find the details about  &amp;  for code submission. <p>**Note:\u00a0** The commit-msg hook is installed in the local Git repository and is a prerequisite for Gerrit to accept commits. The inclusion of the unique Change-ID in the commit message allows Gerrit to automatically associate a new version of a change back to its original review.</p> <p>Note: \u00a0You may need to configure your Git identity on the cloned repository. The email address that your local Git uses should match the email address listed in Gerrit.</p> <p>Example commands to run are as follows:</p> <pre><code>$ git config user.name \"John Doe\"\n$ git config user.email \"john.doe@example.org\"\n</code></pre>"},{"location":"source/docs/how-to-contribute/#work-on-the-change-commit-to-local-clone","title":"Work on the change, commit to local clone","text":"<p>Each commit constitutes a change in Gerrit and must be approved separately. It is recommended to squash several commits into one that represents a change to the project.</p> <p>If necessary, it is possible to squash a series of commits into a single commit before publishing them, using interactive rebase:</p> <pre><code>$ git rebase --interactive\n</code></pre> <p>It is important to preserve the\u00a0 Change-Id \u00a0line when editing and there should only be one \"pick\" entry at the end of this process. The end result is to submit one change to Gerrit.</p>"},{"location":"source/docs/how-to-contribute/#push-the-new-changes-for-gerrit-for-review","title":"Push the new changes for Gerrit for review","text":"<p>Commits will be BLOCKED if the format of the commit message does not comply with the standard. You will see a warning as to why the commit was blocked.</p> <p>Mandatory Information in Commit Message</p> <ol> <li>Associated JIRA ticket (Following the Guideline to create a JIRA)</li> <li>Reason for change information</li> <li>Test procedure by which change can be verified</li> <li>Possible risks of failure</li> </ol> <pre><code>$ git commit --amend\n</code></pre> <p> <pre><code>&amp;lt;JIRA TICKET \\#1&amp;gt;, &amp;lt;JIRA TICKET \\#2&amp;gt;, &amp;lt;JIRA TICKET \\#n&amp;gt; : &amp;lt;one line summary of change&amp;gt;\n&amp;lt;empty line&amp;gt;\nReason\u00a0for\u00a0change: &amp;lt;explanation of change&amp;gt;\nTest Procedure: &amp;lt; test procedure&amp;gt;\nRisks: &amp;lt;side effects and other considerations&amp;gt; [Note: state None\u00a0if\u00a0there are no other considerations]\n&amp;lt;empty line&amp;gt;\nSigned-off-by: Your Name &amp;lt;your_name@email.com&amp;gt;\n</code></pre> <p>Submit your code changes for review</p> <pre><code>$ git push origin HEAD:refs/for/&amp;lt;branch&amp;gt;\n</code></pre> <p>When interfacing with Gerrit you push to a virtual branch /refs/for/&lt;branch&gt;, representing \"code review before submission to branch\". Gerrit will subsequently assign a unique URL for the change, to facilitate access and review via the web UI.</p> <p>Notes: </p> <ul> <li>HEAD \u00a0is a Git symbolic reference to the most recent commit on the current branch. When you change branches,\u00a0 HEAD \u00a0is updated to refer to the new branch's latest commit.</li> <li>The\u00a0 refspec \u00a0in the git push operation takes the form\u00a0 source:destination \u00a0( source \u00a0is the local ref being pushed,\u00a0 destination is the remote ref being updated).</li> </ul>"},{"location":"source/docs/how-to-contribute/#review-notifications-and-addition-of-new-reviewers","title":"Review notifications and addition of new reviewers","text":"<p>Component owners/reviewers/approvers, defined as specific groups in Gerrit, will be added to the review by default. You may request additional feedback by specifically adding reviewers via the Gerrit web GUI.\u00a0</p>"},{"location":"source/docs/how-to-contribute/#scan-and-build-on-code-submission","title":"Scan and build on code submission","text":"<p>BlackDuck, copyright scanning and build jobs will be triggered automatically from CMF Jenkins. The output of these jobs is integrated into the Gerrit voting process via custom labels and will reflect any 'red flag' in a file that has new code changes, whether introduced in the new change/patch-set or not. Scans will post any findings as comments in the Gerrit review. Build jobs also do that, but in addition will upload the build log to the corresponding JIRA ticket (if there is one) as an attachment.</p>"},{"location":"source/docs/how-to-contribute/#code-review-and-scoring-process","title":"Code review and scoring process","text":"<p>Reviewers can comment on and score a given change. The default set of rules for enabling a code change for submission requires:</p> <ul> <li>a Code Review score of +2; this can only be provided by the component owner or an admin;</li> <li>+1 score on any mandatory Gerrit labels configured for the project.</li> </ul> <p>The result of the scoring process and validation rules is to enable the\u00a0 Submit \u00a0action on the Gerrit Web UI and subsequent merge capability to the target branch.</p> <p>Label: Code Review (Highlighted in yellow color) \u00a0For a change to be mergeable, the latest patch set must have a '+2' value approval in this category or label, and no '-2 Do not submit'. Thus -2 on any patch set can block a submit, while +2 on the latest patch set enables it for merging.</p> <p>Labels: Blackduck/Copyright/Component-Build (Highlighted in yellow color) \u00a0For a change to be mergeable, the change must have a '+1' score on these labels, and no '-1 Fails'. Thus, '-1 Fails' can block a submit, while '+1' enables a submit.</p> <p></p>"},{"location":"source/docs/how-to-contribute/#submit-code-change","title":"Submit code change","text":"<p>Only authorized users, i.e. component owners, component approvers or admins, can submit the change allowing Gerrit to merge it to the target branch as soon as possible. A change can be submitted, having satisfied the approval conditions described earlier, by clicking the 'Submit Patch Set n' button within the Gerrit UI.\u00a0When a change has been Submitted, it is automatically merged to the target branch by Gerrit.</p>"},{"location":"source/docs/how-to-contribute/#abandon-change","title":"Abandon change","text":"<p>Depending on the review outcome, it might be decided to abandon the change. The component owner or an authorised user may abandon the change by clicking the \"Abandon Change\" button. The abandoned changes are not removed from the Gerrit database and can be restored at a later stage.</p>"},{"location":"source/docs/how-to-contribute/#submitted-merge-pending","title":"Submitted, Merge Pending","text":"<p>If a change depends on another change that is still in review, it will enter this state. It will be merged automatically by Gerrit once all its dependencies are submitted and merged.</p>"},{"location":"source/docs/how-to-contribute/#change-needs-to-be-reworked","title":"Change needs to be reworked","text":"<p>If you need to rework a change, you need to push another commit with the same\u00a0 Change-ID \u00a0as the original in its commit message. This is the mechanism Gerrit uses to associate or link the two items. The <code>--amend</code> option to the Git commit command prevents a new\u00a0 Change-ID \u00a0being generated by the\u00a0 commit-msg \u00a0hook.</p> <p>The basic steps are outlined below.</p> <p>First, fetch the change. If you still have the checkout that was used to push the original change, you can skip this step.</p> <pre><code>$ git fetch\u00a0https://user@code.rdkcentral.com/r/component1\u00a0refs/changes/02/2/1 &amp;&amp; git checkout FETCH_HEAD\n</code></pre> <p>where the numbering scheme for fetching the changes is as follows:</p> <p>refs/changes/&lt;last two digits of change number&gt; &lt;change number&gt; &lt;patch set number&gt;</p> <p></p> <p>Next, make any necessary source changes, and do:</p> <pre><code>$ git commit --amend\n$ git push origin HEAD:refs/for/&amp;lt;branch&amp;gt;\n</code></pre> <p>A new patch set is now appended to the Gerrit review item, and this will go through the same review process as before.</p>"},{"location":"source/docs/how-to-contribute/#gerrit-merge-failure-as-a-result-of-a-conflict","title":"Gerrit merge failure as a result of a conflict","text":"<p>Essentially this means that the remote branch has evolved since this change was started and now software conflicts with changes in the remote branch. The developer must resolve the merge conflicts in their local clone and then push another patch-set. The process is resumed at step 4, with the important distinction of committing with the --amend option, once the developer pulls the latest changes.\u00a0 Note: \u00a0A summary of the steps involved, assuming the local branch still exists:\u00a0</p> <p>Rebase the local branch to the latest state of origin/&lt;branch&gt;;Resolve all conflicts; Commit with the <code>--amend</code> option; Push changes to Gerrit for review. After this change a new patch set is created for the change.</p> <p>Note: If the local branch no longer exists, the steps are as follows:</p> <pre><code>$ git fetch\u00a0https://user@code.rdkcentral.com/r/rdk_component_1\u00a0refs/changes/58/58/2 &amp;&amp; git checkout FETCH_HEAD\n$ git rebase origin/&amp;lt;branch&amp;gt;\n[Edit the conflicting file, cleaning up the &amp;lt;&amp;lt;&amp;lt;&amp;lt;, ==== &amp;gt;&amp;gt;&amp;gt; markers surrounding the conflicting lines]\n$ git add &amp;lt;file&amp;gt;\n$ git commit --amend\n$ git push origin HEAD:refs/for/&amp;lt;branch&amp;gt;\n</code></pre>"},{"location":"source/docs/how-to-contribute/#rdk-components-product-branch","title":"RDK Components - Product Branch","text":"<p>Following RDK components are hosted at\u00a0 code.rdkcentral . Follow the Instructions to submit your code changes.</p> <p>Example of how to use git clone for meta-rdk-ext component:\u00a0 git clone https://code.rdkcentral.com/r/plugins/gitiles/rdk/components/generic/rdk-oe/meta-rdk-ext \u00a0-b rdk-next</p> <p>List of open-sourced and licensed repositories hosted in RDK central gerrit can be found from Source Code Repositories .</p>"},{"location":"source/docs/how-to-contribute/#code-submission-process-rdk-central-github","title":"Code Submission Process - RDK Central GitHub","text":""},{"location":"source/docs/how-to-contribute/#introduction","title":"Introduction","text":"<p>GitHub is a Git repository hosting service, but it adds many of its own features. While Git is a command line tool, GitHub provides a Web-based graphical interface.</p> <p>GitHub Enterprise is the on-premises version of GitHub and is available on VMware, AWS, and OpenStack KVM, on your own servers or in a private cloud. GitHub Enterprise operates on your infrastructure with your existing information security controls from firewalls and VPNs, to IAM and monitoring systems.</p> <p>CMF GitHub Organizations</p> <p>There is one primary RDKM Code Management organizations, namely RDKcentral. This organization hosts the open-source repositories for projects pertaining to RDK-V, RDK-B and RDK-C profiles.</p> <ul> <li>github/rdkcentral</li> </ul>"},{"location":"source/docs/how-to-contribute/#rdk-central-github-components","title":"RDK Central GitHub Components","text":"<p>Please refer to this link to see all the repositories\u00a0 Source Code Repositories .</p>"},{"location":"source/docs/how-to-contribute/#github-pull-requests","title":"GitHub Pull Requests","text":"<p>Pull requests let you tell others about changes you've pushed to a branch in a repository on GitHub. Once a pull request is opened, you can review the potential changes with collaborators and add follow-up commits before your changes are merged into the base branch. Anyone with read permissions to a repository can create a pull request, but you must have write permissions to create a branch. If you want to create a new branch for your pull request and don't have write permissions to the repository, you can fork the repository first. Pull requests can only be opened between two branches that are different.</p>"},{"location":"source/docs/how-to-contribute/#github-fork","title":"GitHub Fork","text":"<p>A \u2018fork\u2019 is a personal copy of another user's repository that lives on your GitHub account. Forks allow you to freely make changes to a project without affecting the original. A forked project also remains attached to the original, allowing you to submit a pull request to the original's author to update with your changes, ensuring you\u2019re always working off a recent or up-to-date codebase.</p>"},{"location":"source/docs/how-to-contribute/#github-workflow-steps","title":"GitHub Workflow Steps","text":"<ul> <li>Create a Fork by simply clicking on the 'fork' button of the repository page on GitHub.</li> <li>Clone your Fork, the clone command creates a local git repository from your remote fork on GitHub.</li> <li>git clone\u00a0     https://github.com/USERNAME/REPOSITORY.git</li> <li>Modify the Code in your local clone and commit the changes to your local clone using the git commit command.</li> <li>Push your Changes by invoking the git push command, from your workspace, to upload your changes to your remote fork on GitHub.</li> <li>Create a Pull Request by clicking the 'pull request' button on the GitHub page of your remote fork.</li> </ul>"},{"location":"source/docs/how-to-contribute/#configure-your-github-access-token","title":"Configure your Github access token","text":"<p>In the recent past support for direct password authentication was removed from Github. You will need to generate a Github personal token to push your code changes RDK Central Github.</p> <p>To create your personal token, you have to go to github.com -&gt; Settings -&gt; Developer Settings -&gt; Personal Access Token -&gt; Generate New Token.</p> <p>Note - While creating a new token, it will ask for Github configuration options selection \u2013 Select everything.</p> <p>Once the Github token is generated successfull, you will need to add an entry an entry to the ~/.netrc file OR you can directly use this token as your Github password in the command line to push the code changes.</p> <p>Example: how to add Github credential on ~/.netrc file <pre><code>machine\n[github.com](http://github.com)\nlogin your-github-handle-name password ghp_BCy09kNYxg82no6OnliSJQVngGi9K1234567\n</code></pre></p>"},{"location":"source/docs/how-to-contribute/#github-protected-branches","title":"GitHub Protected Branches","text":"<p>Protected branches ensure that collaborators on your repository cannot make irrevocable changes to branches. Enabling protected branches also allows you to enable other optional checks and requirements, like required status checks and required reviews.</p> <p>A custom CMF branch protection scheme is deployed in each repository in order to enforce the desired workflows. This scheme imposes the following rules:</p> <ul> <li>Require pull request reviews before merging</li> <li>Require status checks to pass before merging<ul> <li>blackduck</li> <li>copyright</li> <li>license/cla</li> <li>component-build</li> </ul> </li> </ul> <p>Required status checks ensure that all required CI tests are passing before collaborators can make changes to a protected branch. Status checks are based on external processes, such as continuous integration builds, code compliance scanning, which run for each push you make to a repository. You can see the pending, passing, or failing state of status checks next to individual commits in your pull request.</p>"},{"location":"source/docs/how-to-contribute/#contributor-license-agreement-cla","title":"Contributor License Agreement (CLA)","text":"<p>The RDK CLA facilitates the acceptance and sharing of RDK contributions within the community.</p> <p>When you contribute to an RDK open source project on GitHub via a new pull request, a bot will evaluate whether you have signed the CLA. The bot will comment on the pull request, including a link to accept the agreement.</p> <p>CLA assistant enables contributors to sign CLAs from within a pull request. The CLA is stored as a GitHub Gist file and linked with the repository/organization in CLA assistant.</p> <p>CLA assistant:</p> <ul> <li>Comments on each opened pull request to ask the contributor to sign the CLA</li> <li>Allows contributors to sign a CLA from within a pull request</li> <li>Authenticates the signee with his or her GitHub account</li> <li>Updates the status of a pull request when the contributor agrees to the CLA</li> <li>Automatically asks users to re-sign the CLA for each new pull request in the event the associated Gist &amp; CLA has changed</li> <li>Repository owners can review a list of users who signed the CLA for each version of it.</li> </ul> <p>Note - CLA assistant is provided by SAP as a free hosted offering under:\u00a0 cla-assistant.io</p>"},{"location":"source/docs/how-to-contribute/#compliance-scanning","title":"Compliance Scanning","text":"<p>CMF uses BlackDuck (Protex) to check incoming contributions for license compliance. BlackDuck is normally a very manual tool but a significant level of automation has been developed by the team to reduce manual intervention, but it still requires a human to oversee it.</p> <p>Compliance scanning is looking for several things:</p> <ul> <li>Addition of source code with a conflicting license (e.g. LGPL code in an Apache component).</li> <li>Modification of an opensource component with code of a conflicting license.</li> <li>Incorrect or proprietary copyright attribution.</li> </ul> <p>The key points are as follows:</p> <ul> <li>Scan contribution in GitHub Pull Request.</li> <li>Scan is automatically triggered by a webhook.</li> <li>Results in scan of the contribution only, i.e. only the changes.</li> <li>Required Status Check, associated with the Blackduck scan is updated.</li> <li>Summary of the scan including any code matches are provided via a link to an associated Gist.</li> </ul> <p>OSS Engineer and interested parties are notified of scan failures (violations, pending identifications or reviews etc) via AWS Mailing list and Slack.</p>"},{"location":"source/docs/how-to-contribute/#git-secrets-scanning","title":"git-secrets Scanning","text":"<p>git-secrets is a tool created by AWS Labs that scans commits and commit messages and aims to prevent passwords and other sensitive information being committed to a git repository. The tool can also scan files or folders to look for secrets such as an AWS Access Key ID and AWS Secret Access Keys in a repository. git-secrets scans commits, commit messages, and merge commits to prevent adding secrets into your git repositories. If a commit, commit message, or any commit in merge history matches one of the configured prohibited regular expression patterns, then the commit is rejected.</p>"},{"location":"source/docs/how-to-contribute/#example-of-how-to-push-the-code-changes","title":"Example of how to push the code changes","text":""},{"location":"source/docs/how-to-contribute/#step-1-fork-the-component-from-github","title":"Step 1: Fork the component from GitHub","text":"<p>Sign-in to GitHub with your own credentials.</p> <p>Search for the Component.</p> <p>Fork the component from GitHub. Forking will create a copy (i.e., your own WORKSPACE) of an original component to work.</p> <p></p>"},{"location":"source/docs/how-to-contribute/#step-2-creating-a-new-branch","title":"Step 2: Creating a new Branch","text":"<p>From the file tree view on the left, select the \u00a0 branch dropdown menu, In the \"Find or create a branch...\" text field, type a unique name for your new branch, then click \u00a0 Create branch .</p> <p></p>"},{"location":"source/docs/how-to-contribute/#step-3-clone-the-component-with-new-branch","title":"Step 3: Clone the Component with new branch","text":"<p>Click on the \"Clone or download\" button to get the clone URL from GitHub. Ensure your GitHub username present in the URL to start work with your own workspace.</p> <p></p> <pre><code>abcd123@dvm-yocto4-docker-abcd123:~/builds/meta_wan$ git clone https://github.com/Sukanya673/meta-rdk-wan.git -b new_branch_1\nCloning into 'meta-rdk-wan'...\nremote: Enumerating objects: 276, done.\nremote: Counting objects: 100% (117/117), done.\nremote: Compressing objects: 100% (71/71), done.\nremote: Total 276 (delta 95), refused 47 (delta 41), pack-reused 159 (from 1)\nReceiving objects: 100% (276/276), 59.05 kiB | 2.68 MiB/s, done.\nResolving deltas: 100% (141/141), done.\nabcd123@dvm-yocto4-docker-abcd123:~/builds/meta_wan$\n</code></pre>"},{"location":"source/docs/how-to-contribute/#step-4-work-on-changes-and-gerrit-commands-to-push-the-changes","title":"Step 4: Work on changes and Gerrit commands to push the changes","text":"<p>Make the code changes, and commit the changes</p> <p>cd\u00a0 meta_wan</p> <pre><code>git clone https://github.com/Sukanya673/meta-rdk-wan.git -b new_branch_1</code></pre> <p>Modify your code.</p> <p>$ git status \u00a0 \u00a0Here You will see the files you have locally modified.  $ git add &lt;FILE_NAME&gt; $ git commit -a\u00a0 \u00a0 \u00a0Add the following to your commit message. \u00a0 \u00a0 \u00a0 \u00a0 JIRA-ID Write a small description \u00a0 \u00a0 \u00a0 \u00a0 &lt;One empty line&gt; \u00a0 \u00a0 \u00a0 \u00a0 Reason for change: \u00a0 \u00a0 \u00a0 \u00a0 Test Procedure: \u00a0 \u00a0 \u00a0 \u00a0 Risks:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Signed-off-by:</p> <p>$ git push</p> <p>After submitting your changes, follow the next step to create a PR.</p>"},{"location":"source/docs/how-to-contribute/#step-5-create-pull-request-for-review-the-changes","title":"Step 5: Create pull request for review the changes","text":"<p>Once submitted the changes need to create pull request from GitHub for review. Pull requests \u00a0 let you tell others about changes you've pushed to a branch in a repository on \u00a0 GitHub . Once a \u00a0 pull request \u00a0 is opened, you can discuss and review the potential changes with collaborators and add follow-up commits before your changes are merged into the base branch.</p> <ul> <li>Click on \"Compare &amp; pull request\" button.</li> </ul> <p></p> <ul> <li>Provide the commit request and Click on\u00a0\"Create pull request\" button.</li> </ul> <p></p> <ul> <li>Pull Request page will be created.</li> </ul> <p></p>"},{"location":"source/docs/how-to-contribute/#step-6-working-on-review-comments","title":"Step 6: Working on review comments","text":"<p>Once you've created a pull request, you can push commits from your workspace to add them to your existing pull request. These commits will appear in chronological order within your pull request and the changes will be visible in the \"Files changed\" tab.</p> <p>Other contributors can review your proposed changes, add review comments, contribute to the pull request discussion, and even add commits to the pull request.  </p>"},{"location":"source/docs/how-to-contribute/#documenting-the-code","title":"Documenting the Code","text":""},{"location":"source/docs/how-to-contribute/#why-to-document","title":"Why to Document?","text":"<p>Writing documentation improves the design of your code. Talking through your API and design decisions on paper allows you to think about them in a more formalized way. A nice side effect is that it allows people to contribute code that follows your original intentions as well.</p>"},{"location":"source/docs/how-to-contribute/#how-to-document","title":"How to Document?","text":"<p>RDK component code is documented following the Doxygen standards and guidelines. Doxygen is a popular open-source tool for generating documentation from annotated C/C++ sources. Also, Doxygen supports documenting code written in other programming languages, such as Python, PHP, Java, etc.</p>"},{"location":"source/docs/how-to-contribute/#tools-required-for-doxygen-documentation","title":"Tools Required for Doxygen Documentation","text":"<p>The following tools\u00a0are required to be installed in Linux machine (through apt-get install) to generate documentation with respect to various data flow diagrams.</p> <ol> <li>doxygen : It is a tool for a documentation system for various programming languages such as C++, C, Java and Objective-C.</li> <li>graphviz : Rich set of graph drawing tools. It was required to fulfill the need for centralized documentation presenting all available tools in the graphviz package.</li> <li>dot : Filter for drawing directed graphs. A graph that can be drawn as hierarchy. It reads attributed graph files and writes drawings. By default, the output format dot is the input file with layout coordinates appended.</li> <li>perl : It is a script file used by doxygen, and it should be present in the system.</li> <li>mscgen : Message Sequence Chart Renderer. This will help to make sequence diagram for Doxygen documentation.</li> </ol>"},{"location":"source/docs/how-to-contribute/#steps-to-generate-document-using-doxygen","title":"Steps to Generate Document using Doxygen","text":"<p>The following are the steps to generate documentation using Doxygen tool.</p> <ol> <li>Create a new folder \u201cexample_name\". This is where the final report will reside.</li> <li>Go to directory \u201cexample_name\u201d.</li> <li>Reference doxygen configuration file</li> <li>Doxygen.dox: used for customizing the index page.</li> <li>doxygen.css: style sheet file used for formatting html output.</li> <li>Doxyfile: Configuration file that is needed for generating doxygen output.</li> <li>RDK-Logo.png: RDK Logo.</li> <li>Check out all the RDK component source code (Source code must be Doxygen complaint) for which document needs to be generated, for example:</li> <li>$ git clone https://code.rdkcentral.com/r/rdk/components/generic/wifi \u00a0\u00a0 wifi</li> <li>Edit Doxyfile and set all configurations as required, given below are examples</li> <li>PROJECT_NAME\u00a0 /* Name of the project */</li> <li>INPUT\u00a0\u00a0\u00a0/* Path of source code provided as input for document generation*/</li> <li>OUTPUT_DIRECTORY /* output folder path */</li> <li>Edit doxygen.dox, if the index page needs to be customized, add module names that will be shown in output index page.</li> <li>Edit doxygen.css, for output formats, fonts, etc.</li> <li>Use the following command at the command prompt, to generate html report.</li> <li>$\u00a0 doxygen Doxyfile</li> <li>Doxygen Output HTML report will be available at '/example_name/OUTPUT_DIRECTORY/html' folder, open index.html file to see Doxygen report.</li> </ol>"},{"location":"source/docs/how-to-contribute/#steps-to-add-module-level-information-to-components","title":"Steps to add module level information to components","text":"<p>Refer to below Doxygen Guideline Section for uniform style of adding Doxygen comments for the RDK system.  </p>"},{"location":"source/docs/how-to-contribute/#doxygen-guideline","title":"Doxygen Guideline","text":""},{"location":"source/docs/how-to-contribute/#introduction_1","title":"Introduction","text":"<p>The purpose of this page is to provide a uniform style of Doxygen commenting for the RDK system. It will serve as a reference for current and future developers while documenting the RDK system as it evolves. Ultimately, this will establish a consistent manner of documentation to enhance the simplicity, readability, scalability, writability, reliability, and maintainability of the system.\u00a0</p>"},{"location":"source/docs/how-to-contribute/#documentation-style","title":"Documentation Style","text":"<p>Doxygen documentation can be generated in many formats (HTML, LaTeX, RTF, PDF, DOC). HTML generation has support for more plugins and is easier to refactor as the system changes. Doxygen style should follow a consistent format to aid development across different IDEs, reducing issues when generating documentation.</p> <pre><code>/\\*\\*\n\\* @tagname\n\\*/\n</code></pre> <p>This is an example of a Java doc style Doxygen tag, since it uses the \u201c@\u201d symbol. Tags using the \u201c\\tagname\u201d style are considered Qt style Doxygen tags.There should be a header file containing only Doxygen tags or a separate Doxygen file that acts as a guide for the components, classes, methods, and variables (e.g. DoxygenMainpage.h). This can be done using the\u00a0@mainpage\u00a0tag at the top of the file.</p>"},{"location":"source/docs/how-to-contribute/#system","title":"System","text":"<p>There should be a header file containing only Doxygen tags or a separate Doxygen file that acts as a guide for the components, classes, methods, and variables (e.g., DoxygenMainpage.h). This can be done using the @mainpage\u00a0tag at the top of the file.</p> <pre><code>/\\*\\*\n\\* @mainpage Title of Document\n\\*\n\\*/\n</code></pre>"},{"location":"source/docs/how-to-contribute/#file","title":"File","text":"<p>A file should contain the\u00a0@file\u00a0tag at the top of the file. This supports generation of a file list tab on the main page. It also helps when files contain multiple classes.</p> <pre><code>/\\*\\*\n\\* @file FileName.h\n\\*\n\\* @brief Brief file description.\n\\*\n\\* Verbose file description.\n\\*/\n</code></pre>"},{"location":"source/docs/how-to-contribute/#classes","title":"Classes","text":"<p>Classes can be tagged in a number of different ways, but in general they are tagged using the\u00a0@brief\u00a0and\u00a0@class\u00a0tags before the class declaration. Having the\u00a0@author,\u00a0@date, and\u00a0@version\u00a0supports tractability as the system is versioned throughout the software lifecycle. When updating classes, update comments like this:</p> <pre><code>\\#include &amp;lt;iostream&amp;gt;\nusing namespace std;\n/\\*\\*\n\\* @brief Brief class description\n\\*\n\\* Verbose description of class.\n\\*\n\\* @class Class Name\n\\*/\nclass ClassName &amp;#123;\npublic:\nClassName();\n~ClassName();\nint var1; /\\*\\*&amp;lt; Comment about public member variable\\*/\n/\\*\\*\n\\*@brief Brief method description\n\\*\n\\* Verbose description of method\n\\*\n\\*@param Parameter in the method\u2019s definition\n\\*\n\\*@return Return value of method\n\\*/\nint Function1(int x);\nprotected:\nint var2; /\\*\\*&amp;lt; Comment about protected member variable\\*/\n/\\*\\*\n\\*@brief Brief method description\n\\*\n\\* Verbose description of method\n\\*\n\\*@param Parameter in the method\u2019s definition\n\\*\n\\*@return Return value of method\n\\*/\nint Function2(int x);\nprivate:\nint var3; /\\*\\*&amp;lt; Comment about private member variable\\*/\n/\\*\\*\n\\*@brief Brief method description\n\\*\n\\* Verbose description of method\n\\*\n\\*@param Parameter in the method\u2019s definition\n\\*\n\\*@return Return value of method\n\\*/\nint Function3(int x);\n&amp;#125;;\n</code></pre>"},{"location":"source/docs/how-to-contribute/#structs","title":"Structs","text":"<p>A struct can be tagged in the same way a class, but it is best to use the \u00a0 @struct \u00a0 tag. When updating structs, update comments like this:</p> <pre><code>/\\*\\*\n\\*@brief Brief struct description\n\\*\n\\*@struct Struct Name\n\\*/\n</code></pre>"},{"location":"source/docs/how-to-contribute/#methods","title":"Methods","text":"<p>Methods can be tagged in a number of ways, but in general the \u00a0 @brief ,\u00a0 @details ,\u00a0 @param , and \u00a0 @return \u00a0 tags are used before a method\u2019s declaration or implementation. When updating methods, update comments like this:</p> <pre><code>/\\*\\*\n\\*@brief Brief method description\n\\*\n\\* Verbose description of method\n\\*\n\\*@param Parameter in the method\u2019s definition\n\\*\n\\*@return Return value of method\n\\*@retval Verbose explanation of return values\n\\*/\nint addNumbers(int x)\n&amp;#123;\nint sum = 0;\nsum += x;\u00a0\nreturn sum;\u00a0\n&amp;#125;\n</code></pre>"},{"location":"source/docs/how-to-contribute/#variables","title":"Variables","text":"<p>When updating variables, update comments like this:</p> <pre><code>int number; /\\*\\*&amp;lt; Comment about number\\*/\n</code></pre>"},{"location":"source/docs/how-to-contribute/#enumerated-types","title":"Enumerated Types","text":"<p>Enumerated types are tagged using the\u00a0 @enum . \u00a0When updating enum types, update comments like this:</p> <pre><code>/\\*\\*\n\\*@brief Brief enum description\n\\*\n\\*@enum enum Name\n\\*/\n</code></pre>"},{"location":"source/docs/how-to-contribute/#miscellaneous","title":"Miscellaneous","text":"<p>There are many tags you can use with HTML markup to create unique Doxygen documentation for a given file, class, method, or variable. The following are common tags that should be used when appropriate.</p> <p><pre><code>/\\*\\*\n\\*@note A brief remark about the implementation to help clarify.\n\\*\n\\*@attention An important remark that may cause code to break.\n\\*\n\\*@warning An import remark that may depend on random conditions etc.\n\\*\n\\*@see A reference to a class or a link to documentation (e.g. http://document.1a.com)\n\\*/\n</code></pre> <pre><code>/\\*\\*\n\\*@bug A remark about a known bug in the code.\n\\*\n\\*@todo A remark of what needs to be done to fix issues or remaining work.\n\\*\n\\*/\n</code></pre> <pre><code>/\\*\\*\n\\*@a Formats following word in special font (used for hyperlinks)\n\\*\n\\*@b Formats following word in bold\n\\*\n\\*@em Formats following word in italic\n\\*\n\\*@c Formats following word in monospaced typewriter font\n\\*\n\\*/\n</code></pre> <pre><code>/\\*\\*\n\\* - bulleted list item1\n\\* - sub bulleted item1\n\\*\n\\* - bulleted list item2\n\\*\n\\*/\n</code></pre> <pre><code>/\\*\\*\n\\* -# numbered list item1\n\\* -# numbered list item2\n\\*\n\\*/\n</code></pre> <pre><code>/\\*\\*\n\\*@code\ni++;\n\\*@endcode\n\\*/\n</code></pre></p>"},{"location":"source/docs/how-to-contribute/#setting-up-doxygen-environment-on-linux","title":"Setting up Doxygen Environment on Linux","text":"<p>Tools Required for Doxygen Documentation:</p> <pre><code>Following Tools are need to be installed in Linux machine (through apt-get install) to generate documentation with respect to various data flow diagrams.\n\u00a0 \u00a0 $ sudo apt-get install \"doxy\\*\"\n\u00a0 \u00a0 $ sudo apt-get install graphviz\n\u00a0 \u00a0 $ sudo apt-get install dot\n\u00a0 \u00a0 $ sudo apt-get install mscgen\n\u00a0 \u00a0 $ sudo apt-get install perl\n</code></pre> <p>Check the doxygen version by using command: \u00a0 <code>$ doxygen --version</code> Graphviz:\u00a0 graphviz.org (Click the Download link on the left side of the page)</p>"},{"location":"source/docs/how-to-refresh-the-patches/","title":"How to Refresh the Patches","text":""},{"location":"source/docs/how-to-refresh-the-patches/#overview","title":"Overview","text":"<p>Sometimes while applying patches, it may face offsets mismatch and results in failure. This makes your build verification also to fail. You can get similar error in console logs for patch failures.</p> <p><pre><code>ERROR: Command Error: exit status: 1 Output:  \nApplying patch index.patch  \npatching file source/Styles/xb3/code/index.php  \nHunk \\#1 succeeded at 22 (offset 21 lines).  \nHunk \\#2 succeeded at 32 (offset 21 lines).  \nHunk \\#3 succeeded at 73 (offset 21 lines).  \nHunk \\#4 succeeded at 183 (offset 27 lines).  \nHunk \\#5 succeeded at 195 (offset 27 lines).  \nHunk \\#6 succeeded at 245 (offset 37 lines).  \nHunk \\#7 succeeded at 307 (offset 37 lines).  \nHunk \\#8 succeeded at 460 (offset 52 lines).  \nHunk \\#9 succeeded at 469 (offset 52 lines).  \nHunk \\#10 FAILED at 431.  \nHunk \\#11 FAILED at 445.  \nHunk \\#12 FAILED at 455.  \n3 out of 12 hunks FAILED -- rejects in file source/Styles/xb3/code/index.php  \nPatch index.patch does not apply (enforce with -f)\n</code></pre> From the logs, you can find out that patch is not applied to the source file properly. In such scenarios you will have to update or refersh the patch.</p>"},{"location":"source/docs/how-to-refresh-the-patches/#step-1-get-the-patch-file","title":"Step 1 : Get the patch file","text":"<p>1.Find the repo for the patch file.(For ex : here the patch file is index.patch.)</p> <p>2.Clone the repo. For ex: <pre><code>$ mkdir patch\n$ cd patch/\n$ git clone ssh://rkumar840@gerrit.teamccp.com:29418/rdk/yocto_oe/layers/meta-rdk-oem-pace-broadcom\n</code></pre> 3.Checkout the branch for which you want to create the patch.</p> <p><pre><code>$ git checkout 1905_sprint\n$ git branch\n</code></pre> 4.Find the location of the patch file in the repo.</p> <pre><code>$ find . -iname index.patch\n./meta-pacexf3/recipes-ccsp/ccsp/ccsp-webui/index.patch\n</code></pre>"},{"location":"source/docs/how-to-refresh-the-patches/#step-2-identify-the-component-repo","title":"Step 2 : Identify the component repo","text":"<ol> <li> <p>Next find the repo for the actual source file to which the patch file was getting patched. ( For ex: here the source file is index.php)</p> </li> <li> <p>clone the repo Example: <pre><code>$ mkdir source\n$ cd source/\n$ git clone ssh://rkumar840@gerrit.teamccp.com:29418/rdk/rdkb/components/opensource/ccsp/webui/generic\n</code></pre> 3.checkout the required branch</p> </li> </ol> <p><pre><code>$ git checkout 1905_sprint\n$ git branch\n</code></pre> 4.Cherry-pick the required changes also <pre><code>$ git fetch\u00a0ssh://rkumar840@gerrit.teamccp.com:29418/rdk/rdkb/components/opensource/ccsp/webui/generic\n</code></pre> 5.After cherry-picking you can verify the changes in the source file.</p>"},{"location":"source/docs/how-to-refresh-the-patches/#step-3-apply-the-patches","title":"Step 3 : Apply the patches","text":"<p>1. create another directory, and clone the source code repo (as in step 2). For ex :</p> <ul> <li>$ mkdir dummy</li> <li>$ cd dummy/</li> <li>$ git\u00a0\u00a0clone\u00a0     ssh://rkumar840@gerrit.teamccp.com:29418/rdk/rdkb/components/opensource/ccsp/webui/generi     c</li> </ul> <p>2.checkout the required branch</p> <ul> <li>$ git checkout 1905_sprint</li> <li>$ git branch</li> </ul> <p>3.Copy the patch file from the patch repo (step 1) to the current directory.</p> <ul> <li>$ cp ../patch/meta-pacexf3/recipes-ccsp/ccsp/ccsp-webui/index.patch .</li> <li>$ ls</li> </ul> <p>cmpnt_build_custom_pre_arm.mk CONTRIBUTING.md \u00a0 \u00a0 \u00a0 \u00a0debug_scripts\u00a0 \u00a0 \u00a0 LICENSE\u00a0 \u00a0 \u00a0 \u00a0 \u00a0NOTICE\u00a0 \u00a0 \u00a0 \u00a0 \u00a0scripts \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0cmpnt_build_custom_pre_pc.mk \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0COPYING\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 index.patch\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Makefile.orig\u00a0 \u00a0 \u00a0README\u00a0 \u00a0 \u00a0 \u00a0source</p> <p>4.Apply the patch to the source file/files.</p> <ul> <li>$ patch -p1 &lt; index.patchpatching file source/Styles/xb3/code/index.php     Hunk #1 succeeded at 22 (offset 21 lines).     Hunk #2 succeeded at 32 (offset 21 lines).     Hunk #3 succeeded at 73 (offset 21 lines).     Hunk #4 succeeded at 183 (offset 27 lines).     Hunk #5 succeeded at 195 (offset 27 lines).     Hunk #6 succeeded at 245 (offset 37 lines).     Hunk #7 succeeded at 307 (offset 37 lines).     Hunk #8 succeeded at 445 (offset 37 lines).     Hunk #9 succeeded at 454 (offset 37 lines).     Hunk #10 succeeded at 468 (offset 37 lines).     Hunk #11 succeeded at 482 (offset 37 lines).     Hunk #12 succeeded at 492 (offset 37 lines).</li> </ul> <p>5.It should be applied successfully. In case of observing any failure when apply the patch to the source file/files then skip this step. If no failures observed then take a backup for the file/files got patched. For ex :\u00a0</p> <ul> <li>$ cp source/Styles/xb3/code/index.php source/Styles/xb3/code/index_bk.php</li> </ul> <p>6.In case of observing any failure when apply the patch to the source file/files, then this may\u00a0expects some other patch to be applied first. In such case,</p> <ul> <li>Find the repo init command from the full console log. Search for \"Repo Init\".\u00a0</li> </ul> <p>Example: Repo Init for - Project: &lt; clone_url&gt; Branch: 2003_sprint Manifest: ciscoxb3-3939B</p> <ul> <li>Create another directory</li> </ul> <p>$ mkdir cisco_intel_repo</p> <p>$ cd cisco_intel_repo</p> <ul> <li>Append .xml with manifest filename in repo init command and Clone the repo</li> </ul> <p>$ repo init -u &lt; clone_url&gt; -m ciscoxb3-3939B.xml -b 2003_sprint</p> <p>$\u00a0repo sync -j4 --no-clone-bundle</p> <ul> <li>grep with file name( in which patch applied failure observed) in meta-* layers, So that will find the other patch file which creates this file.</li> </ul> <p>$\u00a0grep -irn \"Filename\" meta-* \u00a0 \u00a0 \u00a0 \u00a0 \u00a0</p> <ul> <li>Analyse and apply the patch file first, and then on top of that apply the second patch file,\u00a0If no failures observed then take a backup for the file/files got patched. For ex :\u00a0</li> </ul> <p>$ cp source/Styles/xb3/code/index.php source/Styles/xb3/code/index_bk.php \u00a0 \u00a0 \u00a0</p>"},{"location":"source/docs/how-to-refresh-the-patches/#step-4-compare-the-files-and-generate-patch","title":"Step 4 : Compare the files and generate patch","text":"<p>1.Now you can use \"Meld tool\" to compare between files to refresh the patch. Here you can compare between the source file generated in step 2 (which will have the required changes) and the source file generated in step-3 (which will have the patch appied on to it).</p> <p>2.During comparing between source files make sure that you take only the required changes (changes available in actual source file step-2) to the patched file generated in step-3.</p> <p>3.Once all changes are taken , you can verify the patch by checking the option file/format as patch in the tool. Save the updated file and copy it to your repo (repo generated in step-2)</p> <p>4.Now in your repo , you will have 2 source file (for ex: one will be\u00a0index.php --original file with the required changes and\u00a0index_bk.php --updated file with patch applied and also your changes).</p> <p>5.In terminal , you can use command \"diff -ruN\u00a0 file1 file2 &gt; new_patch_file.patch\" to generate a\u00a0 new patch.</p> <p>6.For ex : diff -ruN index.php index_bk.php &gt; new_index.patch</p> <p>7.In case patch file has more than one file, then append the difference using diff -ruN next_file nextfile_bk.php &gt;&gt; new_index.patch</p>"},{"location":"source/docs/how-to-refresh-the-patches/#step-5-update-the-patch-file","title":"Step 5 : Update the patch file","text":"<p>1. Open the newly created patch file, update the file location correctly and save it. For ex :</p> <p>git/source/Styles/xb3/code/index.php 2019-05-20 05:56:54.047078876 +0000 +++ git.1/source/Styles/xb3/code/index.php 2019-05-20 06:26:56.000000000 +0000</p>"},{"location":"source/docs/how-to-refresh-the-patches/#step-6-validate-the-patch-file","title":"Step 6 : Validate the patch file","text":"<p>1.In order to verify the newly created patch, you can create a temporary folder, clone the repo, checkout the required branch. Now copy the latest patch (new_index.patch) here.\u00a0</p> <p>2.In the terminal, give the command\u00a0 patch -p1 &lt;\u00a0 new_index.patch , will apply the patch to the source file. It should not fail.</p>"},{"location":"source/docs/how-to-refresh-the-patches/#step-7-push-the-changes","title":"step 7 : Push the changes","text":"<p>1.Now for pushing the latest patch, clone the repo for patch (step-1)</p> <ul> <li>$ mkdir push</li> <li>$ cd push/</li> <li>$ git clone\u00a0     ssh://rkumar840@gerrit.teamccp.com:29418/rdk/yocto_oe/layers/meta-rdk-oem-pace-broadcom     \u00a0.</li> </ul> <p>2.checkout the required branch.</p> <ul> <li>$ git checkout 1905_sprint</li> </ul> <p>3.copy the latest patch(new_index.patch in this case) to the actual patch file available in the repo.</p> <ul> <li>$ cp ../src/new_index.patch\u00a0meta-pacexf3/recipes-ccsp/ccsp/ccsp-webui/index.patch</li> <li>$ git status</li> </ul> <p>4.It will show the file as modified. Perform git add.</p> <ul> <li>$ git add\u00a0meta-pacexf3/recipes-ccsp/ccsp/ccsp-webui/index.patch</li> <li>$ git commit</li> </ul> <p>5.Update if any commit message has to be added and try to push the changes.</p> <ul> <li>$ git push origin HEAD:refs/for/1905_sprint</li> </ul> <p>6.It fails for commit message upload. For ex : you may get error like this :</p> <ul> <li>remote: ERROR: [6b429fb] missing Change-Id in commit message footer</li> <li>remote:</li> <li>remote: Hint: To automatically insert Change-Id, install the hook:</li> <li>remote:     gitdir=$(git rev-parse --git-dir); scp -p -P 29418     rkumar840     @gerrit.teamccp.com     :hooks/commit-msg ${gitdir}/hooks/</li> <li>remote: And then amend the commit:</li> <li>remote: git commit --amend</li> </ul> <p>7.Run the command mention in logs.</p> <ul> <li>$ gitdir=$(git rev-parse --git-dir); scp -p -P 29418\u00a0     rkumar840     @gerrit.teamccp.com     :hooks/commit-msg ${gitdir}/hooks/</li> <li>$ git commit --amend (No change-id is assigned to the change.)</li> <li>$ git commit --amend\u00a0 (change-id has assigned now.)</li> <li>$ git push origin HEAD:refs/for/1905_sprint</li> </ul> <p>8.This will push the changes successfully to the branch. You can open the gerrit link and verify.</p> <p>9.Put the same topic name for the patch and the source file , trigger the verification.</p>"},{"location":"support/docs/overview/","title":"Place Holder markdown for Support page","text":""},{"location":"tools/docs/Automatics/","title":"Automatics","text":"<p>Automatics is the fully \u00a0integrated test automation system to support functional &amp; non-functional testing. Automatics is now available to the RDK community. Any community member can use this system to validate their RDK builds or their infrastructure.</p> <p>Automatics supports:</p> <ul> <li>Integration with CI flow to validate new changes checked in by user</li> <li>Configure test script details and test strategies</li> <li>Manual trigger of automated tests against RDK builds</li> <li>Walk through on test execution results</li> <li>End to End system is designed to support fast-paced DevOps model</li> <li>Support to execute test scripts based on Java, Python and PyTest.</li> </ul> <p>Major features of Automatics framework to work with external tools to enhance the Automatics capabilities:</p> <ul> <li>The framework supports integration with modern software tools -     Jira, ALM, Jenkins, Git, Grafana, Candela, CDRouter etc</li> <li>Dynamic device allocation and device health check is supported</li> <li>Automated defect creation and tagging can be done using the     framework</li> </ul> <p></p>"},{"location":"tools/docs/Automatics/#automatics-overview","title":"Automatics Overview","text":"<ul> <li> <ul> <li> <p> Automatics Architecture </p> </li> <li> <p></p> <p> Automatics in CI/CD </p> </li> <li> <p></p> <p> Automatics Repository Details </p> </li> <li> <p></p> <p> Automatics Tools Releases </p> </li> </ul> </li> </ul>"},{"location":"tools/docs/Automatics/#automatics-recent-updates","title":"Automatics Recent Updates","text":"<p> Automatics Framework and Tools - Release V15.0\u00a0is available</p> <p> Automatics Framework and Tools - Release V10.0\u00a0is available</p> <p> Automatics RDK-B Test script Release V10.0 is available</p>"},{"location":"tools/docs/Automatics/#automatics-useful-links","title":"Automatics Useful Links","text":"<ul> <li>Automatics Overview Webinar</li> <li>Automatics RDK-B Test Coverage Overview Webinar</li> <li>Automatics Demo Webinar</li> <li>Code Contribution Process</li> <li>Scriptless Automation Webinar</li> </ul>"},{"location":"tools/docs/Automatics/#automatics-framework","title":"Automatics Framework","text":"<ul> <li> <ul> <li> <p> Automatics Automated Build &amp; Deployment </p> </li> <li> <p></p> <p> Automatics Device Manager </p> </li> <li> <p></p> <p> Automatics Framework Repository Details </p> </li> <li> <p></p> <p> Automatics Generic Core Test Execution </p> </li> <li> <p></p> <p> Automatics Getting Started </p> </li> <li> <p></p> <p> Automatics Properties </p> </li> <li> <p></p> <p> Automatics Provider Details </p> </li> <li> <p></p> <p> Automatics Providers List </p> </li> <li> <p></p> <p> Automatics System Setup </p> </li> <li> <p></p> <p> Automatics Technology Stack - Upgrade </p> </li> <li> <p></p> <p> Automatics Tool Setup </p> </li> <li> <p></p> <p> Jenkins Setup and Deployment Guide </p> </li> </ul> </li> </ul>"},{"location":"tools/docs/Automatics/#automatics-core","title":"Automatics Core","text":"<ul> <li> <ul> <li> <p> Automatics API Specification </p> </li> <li> <p></p> <p> Automatics Core Overview </p> </li> </ul> </li> </ul>"},{"location":"tools/docs/Automatics/#automatics-rdk-b-tests","title":"Automatics RDK-B Tests","text":"<ul> <li> <ul> <li> <p> Automatics RDK-B Test case Provider Mapping </p> </li> <li> <p></p> <p> Automatics RDK-B Test Plan </p> </li> <li> <p></p> <p> Automatics RDK-B Test Property configuration </p> </li> <li> <p></p> <p> Automatics RDK-B Test Refactoring Releases &amp; Roadmap </p> </li> <li> <p></p> <p> Automatics RDKB Test Repository Details </p> </li> <li> <p></p> <p> Automatics RDK-B Test script Releases </p> </li> <li> <p></p> <p> Automatics RDK-B Test Scripts </p> </li> <li> <p></p> <p> Automatics RDK-B Tests Test Category </p> </li> <li> <p></p> <p> Automatics TCs shared by L&amp;T for open sourcing </p> </li> <li> <p></p> <p> Device Configuration in Automatics </p> </li> <li> <p></p> <p> RDKB Automatics Test - Connected Client Environment Setup </p> </li> <li> <p></p> <p> RDK-B Automatics Test Setup </p> </li> <li> <p></p> <p> RDKB - Test Reports 2023Q4 Kirkstone build </p> </li> <li> <p></p> <p> RDKB - Test Reports 2024Q2 Kirkstone build </p> </li> <li> <p></p> <p> RDKB - Test Reports 2024Q3 Kirkstone build </p> </li> <li> <p></p> <p> RDKB - Test Reports 2024Q4 Kirkstone build </p> </li> <li> <p></p> <p> RDKB Tests on Raspberry Pi device </p> </li> <li> <p></p> <p> RDKB Tests on Raspberry Pi device - Execution Status </p> </li> </ul> </li> </ul>"},{"location":"tools/docs/Automatics/#automatics-working-group","title":"Automatics Working Group","text":"<ul> <li> <ul> <li> <p> Automatics-3.0 </p> </li> <li> <p></p> <p> Automatics Candela Integration </p> </li> <li> <p></p> <p> Automatics Roadmap and Backlogs </p> </li> <li> <p></p> <p> TR181 Validation Support </p> </li> </ul> </li> </ul>"},{"location":"tools/docs/Automatics/#automatics-community-collaboration","title":"Automatics Community Collaboration","text":"<ul> <li> <ul> <li> <p> Automatics Community Contributions </p> </li> </ul> </li> </ul>"},{"location":"tools/docs/TDK/","title":"Test Development Kit (TDK) Home","text":"<p>Welcome to the TDK space!</p> <p>The RDK Test Development Kit (TDK) is a generic test kit for automated testing of generic RDK components and end-to-end scenarios facilitated by a web based user interface for configuration, test creation, execution and result aggregation. The web based UI is complemented by command line interfaces to power test automation from third party test and continuous integration tools. The TDK facilitates the testing of RDK devices in standalone environments. This page provides information regarding the TDK roadmap, usage tutorials, development processes and FAQs to facilitate the RDK community to start using the tool and provide feedback and requirements for the improvement of the tool to suite the generic community needs.</p>"},{"location":"tools/docs/TDK/#tdk-release-notes-roadmap-updates","title":"TDK Release Notes &amp; Roadmap Updates","text":"<ul> <li>TDK Releases</li> </ul>"},{"location":"tools/docs/TDK/#tdk-documentation","title":"TDK-Documentation","text":"<ul> <li> <p>TDK-V Documentation</p> </li> <li> <p>TDK-B Documentation</p> </li> <li> <p>TDK-C Documentation</p> </li> <li> <p>RDK Certification\u00a0</p> </li> </ul>"},{"location":"tools/docs/TDK/#tutorials-documents","title":"Tutorials &amp; Documents","text":"<ul> <li> <p>TDK-V Test Case Documents</p> </li> <li> <p>TDK-B Test Case Documents</p> </li> <li> <p>Docker Setup for TDK Test Manager</p> </li> <li> <p>TDK-B E2E Setup Document</p> </li> <li> <p>TDK Bug Resolution     Workflow</p> </li> <li> <p>FAQ</p> </li> <li> <p>TDK Test Manager Java8 Migration</p> </li> <li> <p>TDK - RDK Service Validation Framework</p> </li> </ul>"}]}